{"posts":[{"title":"Hello World","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new &quot;My New Post&quot; More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","link":"/Hexo/2024/06/18/hello-world/"},{"title":"Docker容器中删除文件后，大小不减反增怎么办？","text":"Docker的镜像是由多层存储结构组成的，每一层都是只读的，所以您无法删除之前层的操作。 但是可以通过以下步骤达到一样的效果。 假设你从原始镜像a中创建了容器b。 现在你在容器b中删除了一些东西。 您可以使用docker export命令将容器的文件系统导出为一个tar文件: 1docker export -o my.tar containerID 然后，使用docker import命令从这个tar文件导入为一个新的镜像: 1docker import my.tar new-image 此时这个new-image镜像就摆脱了旧镜像的历史层，大小也会相应大大减少。 但是你可能会失去一些东西：环境变量、端口映射、镜像的历史记录和层级结构、镜像的标签和版本号、镜像的创建时间和作者、容器的启动命令和参数等等。","link":"/Hexo/2023/06/10/2023-H1/2023-06-10-21-23-00/"},{"title":"基数排序和快速排序谁快(随机数测试)？","text":"前言什么?你说归并？？？开了个1百万的数据量，差点以为是鲁大师点烟。 一、测试结果对比使用的是win10的子系统ubuntu编译运行 计算时间使用的是&lt; cstdlib&gt;里的clock()函数，因为数量很小，所以最后结果没除CLOCKS_PER_SEC 基数排序会快一些，但是消耗空间接近2倍更多。2倍，才2倍？我参考了这个优化—链接 二、附上代码，大家可以自己手动测试测试language-cpp12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970#include&lt;iostream&gt;#include&lt;cstdio&gt;#include&lt;ctime&gt;#include&lt;algorithm&gt;#include&lt;cstdlib&gt;using namespace std;int getMax(int* p,int len){ int m=p[0]; for(int i=1;i&lt;len;++i) { if(p[i]&gt;m){ m=p[i];}} return m;}void count_sort(int* p,int len,int cot){ int temp[len];//不报错？？？ int buckets[10]={ 0}; for(int i=0;i&lt;len;++i) { buckets[(p[i]/cot)%10]++;} for(int i=1;i&lt;10;++i) { buckets[i]+=buckets[i-1];} for(int i=len-1;i&gt;=0;--i) { temp[buckets[(p[i]/cot)%10]-1]=p[i]; buckets[(p[i]/cot)%10]--; } for(int i=0;i&lt;len;++i) { p[i]=temp[i];}}int main(){ srand((unsigned)time(NULL)); clock_t start,end; int arr[100]; int len=100; for(int i=0;i&lt;len;++i) { arr[i]=rand()%len;} start=clock(); //count_sort int maxA=getMax(arr,len); for(int cot=1;maxA/cot&gt;0;cot*=10) { count_sort(arr,len,cot);} //sort(arr,arr+len); end=clock(); printf(&quot;\\ntime=%.6lf\\n&quot;,(double)(end-start));//CLOCKS_PER_SEC // for(int i=0;i&lt;len;++i) // {printf(&quot;%d &quot;,arr[i]);} return 0;}","link":"/Hexo/2021/12/13/2021-H2/2021-12-13-20-36-12/"},{"title":"优雅地给Docker容器添加新端口","text":"一共分为三步，停止容器和docker服务，修改配置文件，重启服务和容器。 这里只讲如何修改配置文件。 如果你是Linux环境容器配置文件hostconfig.json 通常位于 /var/lib/docker/containers/[hash_of_the_container]/hostconfig.json 或者 /var/snap/docker/common/var-lib-docker/containers/[hash_of_the_container]/hostconfig.json 找到PortBindings字段，以下是一个端口的格式例子 1234567891011121314&quot;PortBindings&quot;: { &quot;8080/tcp&quot;: [ { &quot;HostIp&quot;: &quot;&quot;, &quot;HostPort&quot;: &quot;8080&quot; } ], &quot;8088/tcp&quot;: [ { &quot;HostIp&quot;: &quot;&quot;, &quot;HostPort&quot;: &quot;8088&quot; } ] }, 如果不起作用，建议同时修改下面提到的config.v2.json 。 如果你是windws+wsl2环境那么你需要修改两个文件，hostconfig.json和config.v2.json，它们都位于/mnt/wsl/docker-desktop-data/data/docker/&lt;containerID&gt;下。 hostconfig.json文件修改和linux的一样。 config.v2.json需要修改以下两个字段 123&quot;ExposedPorts&quot;:{&quot;8080/tcp&quot;:{},&quot;8088/tcp&quot;:{}}&quot;Ports&quot;:{&quot;8080/tcp&quot;:[{&quot;HostIp&quot;:&quot;0.0.0.0&quot;,&quot;HostPort&quot;:&quot;8080&quot;}],&quot;8088/tcp&quot;:[{&quot;HostIp&quot;:&quot;0.0.0.0&quot;,&quot;HostPort&quot;:&quot;8088&quot;}]} 参考资料How do I assign a port mapping to an existing Docker container? - Stack Overflowhttps://stackoverflow.com/questions/19335444/how-do-i-assign-a-port-mapping-to-an-existing-docker-containerAdding new exposed ports to existing docker container (Windows/WSL 2) | by LifeOnKeyboardBlog | Mediumhttps://medium.com/@lifeonkeyboardblog/adding-new-exposed-ports-to-existing-docker-container-windows-wsl-2-3cfe58d551e","link":"/Hexo/2023/06/12/2023-H1/2023-06-12-16-58-01/"},{"title":"Linux+Docker部署基于Ambari的Hadoop集群","text":"建议文档和视频一起食用。 文档链接 文档https://1138882663s-organization.gitbook.io/between-code-and-words/bigdata/ambari/da-jian-xu-ni-ji-ji-qun-yi-ji-an-zhuang-ambari 视频链接视频https://b23.tv/YdYulVJ docker因为容器化技术和虚拟化技术的区别，部署hadoop会存在很多bug。建议使用虚拟机而不是容器。 https://www.bilibili.com/video/BV1Az4y1v7Zw/https://www.bilibili.com/video/BV1Az4y1v7Zw/","link":"/Hexo/2023/06/19/2023-H1/2023-06-19-17-06-08/"},{"title":"Docker for Winodws从镜像简易部署基于Ambari的hadoop集群","text":"建议文档视频一起食用。 文档链接 https://1138882663s-organization.gitbook.io/between-code-and-words/bigdata/ambari/da-jian-xu-ni-ji-ji-qun-yi-ji-an-zhuang-ambarihttps://1138882663s-organization.gitbook.io/between-code-and-words/bigdata/ambari/da-jian-xu-ni-ji-ji-qun-yi-ji-an-zhuang-ambari视频链接 https://www.bilibili.com/video/BV1Eh4y1R78n/?share_source=copy_web&amp;vd_source=c049c0e0a94c93c0094803efaa8a12fchttps://www.bilibili.com/video/BV1Eh4y1R78n/?share_source=copy_web&amp;vd_source=c049c0e0a94c93c0094803efaa8a12fc docker因为容器化技术和虚拟化技术的区别，部署hadoop会存在很多bug。建议使用虚拟机而不是容器。 https://www.bilibili.com/video/BV1Az4y1v7Zw/https://www.bilibili.com/video/BV1Az4y1v7Zw/","link":"/Hexo/2023/06/19/2023-H1/2023-06-19-17-08-42/"},{"title":"JavaSE-集合","text":"Java基础集合分为两大类，Collection和Map，前者单列集合，后者双列集合。 Collection下图为Collection集合体系树 Collection下有List和Set两小类集合，List和Set都只是接口。 List的具体实现有ArrayList和LinkedList，Set的具体实现有HashSet，LinkedHashSet，TreeSet。 它们的特点如下表 |——|—————|————|| | | || List | ArrayList | 有序，可重复，有索引 || List | LinkedList | 有序，可重复，有索引 || Set | HashSet | 无序，不重复，无索引 || Set | LinkedHashSet | 有序，不重复，无索引 || Set | TreeSet | 排序，不重复，无索引 | Map下图为Map集合体系树 其中具体的实现分别是HashMap，LinkedHashMap，TreeMap，特点如下表 |—–|—————|————|| | | || Map | HashMap | 无序，不重复，无索引 || Map | LinkedHashMap | 有序，不重复，无索引 || Map | TreeMap | 排序，不重复，无索引 | 需要注意的是Map的”序”都是基于Key的 性能ArrayListArrayList行为和数组无异，插入删除会设计复制覆盖，性能不高，但是因为索引所以涉及索引的操作性能格外的好，比如读取，末尾增删改。同时内存占用很小，除了数据本身没有太多其他的东西。 LinkedListLinkedList在ArrayList基础上，使用”链”链接前后元素，取缔了ArrayList因为复制覆盖造成的低效行为，在增删改性能都很好，但是因为使用了链所以数据在内存中不是连续的，故而失去了索引一步读取的优势，需要遍历才能锁定元素，因此涉及索引的操作都受到一定性能下滑。内存占用比ArrayList多了”链”。 请使用Iterator迭代器，通过Iterator迭代List永远是效率最高的 123List&lt;String&gt; list = new ArrayList&lt;String&gt;();//后期还可直接替换成LinkedListlist = new LinkedList&lt;String&gt;(); HashSetHashSet是基于哈希表实现的，哈希表是一种增删改查性能都较好的数据结构 目前的（jdk8+）哈希表是基于数组+链表+红黑树实现的。 我们可以肯定LinkedList的链能够一步增删元素的优势，但是却没法一步定位到元素，但是Hash可以逼近，Hash将元素的哈希值取余后的到的结果作为索引放入数组对应位置，如果多个元素位置相同就用链连接，这就是哈希表的雏形=数组+链表，虽然看起来漏洞百出。使用哈希表定位元素只需对哈希值取余得到索引，锁定数组位置，然后遍历链表，锁定元素。只需要保证哈希表取余和遍历都不会花上太多时间，那么哈希表在锁定元素上就也是成功的。 庆幸的是，哈希表的取余操作十分高效，这得益于它的设计，哈希表的数组长度保持为2的幂，用二进制数表示就是一个1+多个0，比如10=2，100=4，1000=8，那么对于随便一个二进制数，和这个2幂进行”按位与”运算就可以得到余数的二进制数。 如果我们保证一个数组位置上的元素不会太多，那么遍历链表也是开销极小的。哈希表默认的加载因子为0.75，意味着元素数超过数组长度*0.75时，哈希表会进行扩容，也就是将数组长度*2 ，这就保证了一个数组位置上的链表不会太长。此时又会产生一个问题，扩容后所有元素都需要重新取余计算位置吗？不用，哈希表也有巧妙的办法，基本上只需要移动一半的元素就可以。 同时，在红黑树的加持下，如果太过幸运，数组某位置上的链表过长（&gt;8），那么哈希表会把这个链表变成红黑树，进一步为遍历加速。 因此，HashSet的性能是均衡地较好。 LinkedHashSet就是在HashSet的基础上，给元素间加上了链，确定了它们的顺序。 TreeSet底层不是哈希表了，而是红黑树，一种自平衡二叉树。性能感觉起来是更优雅的均衡较好。 随着元素数量增加，二叉树优势越为明显，如果数组+链表的结构能在低量元素时能比红黑树快，那么哈希表就比单纯的红黑树快。 MapMap和Set是一样的，更准确地说，Set底层用的就是Map，忽略了value只保留key而已。 其他问题HashSet不能对内容一样的两个不同对象去重，为什么？怎么办？比如自定义Student类 12345public class Student { private String name; private int age; private double height;} 12Student s1 = new Student(&quot;张三&quot;, 22, 189.5);Student s2 = new Student(&quot;张三&quot;, 22, 189.5); 因为第一，哈希表需要对象的哈希值确定位置，而hashCode()默认是地址的比较，两个不同对象地址明显不同，使用哈希表会错误地把两个对象也放进去。解决办法是重写对象地hashCode()方法。 因为第二，如果两个对象hashCode()一致，在数组同一位置，此时会进行equals比较，如果是false，后者就会当作新元素。解决办法就是重写equals方法。 在Java中==对基本数据类型是值的比较，对对象是地址比较。 equals方法（一般不对基本数据类型比较），对对象是地址比较，但是对象的equals方法可以重写。这很常见，就像String一样是重写过的，使用equals实际上是在对值进行比较。 所以想要去重，就要重写对象的hashCode和equals方法。 idea可以快捷插入hashCode和equals，默认是值一样就相等。 123456789101112@Overridepublic boolean equals(Object o) { if (this == o) return true; if (o == null || getClass() != o.getClass()) return false; StudentComp student = (StudentComp) o; return age == student.age &amp;&amp; Double.compare(height, student.height) == 0 &amp;&amp; Objects.equals(name, student.name);}@Overridepublic int hashCode() { return Objects.hash(name, age, height);} 如果TreeSet的键是自定义对象，怎么定义排序规则？两个办法 Student类继承Comparable接口，重写compareTo方法 12345678910111213public class Student implements Comparable&lt;Student&gt; { private String name; @Override public int compareTo(Student o) { if (this.age!=o.age){ return Integer.compare(this.age, o.age); }else if (this.height!=o.height){ return Double.compare(this.height, o.height); }else{ return this.name.compareTo(o.name); } }} 使用TreeSet时提供参数构造器的Comparator 123456789101112Set&lt;Student&gt; set2 = new TreeSet&lt;&gt;(new Comparator&lt;Student&gt;() { @Override public int compare(Student o1, Student o2) { if (o1.age!=o2.age){ return Integer.compare(o1.age, o2.age); }else if (o1.height!=o2.height){ return Double.compare(o1.height, o2.height); }else{ return o1.name.compareTo(o2.name); } } }); 123456789Set&lt;Student&gt; set2 = new TreeSet&lt;&gt;((o1, o2)-&gt;{ if (o1.age!=o2.age){ return Integer.compare(o1.age, o2.age); }else if (o1.height!=o2.height){ return Double.compare(o1.height, o2.height); }else{ return o1.name.compareTo(o2.name); } });","link":"/Hexo/2023/10/13/2023-H2/2023-10-13-14-23-54/"},{"title":"JavaSE-Stream流","text":"从流的出生，经过过滤，排序，去重等各种方法，变成最后的结果，就像水流一样，在代码层面也类似地简单明了，最大的优点是不用自己去保存中间状态，而是可以一直往后操作，直到遇到Stream的终结方法，也像水流一样，Stream流使用后就会改变，一般只用一遍。 1.获取Stream流一般集合都提供了stream方法，只需要.stream()就可以获取。比如 12Set&lt;String&gt; set = new HashSet&lt;&gt;();Stream&lt;String&gt; stream = set.stream(); 但Map除外，Map用以下方法获取流： keySet()获取Key的Set后stream或者values()获取Value的Set后stream entrySet()转化为包含Map.Entry的Set后stream 一般建议用第二种，毕竟Key+Value才是Map的精髓，下面代码里的Entry可以理解为Pair(一对)。 12Map&lt;String, Double&gt; map = new HashMap&lt;&gt;();Stream&lt;Map.Entry&lt;String, Double&gt;&gt; stream = map.entrySet().stream(); Arrays数组可以通过以下方式获得Stream Arrays.stream(YourArrays) Stream.of(YourArrays) 2.常用的Stream的中间方法 filter使用lambda式判断条件作为过滤，例如： 12345678List&lt;Double&gt; scores = new ArrayList&lt;&gt;();Collections.addAll(scores, 88.5, 108.8, 60.0, 99.0, 9.5, 99.6, 25.0);//需求1:找出成绩人于等于60分的数据,并升序后,可输出。List&lt;Double&gt; list1 = scores.stream() .filter(s -&gt; s &gt; 60) .sorted() .collect(Collectors.toList());System.out.println(list1); sorted排序，limit限制数量，skip跳过，distinct去重，都比较简单。其中sorted需要重写排序规则，在集合体系已经讲过，distinct需要重写hashCode和equals，如果是Java自带的基础集合，都不用管这些。 map操作接收一个函数作为参数，支持lambda，比如 1234List&lt;Integer&gt; numList = Arrays.asList(1, 2, 3, 4, 5); List&lt;String&gt; strList = numList.stream() .map(n -&gt; n.toString()) .collect(Collectors.toList()); concat合并流，后者接在前者后面，比如 1234Stream&lt;String&gt; stream1 = Stream.of(&quot;张三&quot;, &quot;李四&quot;);Stream&lt;String&gt; stream2 = Stream.of(&quot;张三2&quot;, &quot;李四2&quot;, &quot;王五&quot;);Stream&lt;String&gt; streamAll = Stream.concat(stream1, stream2);streamAll.forEach(s -&gt; System.out.println(s)); 3.常用的终结方法 collect里面填诸如Collectors.toList()，Collectors.toSet()，to什么就用什么接收结果。 12.collect(Collectors.toList());.collect(Collectors.toMap(Student::getName, Student::getHeight))","link":"/Hexo/2023/10/13/2023-H2/2023-10-13-14-24-12/"},{"title":"JavaSE-IO","text":"IO流总体来看有四大类 字节输入流 字节输出流 字符输入流 字符输出流 IO的体系如下图 需要注意的是字节流适合完整的复制文件之类的操作，而字符流尤其适合纯文本文件。 第一行实现类，都是原始流，性能并不高。 第二行是Buffer缓冲流，自带8KB缓冲池，相当于缓存之于cpu和硬盘的感觉。 第三行是打印流，符合平常的println习惯。 第四行是数据流，适合保存读取基本类型数据，保存后的文件打开是乱码很正常。 第五行是序列流，适合保存读取对象，对象需实现Serializable接口，transient关键字可以设置某变量不参加序列化。 除了原始流，其他的都是高级流，高级流都封装了原始流，并且性能都比较好。 IO框架Commons-IOhttps://www.w3schools.cn/apache_commons_io/同时Java自己后来也提供了IO框架库。","link":"/Hexo/2023/10/13/2023-H2/2023-10-13-14-42-45/"},{"title":"JavaSE-日志文件","text":"​日志接口有两类， Commons Logging (JCL) Simple Logging Facade for Java (SLF4J) 热门的Logback是基于SLF4J实现的。 ​​ 所以要使用Logback首先需要添加3个依赖，去maven仓库搜一下，用maven加载就好。 = = = = = = = = = = = = = = = = = = == = = = = = Maven仓库 = = = = = = == = = = = = = = = = = = = = = = = = = 然后我们可以通过一个logback.xml文件来配置logback一些东西，文件放在/src/main/resources下，这是一份样例。 language-xml1234567891011121314151617181920212223242526272829303132333435363738394041424344&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;configuration&gt; &lt;!-- CONSOLE ：表示当前的日志信息是可以输出到控制台的。 --&gt; &lt;appender name=&quot;CONSOLE&quot; class=&quot;ch.qos.logback.core.ConsoleAppender&quot;&gt; &lt;!--输出流对象 默认 System.out 改为 System.err--&gt; &lt;target&gt;System.out&lt;/target&gt; &lt;encoder&gt; &lt;!--格式化输出：%d表示日期，%thread表示线程名，%-5level：级别从左显示5个字符宽度 %msg：日志消息，%n是换行符--&gt; &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [%-5level] %c [%thread] : %msg%n&lt;/pattern&gt; &lt;charset&gt;utf-8&lt;/charset&gt; &lt;/encoder&gt; &lt;/appender&gt; &lt;!-- File是输出的方向通向文件的 --&gt; &lt;appender name=&quot;FILE&quot; class=&quot;ch.qos.logback.core.rolling.RollingFileAppender&quot;&gt; &lt;encoder&gt; &lt;pattern&gt;%d{yyyy-MM-dd HH:mm:ss.SSS} [%thread] %-5level %logger{36} - %msg%n&lt;/pattern&gt; &lt;charset&gt;utf-8&lt;/charset&gt; &lt;/encoder&gt; &lt;!--日志输出路径--&gt; &lt;file&gt;C:/Users/kmo/IdeaProjects/JAVA-DataSt/DataSt/src/main/resources/Log/data.log&lt;/file&gt;&lt;!-- 指定日志文件拆分和压缩规则--&gt; &lt;rollingPolicy class=&quot;ch.qos.logback.core.rolling.SizeAndTimeBasedRollingPolicy&quot;&gt; &lt;!--通过指定压缩文件名称，来确定分割文件方式--&gt; &lt;fileNamePattern&gt;C:/Users/kmo/IdeaProjects/JAVA-DataSt/DataSt/src/main/resources/Log/log-%d{yyyy-MM-dd}.log%i.gz&lt;/fileNamePattern&gt; &lt;!--文件拆分大小--&gt; &lt;maxFileSize&gt;1MB&lt;/maxFileSize&gt; &lt;/rollingPolicy&gt; &lt;/appender&gt; &lt;!-- level:用来设置打印级别，大小写无关：TRACE, DEBUG, INFO, WARN, ERROR(只有大于等于这个级别的才会被记录) | ALL 和 OFF ， 默认debug &lt;root&gt;可以包含零个或多个&lt;appender-ref&gt;元素，标识这个输出位置将会被本日志级别控制。 --&gt; &lt;root level=&quot;ALL&quot;&gt; &lt;!-- 注意：如果这里不配置关联打印位置，该位置将不会记录日志--&gt; &lt;appender-ref ref = &quot;CONSOLE&quot;/&gt; &lt;appender-ref ref=&quot;FILE&quot; /&gt; &lt;/root&gt;&lt;/configuration&gt; ​接着这样在代码中引入logback日志输出器 language-java1234567891011import org.slf4j.Logger;import org.slf4j.LoggerFactory;public class Test{ public static void main(String[] args) { Logger logger = LoggerFactory.getLogger(&quot;&quot;); logger.info(&quot;This a info message&quot;); logger.warn(&quot;This a warning message&quot;); }}","link":"/Hexo/2023/10/13/2023-H2/2023-10-13-14-56-45/"},{"title":"JavaSE-高级特性","text":"一、单元测试使用Junit框架 二、反射反射可以破坏封装性，得到一个类的所有成分，最重要的途径是用来参与Java框架制作。获取Class对象的三种方式 Class c1 = 类名.class 调用Class提供方法: public static Class forName(String package); Object提供的方法: public Class getClass(); Class c3 = 对象.getClass(); 反射案例需求：对于任意对象，将对象的字段名和对应的值保存到文件中去假设我们有Teacher类和Student类，那么代码如下 language-java12345678910111213141516171819202122232425262728293031323334353637public class Demo01 { private String dirPath = &quot;src/main/resources/P13/&quot;; @Test public void test01() { Student s1 = new Student(&quot;淇&quot;,22,'女',167.56,&quot;swim&quot;); Teacher t1 = new Teacher(&quot;柳&quot;,5433.2); work(s1, dirPath+&quot;s.txt&quot;); work(t1, dirPath+&quot;t.txt&quot;); } public void work(Object object, String filePath) { //1.create fileIO try (// FileWriter fileWriter = new FileWriter(filePath); PrintWriter printWriter = new PrintWriter(filePath); ) { //2.get Object fields info Class c = object.getClass(); Field[] declaredFields = c.getDeclaredFields(); printWriter.println(&quot;--------&quot;+c.getSimpleName()+&quot;--------&quot;); for (Field f : declaredFields) { f.setAccessible(true); printWriter.println(f.getName()+&quot; --&gt; &quot;+f.get(object)); } } catch (Exception e) { throw new RuntimeException(e); } }} 三、注解 我的注解一如下 language-java1234567public @interface MyAnnotation { String aaa(); boolean bbb() default true; String[] ccc();} 注解二如下 language-java1234public @interface MyAnnotation2 { String value();} 注解使用如下 language-java12345678910111213141516171819package org.kmo.d08_Annotation.Test01;import org.junit.Test;@MyAnnotation(aaa=&quot;牛魔王&quot;, ccc={ &quot;Python&quot;,&quot;Java&quot;})public class MyTest01 { @MyAnnotation(aaa=&quot;铁山&quot;,bbb=false,ccc={ &quot;C++&quot;,&quot;C&quot;}) public void test1(){ } @MyAnnotation2(&quot;孙悟空&quot;) public void test2(){ }} 解析注解案例需求：定义注解MyTest4。定义一个Demo类,在类中定义一个test1方法，并在该类和其方法上使用MyTest4注解。定义AnnotationTest3测试类,解析Demo类中的全部注解。 这是一个注解 language-java123456789@Target({ ElementType.TYPE, ElementType.METHOD})@Retention(RetentionPolicy.RUNTIME)public @interface MyTest4 { String value(); double aaa() default 100; String[] bbb();} 这是Demo类 language-java123456789101112@MyTest4(value = &quot;vv&quot;,aaa = 99.9, bbb={ &quot;b&quot;,&quot;bb&quot;,&quot;bbb&quot;})public class Demo { @MyTest4(value = &quot;我是至尊宝&quot;,aaa = 100.9, bbb = { &quot;小淇&quot;,&quot;爱你&quot;}) public void test01(){ }} 这是解析类，解析Demo类上的注解以及Demo类方法的注解 language-java1234567891011121314151617181920212223242526272829public class AnnotationTest3 { @Test public void test01(){ Class c = Demo.class; if (c.isAnnotationPresent(MyTest4.class)){ MyTest4 myTest4 = (MyTest4) c.getDeclaredAnnotation(MyTest4.class); System.out.println(myTest4.value()); System.out.println(myTest4.aaa()); System.out.println(Arrays.toString(myTest4.bbb())); } } @Test public void test02() throws Exception { Class c = Demo.class; Method method = c.getDeclaredMethod(&quot;test01&quot;); if (method.isAnnotationPresent(MyTest4.class)){ MyTest4 myTest4 = (MyTest4) method.getDeclaredAnnotation(MyTest4.class); System.out.println(myTest4.value()); System.out.println(myTest4.aaa()); System.out.println(Arrays.toString(myTest4.bbb())); } }} 注解案例-简易Junit这是一个注解 language-java123456@Target(ElementType.METHOD)@Retention(RetentionPolicy.RUNTIME)public @interface MyTest { } 这是运行代码 language-java12345678910111213141516171819202122232425262728293031323334353637public class Demo { @MyTest() public void test01(){ System.out.println(&quot;===Test01====&quot;); } public void test02(){ System.out.println(&quot;===Test02====&quot;); } @MyTest public void test03(){ System.out.println(&quot;===Test03====&quot;); } public void test04(){ System.out.println(&quot;===Test04====&quot;); } public static void main(String[] args) throws Exception { Demo demo = new Demo(); Class c = Demo.class; Method[] methods = c.getDeclaredMethods(); for (Method method : methods) { if (method.isAnnotationPresent(MyTest.class)){ method.invoke(demo); } } }} 四、动态代理 相当于把相同的地方集合到一起了，只要写一遍，且灵活。 动态代理案例需求：对一个类的所有方法前后都加上计时，当类的方法被调用时，输出时间。 一个UserService接口 language-java123456public interface UserService { void login(String loginName, String password) throws Exception; void deleteUsers() throws Exception; String[] selectUsers() throws Exception;} UserServicelmpl实现类 language-java1234567891011121314151617181920212223242526272829303132public class UserServiceImpl implements UserService { @Override public void login(String loginName, String passWord) throws Exception { if (&quot;admin&quot;.equals(loginName) &amp;&amp; &quot;123456&quot;.equals(passWord)) { System.out.println(&quot;您登录成功，欢迎光临本系统~&quot;); } else { System.out.println(&quot;您登录失败，用户名或密码错误~&quot;); } Thread.sleep(1000); } @Override public void deleteUsers() throws Exception { System.out.println(&quot;成功删除了1万个用户~&quot;); Thread.sleep(1500); } @Override public String[] selectUsers() throws Exception { System.out.println(&quot;查询出3个用户&quot;); String[] names = { &quot;张全蛋&quot;,&quot;李二狗&quot;,&quot;牛爱花&quot;}; Thread.sleep(500); return names; }} ProxyUtil代理类 language-java1234567891011121314151617181920212223242526272829303132public class ProxyUtil { public static UserService createProxy(UserService userService){ UserService userServiceProxy = (UserService) Proxy.newProxyInstance( ProxyUtil.class.getClassLoader(), new Class[]{ UserService.class}, new InvocationHandler() { @Override public Object invoke(Object proxy, Method method, Object[] args) throws Throwable { if (method.getName().equals(&quot;login&quot;) || method.getName().equals(&quot;deleteUsers&quot;) || method.getName().equals(&quot;selectUsers&quot;)){ long startTime = System.currentTimeMillis(); Object res = method.invoke(userService, args); long endTime = System.currentTimeMillis(); System.out.println(method.getName()+&quot;方法执行耗时: &quot; + (endTime - startTime) / 1000.0 + &quot;s&quot;); return res; }else { Object res = method.invoke(userService, args); return res; } } } ); return userServiceProxy; }} 在这个代理中，被代理的类传入，Proxy.newProxyInstance中重写的invoke方法里，就是在重写被代理类的所有方法，可以理解为在调用（被代理的）类的方法时，其实是在调用这里的invoke。如果不想做更改，直接执行method.invoke就行。 运行代码 language-java1234567891011121314151617public class Tests { public static void main(String[] args) throws Exception { // UserService userService = new UserServiceImpl(); UserService userService = ProxyUtil.createProxy(new UserServiceImpl()); userService.login(&quot;admin&quot;,&quot;123456&quot;); System.out.println(&quot;--------------------&quot;); userService.deleteUsers(); System.out.println(&quot;--------------------&quot;); String[] strings = userService.selectUsers(); System.out.println(Arrays.toString(strings)); System.out.println(&quot;--------------------&quot;); }}","link":"/Hexo/2023/10/14/2023-H2/2023-10-14-19-22-07/"},{"title":"JavaSE-网络通信","text":"一、概述基本的通信架构有2种形式: CS架构( Client客户端/Server服务端) BS架构(Browser浏览器/Server服务端) IPV4共32bit，4字节，形如192.168.000.001IPV6共128bit，16字节，形如2001:0db8:0000:0023:0008:0800:200c:417aIPV4形为4位十进制数，每个数字基于8bit，范围0~255IPV6形为8位十六进制数，每个数基于16bit，范围0000~FFFF(0 ~ 65535)使用Java自带的java.net.InetAddress 可以互动IP 前两个为构造器，后三个为方法 二、端口和协议 UDP不事先建立连接，发送方直接发送，不管对面状态，是不可靠连接。但是通信效率高，适合诸如视频直播、语音通话等。单个数据包最大限制为64KB。 TCP事先通过三次握手建立连接，可靠连接，四次挥手断开连接，在不可靠信道做到可靠连接 三次握手是要Client和Server知道对方可以’收’和’发’第一次握手：S知道C可以发第二次握手：C知道S可以收发第三次握手：S知道C可以收发之后传输数据时，C也不断向S发送确认消息，S需要回复确认，如果没有，那么C会采取重发等措施。 三、UDP编程 S和C都需要先创建数据包类，用来接收信息。S代码如下 language-cpp12345678910111213141516171819202122232425public class Server { public static void main(String[] args) throws Exception { //1. create server socket DatagramSocket socket = new DatagramSocket(8889); //2. create packet byte[] bytes = new byte[1024 * 64]; DatagramPacket packet = new DatagramPacket(bytes, bytes.length); while (true) { //3.receive socket.receive(packet); System.out.println(&quot;服务端收到了长度为 &quot;+packet.getLength()+&quot; bytes的数据&quot;); System.out.println(&quot;数据为: &quot;+new String(bytes,0, packet.getLength())); System.out.println(&quot;消息来自:\\nIP-&gt;&quot;+packet.getAddress().getHostAddress()); System.out.println(&quot;Name-&gt;&quot;+packet.getAddress().getHostName()); System.out.println(&quot;Port-&gt;&quot;+packet.getPort()); System.out.println(&quot;-----------------------------&quot;); }// socket.close(); }} S会在socket.receive一直等待C的消息，同时通过packet也可以查看发送方的一些信息。C代码如下 language-cpp12345678910111213141516171819202122232425262728public class Client { public static void main(String[] args) throws Exception { //1. create client DatagramSocket socket = new DatagramSocket(); Scanner sc = new Scanner(System.in); while (true){ System.out.println(&quot;请说：&quot;); String s = sc.nextLine(); if (&quot;exit&quot;.equals(s)){ System.out.println(&quot;欢迎下次使用~&quot;); break; } //2. create data package byte[] bytes = s.getBytes(); DatagramPacket packet = new DatagramPacket(bytes, bytes.length, InetAddress.getLocalHost(),8889); //3.send socket.send(packet); System.out.println(&quot;客户端发送了长度为 &quot;+bytes.length+&quot; bytes的数据&quot;); System.out.println(&quot;数据为: &quot;+new String(bytes)); System.out.println(&quot;----------------------&quot;); } socket.close(); }} 你可能会好奇为什么S可以在循环外创建packet重复使用而C每次循环都要创建新的？因为C每次发送的信息长度是未知的，而packet创建需要给出length所以C每次发送都需要重新创建，同时S对C发送的消息长度也是未知的，但是由于UDP对数据包有64KB上限制约，所以我们可以直接创建个64KB大的packet来接收，然后截断字节就可以。 四、TCP编程 TCP中C由Socket类创建，而S由ServerSocket类创建，然后通过accept方法再次获得Socket类。 S代码如下 language-cpp1234567891011121314151617181920212223242526272829 public static void main(String[] args) throws Exception { //1.create serversocket ServerSocket serverSocket = new ServerSocket(8889); //2.wait client link request Socket socket = serverSocket.accept(); //3.get input is for receive message InputStream is = socket.getInputStream(); //4.package low is to high is DataInputStream dis = new DataInputStream(is); while (true) { try { //5.receive message System.out.println(&quot;消息来自: &quot;+socket.getRemoteSocketAddress()); String rs = dis.readUTF(); System.out.println(&quot;消息为:&quot;+rs); } catch (IOException e) { System.out.println(&quot;客户端离线了&quot;); break; } } //close dis.close(); socket.close(); }} S会在accept等待CC代码如下 language-cpp12345678910111213141516171819202122232425262728293031public class Client { public static void main(String[] args) throws Exception { //1.create socket and send link request to server Socket socket = new Socket(InetAddress.getLocalHost().getHostAddress(), 8889); //2.get socket output for write message to server OutputStream os = socket.getOutputStream(); //3.package low os to high os DataOutputStream dos = new DataOutputStream(os); Scanner sc = new Scanner(System.in); while (true) { System.out.println(&quot;请说&quot;); String s = sc.nextLine(); if (s.equals(&quot;exit&quot;)){ break; } //4.write message dos.writeUTF(s); dos.flush();//立刻发送 System.out.println(&quot;已发送~&quot;); } //close dos.close(); socket.close(); }} 通过高级流包装原始流，方便编程，这里用的是数据流，将字符串以UTF-8的编码形式传输。 五、QATCP怎么实现多个C对一个S？一个S应对多个C的TCP通信，S需要线程池，每个通信都抛给子线程处理即可。在ServerSocket.accept到一个C的适合，就把这个socket抛到子线程。 TCP怎么实现群聊？C除了需要发送信息，还需要接收信息，并且两个行为需要持续开启，所以C需要多线程，一个从用户键盘读取信息发送，一个从S接收其他C发送的信息。S除了线程池外，还需要一个子线程都能访问共享数组，来保存所有socket，子线程收到对应的C的消息，就抄一份发给所有socket。","link":"/Hexo/2023/10/14/2023-H2/2023-10-14-19-23-30/"},{"title":"Vue-ts-优雅的响应式对象数组（reactive型数组）","text":"需求绘制如下画面，每一行绑定的数据都是独立的，并且还需要完成”增加行”按钮。 Vue前端代码language-html123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;el-button @click=&quot;addLine&quot;&gt;增加行&lt;/el-button&gt; &lt;el-row&gt; &lt;el-col :span=&quot;4&quot; align=&quot;middle&quot;&gt;产品&lt;/el-col&gt; &lt;el-col :span=&quot;4&quot; align=&quot;middle&quot;&gt;仓库&lt;/el-col&gt; &lt;el-col :span=&quot;4&quot; align=&quot;middle&quot;&gt;批次号&lt;/el-col&gt; &lt;el-col :span=&quot;4&quot; align=&quot;middle&quot;&gt;库存数量&lt;/el-col&gt; &lt;el-col :span=&quot;4&quot; align=&quot;middle&quot;&gt;隔离数量&lt;/el-col&gt; &lt;/el-row&gt; &lt;el-form&gt; &lt;el-row v-for=&quot;(item, i) in inItemNums&quot;&gt; &lt;el-col :span=&quot;4&quot;&gt; &lt;el-select v-model=&quot;inQueryParams[i].product&quot; placeholder=&quot;请选择产品&quot; @change=&quot;inSelectProductChange(i)&quot;&gt; &lt;el-option v-for=&quot;item in inSelectOption[i].product&quot; :key=&quot;item.value&quot; :label=&quot;item.label&quot; :value=&quot;item.value&quot; /&gt; &lt;/el-select&gt; &lt;/el-col&gt; &lt;el-col :span=&quot;4&quot;&gt; &lt;el-select v-model=&quot;inQueryParams[i].factory&quot; placeholder=&quot;Select&quot; @change=&quot;inSelectFactoryChange(i)&quot;&gt; &lt;el-option v-for=&quot;item in inSelectOption[i].factory&quot; :key=&quot;item.value&quot; :label=&quot;item.label&quot; :value=&quot;item.value&quot; /&gt; &lt;/el-select&gt; &lt;/el-col&gt; &lt;el-col :span=&quot;4&quot;&gt; &lt;el-select v-model=&quot;inQueryParams[i].batchNum&quot; placeholder=&quot;Select&quot; @change=&quot;inSelectBatchNumChange(i)&quot;&gt; &lt;el-option v-for=&quot;item in inSelectOption[i].batchNum&quot; :key=&quot;item.value&quot; :label=&quot;item.label&quot; :value=&quot;item.value&quot; /&gt; &lt;/el-select&gt; &lt;/el-col&gt; &lt;el-col :span=&quot;4&quot;&gt; &lt;el-input v-model=&quot;inQueryParams[i].stockQuantity&quot; readonly&gt;&lt;/el-input&gt; &lt;/el-col&gt; &lt;el-col :span=&quot;4&quot;&gt; &lt;el-input v-model=&quot;inQueryParams[i].isolateQuantity&quot;&gt;&lt;/el-input&gt; &lt;/el-col&gt; &lt;/el-row&gt; &lt;/el-form&gt; Vue逻辑实现language-typescript123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051interface IselectOptionItem { product: [], factory: [], batchNum: [], isolateQuantity: []}const selectOptionItem = { product: [], factory: [], batchNum: [], isolateQuantity: []}interface IqueryParamsItem { product: undefined, factory: undefined, batchNum: undefined, stockQuantity: undefined, isolateQuantity: undefined}const queryParamsItem = { product: undefined, factory: undefined, batchNum: undefined, stockQuantity: undefined, isolateQuantity: undefined}const inItemNums = ref(5);const inSelectOption = reactive&lt;IselectOptionItem []&gt;([])for (let i = 0; i &lt; inItemNums.value; i++) { inSelectOption.push({ ...selectOptionItem})}const inQueryParams = reactive&lt;IqueryParamsItem[]&gt;([]);for (let i = 0; i &lt; inItemNums.value; i++) { inQueryParams.push({ ...queryParamsItem})}const addLine=()=&gt;{ inSelectOption.push({ ...selectOptionItem}) inQueryParams.push({ ...queryParamsItem}) inItemNums.value = inItemNums.value+1;} 注意点往数组添加元素时，不使用selectOptionItem而是{...selectOptionItem}，区别是前者是引用，而后置是复制，如果写前者，那么数组里的元素都指向一个对象，那么就会出现下拉框的值一起联动。","link":"/Hexo/2023/10/16/2023-H2/2023-10-16-15-09-56/"},{"title":"Vue-Router-编程式路由跳转","text":"历届办法 path+query参数会暴露在url name+params官方在2022–8-22已禁用params传参，具体看这This state参数不会暴露在url，但刷新页面会失效，和以前的params一样 store用额外的插件来store，顾名思义存储数据，此本章不做讲解。 起手式：配置路由无论是path还是name，都需要在路由配置中指定每个路径对应的组件。将配置都写到一个配置文件中，然后在vue的main.js中挂载配置它，具体流程是这样的： 首先，您需要在项目的src目录下创建一个router文件夹，用来存放路由相关的文件。 然后，在router文件夹中创建一个index.js文件，用来编写路由配置。例如： language-js123456789101112131415161718192021222324252627282930// router/index.jsimport { createRouter, createWebHashHistory } from 'vue-router'// 导入路由组件 import Home from '.../components/Home.vue' import About from '.../components/About.vue'// 定义路由 //pathconst routes = [ { path: '/', component: Home }, { path: '/about', component: About }, ]/*//nameconst routes = [ { name: &quot;Home&quot;, path: &quot;/&quot;, component: Home } { name: &quot;About &quot;, path: &quot;/about&quot;, component: About }]*/// 创建路由实例 const router = createRouter({ history: createWebHashHistory(), routes, })// 导出路由实例 export default router 最后，在main.js文件中导入路由器对象，并将其挂载到Vue实例上。例如： language-js1234567891011121314// main.js// 在main.js中 import { createApp } from 'vue' import App from './App.vue'// 导入路由实例 import router from './router'// 创建并挂载根实例 const app = createApp(App)// 使用路由实例 app.use(router)app.mount('#app') 1. path+query发送方 language-typescript1234567891011&lt;script setup lang=&quot;ts&quot;&gt;import { useRouter } from &quot;vue-router&quot;;const router = useRouter();const goPath = (id: number) =&gt; { router.push({ path: &quot;/about&quot;, query: { id: id } });};&lt;/script&gt; 接收方 language-typescript12345678910111213&lt;script setup lang=&quot;ts&quot;&gt;import { useRoute } from &quot;vue-router&quot;;const route = useRoute();const id = route.query.id;&lt;/script&gt;&lt;template&gt;&lt;div&gt;Id: { { id }}&lt;/div&gt;&lt;/template&gt; 2. state发送方 language-typescript1234567891011121314&lt;script setup lang=&quot;ts&quot;&gt;import { useRouter } from &quot;vue-router&quot;;const router = useRouter();const goPath = (id: number) =&gt; { router.push({ path: &quot;/about&quot;, state: { id: id } }); //或者 //router.push({ name: &quot;About&quot;, state: { id: id } });};&lt;/script&gt; 接收方 language-typescript12345678910&lt;script setup lang=&quot;ts&quot;&gt;const id = history.state.data;&lt;/script&gt;&lt;template&gt;&lt;div&gt;Id: { { id }}&lt;/div&gt;&lt;/template&gt;","link":"/Hexo/2023/10/18/2023-H2/2023-10-18-10-17-20/"},{"title":"云服务器Docker部署SpringBoot+MySQL(Ubuntu)","text":"参考文件夹结构 language-bash1234567MyTest01├── javaDocker.sh├── mysqlDocker.sh├── MySQL│ └── data├── SpringBoot └── MyWeb01-SpringBoot-0.0.1-SNAPSHOT.jar 一、起手式：配置环境1.镜像拉取以下两个镜像 language-bash12docker pull openjdk:17docker pull mysql:8 二、启动Mysql容器在mysqlDocker.sh脚本写入以下内容，然后bash运行脚本意思是将mysql数据映射到主机并设置密码为xxxx， language-bash12345678910#!/bin/bashcontainerName=&quot;MySQLTest01&quot;MySQLData=&quot;/root/MyTest01/MySQL/data&quot;docker run -d --name &quot;$containerName&quot; \\ -p 3306:3306 \\ -v &quot;$MySQLData&quot;:/var/lib/mysql \\ -e MYSQL_ROOT_PASSWORD=xxxx \\ mysql:8 在云服务器安全组开放入站规则3306端口此时可以用你喜欢的数据库连接软件来连接这个mysql容器，并创建test01数据库和一张student表，结构随意，随便插入几条数据。 三、配置SpringBoot容器并简单测试添加如下配置到application.yml补充你的云服务器IP和刚才设置的密码 language-yaml123456spring: datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://xxx.xxx.xxx.xxx:3306/test01?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false&amp;serverTimezone=UTC username: root password: xxxx 写一个简单的测试如下 language-java1234567891011121314151617181920212223242526272829303132333435package com.example.myweb01springboot.controller;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.jdbc.core.JdbcTemplate;import org.springframework.web.bind.annotation.CrossOrigin;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;import javax.sql.DataSource;import java.sql.SQLException;@RestController@RequestMapping(&quot;/Home&quot;)@CrossOrigin(origins = &quot;*&quot;, allowedHeaders = &quot;*&quot;)public class TestController { @Autowired DataSource dataSource; @Autowired JdbcTemplate jdbcTemplate; @GetMapping(&quot;/Kmo&quot;) public String test() throws SQLException { System.out.println(&quot;默认数据源为：&quot; + dataSource.getClass()); System.out.println(&quot;数据库连接实例：&quot; + dataSource.getConnection()); //访问数据库user表，查询user表的数据量 Integer i = jdbcTemplate.queryForObject(&quot;SELECT count(*) from `student`&quot;, Integer.class); System.out.println(&quot;user 表中共有&quot; + i + &quot;条数据。&quot;); return &quot;Success!&quot;+i; }} 然后本地运行打开浏览器访问localhost:8081/Home/Kmo验证是否从远程数据库取得连接。然后在application.yml中将url的服务器IP改成db language-yaml123456spring: datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://db:3306/test01?useUnicode=true&amp;characterEncoding=utf-8&amp;useSSL=false&amp;serverTimezone=UTC username: root password: xxxx 然后maven打包成jar，参考文件夹结构，将jar放入指定位置。将以下内容写入javaDocker.sh脚本并bash运行脚本意思是，向名为MySQLTest01的容器建立网络链接（单向的），它的名字（IP，主机名）为db，于是此容器可以通过db:3306访问MySQLTest01容器的mysql服务。 language-bash1234567891011#!/bin/bashcontainerName=&quot;JavaTest01&quot;SpringBootPath=&quot;/root/MyTest01/SpringBoot/MyWeb01-SpringBoot-0.0.1-SNAPSHOT.jar&quot;docker run -d --name &quot;$containerName&quot; \\ -p 8081:8081 \\ --link MySQLTest01:db \\ -v &quot;$SpringBootPath&quot;:/app/your-app.jar \\ openjdk:17 java -jar /app/your-app.jar 开放云服务器安全组入站规则8081端口，浏览器访问云服务器IP:8081/Home/Kmo验证。 结束后记得关闭云服务器的3306入站规则 (完)","link":"/Hexo/2023/10/23/2023-H2/2023-10-23-20-35-06/"},{"title":"云服务器Docker部署SpringBoot+Redis(Ubuntu)","text":"参考文件夹结构 language-bash1234567MyTest01├── javaDocker.sh├── redisDocker.sh├── Redis│ └── data├── SpringBoot └── MyWeb01-SpringBoot-0.0.1-SNAPSHOT.jar 一、起手式：配置环境1.镜像拉取以下两个镜像 language-bash12docker pull openjdk:17docker pull redis 二、启动Redis容器在redisDocker.sh脚本写入以下内容，然后bash运行脚本意思是将redis数据映射到主机 language-bash123456789#!/bin/bashcontainerName=&quot;RedisTest01&quot;RedisData=&quot;/root/MyTest01/Redis/data&quot;docker run -d --name &quot;$containerName&quot; \\ -v &quot;$RedisData&quot;:/data \\ -p 6379:6379 \\ redis 三、配置SpringBoot容器并简单测试添加如下配置到application.yml language-yaml123456spring: data: redis: host: redisdb port: 6379 password: 写一个简单的测试如下 language-java1234567891011121314151617181920212223242526272829303132333435package com.example.myweb01springboot.controller;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.data.redis.core.RedisTemplate;import org.springframework.web.bind.annotation.CrossOrigin;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;import javax.sql.DataSource;import java.sql.SQLException;@RestController@RequestMapping(&quot;/Home&quot;)@CrossOrigin(origins = &quot;*&quot;, allowedHeaders = &quot;*&quot;)public class TestController { @Autowired private RedisTemplate&lt;String, String&gt; redisTemplate; @GetMapping(&quot;/Kmo&quot;) public String test() throws SQLException { // 设置一个键值对 redisTemplate.opsForValue().set(&quot;name&quot;, &quot;张三&quot;); // 获取一个键值对 String name = redisTemplate.opsForValue().get(&quot;name&quot;); System.out.println(name); return &quot;Success!&quot;+name; }} 然后maven打包成jar，参考文件夹结构，将jar放入指定位置。将以下内容写入javaDocker.sh脚本并bash运行脚本意思是，向名为MySQLTest01的容器建立网络链接（单向的），它的名字（IP，主机名）为db，于是此容器可以通过db:3306访问MySQLTest01容器的mysql服务。 language-bash1234567891011#!/bin/bashcontainerName=&quot;JavaTest01&quot;SpringBootPath=&quot;/root/MyTest01/SpringBoot/MyWeb01-SpringBoot-0.0.1-SNAPSHOT.jar&quot;docker run -d --name &quot;$containerName&quot; \\ -p 8081:8081 \\ --link RedisTest01:redisdb \\ -v &quot;$SpringBootPath&quot;:/app/your-app.jar \\ openjdk:17 java -jar /app/your-app.jar 开放云服务器安全组入站规则8081端口，浏览器访问云服务器IP:8081/Home/Kmo验证。 (完)","link":"/Hexo/2023/10/23/2023-H2/2023-10-23-20-44-25/"},{"title":"Vue3 setup组合式语法优雅地使用Echarts库","text":"1. 安装Echartsnpm或者yarn安装 npm install echarts yarn add echarts 2.main.js全局挂载Echartslanguage-javascript123456789import { createApp } from 'vue'import App from './App.vue' import * as echarts from 'echarts' const app = createApp(App)app.config.globalProperties.$echarts = echarts // 全局挂载echartsapp.mount('#app') 3.Vue setup组合式语法使用案例language-html12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182&lt;template&gt; &lt;!-- 通过ref获取html元素 宽高必须设置 --&gt; &lt;el-row&gt; &lt;el-col :offset=&quot;8&quot; :span=&quot;8&quot;&gt; &lt;div ref=&quot;info&quot; style=&quot;width: 100%; height: 600px&quot;&gt;&lt;/div&gt; &lt;/el-col&gt; &lt;/el-row&gt;&lt;/template&gt;&lt;script setup&gt;import { onMounted, ref, inject } from &quot;vue&quot;;const { proxy } = getCurrentInstance()//获取Vue3全局配置const info = ref();//用来获取对应标签组件onMounted(() =&gt; { var infoEl = info.value;//获取ref=&quot;info&quot;的标签组件 var userEc = proxy.$echarts.init(infoEl, &quot;light&quot;);//proxy.$echarts是在获取全局配置中的echarts，这样就不需要在每个vue中import echarts了//此处为图表配置区，可参考Echarts官网替换各种图表 var option = { tooltip: { trigger: 'item' }, legend: { top: '5%', left: 'center' }, series: [ { name: 'Access From', type: 'pie', radius: ['40%', '70%'], avoidLabelOverlap: false, itemStyle: { borderRadius: 10, borderColor: '#fff', borderWidth: 2 }, label: { show: false, position: 'center' }, emphasis: { label: { show: true, fontSize: 40, fontWeight: 'bold' } }, labelLine: { show: false }, data: [ { value: 1048, name: 'Search Engine' }, { value: 735, name: 'Direct' }, { value: 580, name: 'Email' }, { value: 484, name: 'Union Ads' }, { value: 300, name: 'Video Ads' } ] } ] }; userEc.setOption(option);//将图标挂载到标签组件});&lt;/script&gt; （完）","link":"/Hexo/2023/10/28/2023-H2/2023-10-28-22-20-16/"},{"title":"ElementPlus-穿梭框长宽设置","text":"1234567891011121314151617&lt;style scoped&gt;:deep(.el-transfer-panel) { height: 400px; /* 穿梭框高度 */ width: 300px;}:deep(.el-transfer-panel__list.is-filterable) { height: 400px; /* 穿梭框列表高度 */}:deep(.el-transfer-panel__body) { height: 400px; /* 穿梭框视图层高度 */}:deep(.el-transfer-panel__filter) { width: 300px; /* 修改搜索栏的宽度 */}&lt;/style&gt;","link":"/Hexo/2023/10/28/2023-H2/2023-10-28-22-22-18/"},{"title":"JavaWeb项目开发流程","text":"1. 需求分析收集客户需求，明确项目功能，设计较为详细的实体关系图。 推荐：ProcessOn 2. 技术选型确定开发框架、数据库、服务器等技术选型，这些选择应该与项目需求相匹配，同时也要考虑团队成员技术能力和经验。 推荐：RuoYi-Vue3 3. 数据库设计根据需求分析结果，设计数据库模型，表结构，表关系。 推荐：dbdiagram.io 4. 模块划分和接口设计将项目划分为多个小模块，并为每个模块的前后端设计api。 推荐：Apifox 4. UI设计根据需求分析结果，设计原型模型，包括UI界面设计等。 推荐：Pixso 5. 编码根据需求分析、技术选型、原型设计和数据库设计等结果，开始编写代码，包括前端代码和后端代码等。 推荐：前端Vue3+ElementPlus开发，后端SpringBoot+MybatisPlus开发 6. 调试和测试在编码过程中，需要不断进行代码调试和测试，以确保程序的正确性和稳定性。 推荐：Junit 7. 部署和上线完成测试后，将程序部署到服务器上，并进行上线运行，同时需要进行系统监控和数据备份等工作。 推荐：云服务器+Docker 8. 运维和维护程序上线后，需要进行运维和维护工作，包括性能监控、安全维护、bug修复等。 （例子待完善）","link":"/Hexo/2023/10/30/2023-H2/2023-10-30-21-36-41/"},{"title":"ElementPlus隐藏Scrollbar的横向滚动条","text":"language-css12345678:deep(.el-scrollbar__wrap ){ overflow-x: hidden !important;}:deep(.el-scrollbar__bar.is-horizontal) { height: 0 !important;}","link":"/Hexo/2023/11/01/2023-H2/2023-11-01-22-15-02/"},{"title":"ElementPlus表单验证v-for循环问题","text":"提供两个样例，主要注意&lt;el-form-item&gt;中的prop 样例一language-html123456789101112131415161718192021222324252627282930313233343536373839404142434445464748&lt;template&gt; &lt;el-form ref=&quot;dynamicValidateForm&quot; :model=&quot;dynamicValidateForm&quot; label-width=&quot;120px&quot; class=&quot;demo-dynamic&quot; &gt; //重点关注el-form-item标签中的prop内容 &lt;el-form-item v-for=&quot;(domain, index) in dynamicValidateForm.domains&quot; :key=&quot;domain.key&quot; :label=&quot;'Domain' + index&quot; :prop=&quot;'domains.' + index + '.value'&quot; :rules=&quot;{ required: true, message: 'domain can not be null', trigger: 'blur', }&quot; &gt; &lt;el-input v-model=&quot;domain.value&quot;&gt;&lt;/el-input&gt; &lt;/el-form-item&gt; &lt;/el-form&gt;&lt;/template&gt;&lt;script lang=&quot;ts&quot;&gt; export default { data() { return { dynamicValidateForm: { domains: [ { key: 1, value: '', }, ], email: '', }, } }, }&lt;/script&gt; 样例二language-html12345678910111213141516171819202122232425&lt;template&gt;&lt;el-form :model=&quot;queryParams&quot; style=&quot;width: 100%&quot;&gt; &lt;el-table :data=&quot;queryParams.items&quot;&gt; &lt;el-table-column label=&quot;移动数量&quot; width=&quot;100&quot;&gt; &lt;template #default=&quot;scope&quot;&gt; &lt;div style=&quot;display: flex; align-items: center&quot;&gt; &lt;el-form-item style=&quot;width: 100px;padding: 0px;margin: 0px&quot; :prop=&quot;'items.'+scope.$index+'.moveAmount'&quot; :rules=&quot;{ required: true, message: '不能为空', trigger: 'blur',}&quot;&gt; &lt;el-input-number class=&quot;number&quot; :controls=&quot;false&quot; v-model=&quot;scope.row.moveAmount&quot;&gt;&lt;/el-input-number&gt; &lt;/el-form-item&gt; &lt;/div&gt; &lt;/template&gt; &lt;/el-table-column&gt; &lt;/el-table&gt; &lt;/el-form&gt;&lt;/template&gt;&lt;script setup&gt;const queryParams = reactive({ factory1: undefined, factory2: undefined, commentText: undefined, items:[]})&lt;/script&gt;","link":"/Hexo/2023/11/13/2023-H2/2023-11-13-15-10-21/"},{"title":"JavaWeb后端将excel文件传输到前端浏览器下载(SpringBoot+Vue3)","text":"一、后端 导入依赖 language-xml12345&lt;dependency&gt; &lt;groupId&gt;org.apache.poi&lt;/groupId&gt; &lt;artifactId&gt;poi-ooxml&lt;/artifactId&gt; &lt;version&gt;4.1.2&lt;/version&gt;&lt;/dependency&gt; controller层其中@RequestParam String moveNo是前端传入的参数，而HttpServletResponse response不是，前者可以没有，后者一定要有。 language-java1234567@GetMapping(&quot;/yourControllerApi&quot;)public AjaxResult exportData(@RequestParam String moveNo, HttpServletResponse response){ System.out.println(moveNo); System.out.println(response); return stockMgntService.exportData(moveNo, response);} service层 language-java12345678910111213141516171819202122232425262728293031323334@Servicepublic class StockMgntServiceImpl implements StockMgntService { @Override public AjaxResult exportData(String moveNo, HttpServletResponse response) { //这里是从后台resources文件夹下读取一个excel模板 ClassPathResource resource = new ClassPathResource(&quot;template/模板.xlsx&quot;); try(InputStream fis = resource.getInputStream(); Workbook workbook = WorkbookFactory.create(fis); ServletOutputStream os = response.getOutputStream() ){ //这块写入你的数据 //往第一个sheet的第一行的第2列和第5列写入数据 Sheet sheet = workbook.getSheetAt(0); sheet.getRow(0).getCell(1, Row.MissingCellPolicy.CREATE_NULL_AS_BLANK).setCellValue(&quot;test&quot;); sheet.getRow(0).getCell(5, Row.MissingCellPolicy.CREATE_NULL_AS_BLANK).setCellValue(&quot;test&quot;); /*......你的操作......*/ //这块开始配置传输 response.setCharacterEncoding(&quot;UTF-8&quot;); response.setContentType(&quot;application/vnd.ms-excel&quot;); response.setHeader(&quot;Content-disposition&quot;, &quot;attachment;filename=template.xlsx&quot;); response.flushBuffer(); workbook.write(os); os.flush(); os.close(); }catch (IOException e) { throw new RuntimeException(e); } return null; }} 二、前端axios向对应api发送请求并携带参数，然后使用Blob来接收后端的OutputStream输出流并保存下载保存到本地浏览器。 language-html12345678910111213141516171819202122232425262728&lt;template&gt; &lt;el-button type=&quot;primary&quot; @click=&quot;downloadData&quot; size=&quot;small&quot; plain&gt;模板下载&lt;/el-button&gt;&lt;/template&gt;&lt;script setup&gt;const downloadData = () =&gt; { console.log(queryParams.moveNo) axios({ url: '/yourControllerApi', method: 'get', params: { moveNo:'0000212132142'}, responseType: &quot;blob&quot; }).then(rp=&gt;{ console.log(rp) const blob = new Blob([rp], { type: 'application/vnd.ms-excel'}); let link = document.createElement('a'); link.href = URL.createObjectURL(blob); link.setAttribute('download', '模板下载.xlsx'); link.click(); link = null; });}&lt;/script&gt;","link":"/Hexo/2023/11/23/2023-H2/2023-11-23-13-15-18/"},{"title":"JavaWeb后端解析前端传输的excel文件(SpringBoot+Vue3)","text":"一、前端前端拿Vue3+ElementPlus做上传示例 language-html12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576&lt;template&gt; &lt;el-button type=&quot;primary&quot; @click=&quot;updateData&quot; size=&quot;small&quot; plain&gt;数据上传&lt;/el-button&gt; &lt;el-dialog :title=&quot;upload.title&quot; v-model=&quot;upload.open&quot; width=&quot;400px&quot; align-center append-to-body&gt; &lt;el-upload ref=&quot;uploadRef&quot; :limit=&quot;1&quot; accept=&quot;.xlsx, .xls&quot; :headers=&quot;upload.headers&quot; :action=&quot;upload.url&quot; :disabled=&quot;upload.isUploading&quot; :on-progress=&quot;handleFileUploadProgress&quot; :on-success=&quot;handleFileSuccess&quot; :auto-upload=&quot;false&quot; drag &gt; &lt;el-icon class=&quot;el-icon--upload&quot;&gt; &lt;upload-filled/&gt; &lt;/el-icon&gt; &lt;div class=&quot;el-upload__text&quot;&gt;将文件拖到此处，或&lt;em&gt;点击上传&lt;/em&gt;&lt;/div&gt; &lt;template #tip&gt; &lt;div class=&quot;el-upload__tip text-center&quot;&gt; &lt;span&gt;仅允许导入xls、xlsx格式文件。&lt;/span&gt; &lt;/div&gt; &lt;/template&gt; &lt;/el-upload&gt; &lt;template #footer&gt; &lt;div class=&quot;dialog-footer&quot;&gt; &lt;el-button type=&quot;primary&quot; @click=&quot;submitFileForm&quot;&gt;确 定&lt;/el-button&gt; &lt;el-button @click=&quot;upload.open = false&quot;&gt;取 消&lt;/el-button&gt; &lt;/div&gt; &lt;/template&gt; &lt;/el-dialog&gt;&lt;/template&gt;&lt;script setup&gt;const upload = reactive({ // 是否显示弹出层（用户导入） open: false, // 弹出层标题（用户导入） title: &quot;标题&quot;, // 是否禁用上传 isUploading: false, // 是否更新已经存在的用户数据 updateSupport: 0, // 设置上传的请求头部 headers: { Authorization: &quot;Bearer &quot; + getToken()}, // 上传的地址 url: import.meta.env.VITE_APP_BASE_API + &quot;/yourControllerApi&quot;});//数据上传const updateData = () =&gt; { upload.title = &quot;数据上传&quot;; upload.open = true;}//文件上传中处理const handleFileUploadProgress = (event, file, fileList) =&gt; { upload.isUploading = true; console.log(upload.url)};//文件上传成功处理const handleFileSuccess = (rp, file, fileList) =&gt; { //这里的rp就是后端controller的响应数据 console.log(rp) upload.open = false; upload.isUploading = false; proxy.$refs[&quot;uploadRef&quot;].handleRemove(file);};&lt;/script&gt; 二、后端 导入依赖 language-xml12345&lt;dependency&gt; &lt;groupId&gt;org.apache.poi&lt;/groupId&gt; &lt;artifactId&gt;poi-ooxml&lt;/artifactId&gt; &lt;version&gt;4.1.2&lt;/version&gt;&lt;/dependency&gt; controller接收file language-java12345@PostMapping(&quot;/yourControllerApi&quot;)public AjaxResult importData(@RequestBody MultipartFile file){ return stockMgntService.importData(file);} service具体实现 language-java12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152@Servicepublic class StockMgntServiceImpl implements StockMgntService { @Override public AjaxResult importData(MultipartFile file) { try(InputStream is = file.getInputStream();) { Workbook workbook = WorkbookFactory.create(is); int numberOfSheets = workbook.getNumberOfSheets(); if (numberOfSheets != 1){ //要处理多个sheet，循环就可以 System.out.println(&quot;只允许有1个Sheet&quot;); return null; } //取得第一个sheet Sheet sheet = workbook.getSheetAt(0); //获取最后一行的索引，但通常会比预想的要多出几行。 int lastRowNum = sheet.getLastRowNum(); //循环读取每一行 for (int rowNum = 0; rowNum &lt; lastRowNum; rowNum++) { Row rowData = sheet.getRow(rowNum); if (rowData != null){ //可以使用rowData.getLastCellNum()获取最后一列的索引，这里只有6行，是假设现在的excel模板是固定的6行 for(int cellNum = 0; cellNum &lt; 6; ++cellNum){ Cell cell = rowData.getCell(cellNum); if (cell == null){ continue;} cell.setCellType(CellType.STRING); if (!cell.getStringCellValue().isEmpty()){ System.out.println(cell.getStringCellValue()); } /* 利用这个方法可以更好的将所有数据以String获取到 Cell cell = productCodeRow.getCell(cellNum , Row.MissingCellPolicy.RETURN_BLANK_AS_NULL); String cellValue = dataFormatter.formatCellValue(cell ); */ } } } }catch (Exception e) { System.out.println(e.getMessage()); throw new RuntimeException(); } }} 三、结语这样的方式只能处理简单的excel，对于结构更复杂的excel，需要其他工具utils结合。以及可以结合SpringBoot有更好的poi使用方法。","link":"/Hexo/2023/11/23/2023-H2/2023-11-23-13-15-45/"},{"title":"JavaWeb Springboot后端接收前端Date变量","text":"如果前端传输的日期符合ISO 8601格式，那么后端用@PostMapping + @RequestBody那么springboot就会自动解析。 如果传输的日期格式不符合ISO 8601格式或者传输用的是Get方法，那么在接收传输的实体类中加上@DateTimeFormat(pattern = &quot;yyyy-MM-dd HH:mm:ss&quot;)，这里面的pattern对应传来的日期格式。 language-html12345678910111213141516171819202122ISO 8601是一种国际标准的日期和时间表示方式。这种格式的主要特点包括：- 时间日期按照年月日时分秒的顺序排列，大时间单位在小时间单位之前。- 每个时间单位的位数固定，不足时于左补0。- 提供两种方法来表示时间：其一为只有数字的基础格式；其二为添加分隔符的扩展格式，让人能更容易阅读。具体来说，ISO 8601的日期和时间表示方式的格式为`YYYY-MM-DDTHH:mm:ss.sssZ`，其中：- `YYYY`代表四位数年份。- `MM`代表月份。- `DD`代表天数。- `T`作为日期和时间的分隔符。- `HH`代表小时。- `mm`代表分钟。- `ss.sss`代表秒和毫秒。- `Z`代表的是时区。例如，&quot;2023年11月15日06时16分50秒&quot;可以表示为&quot;2023-11-15T06:16:50&quot;。&quot;2023-11-15&quot;是ISO 8601日期格式的一个子集。在ISO 8601中，日期可以表示为&quot;YYYY-MM-DD&quot;的格式。因此，&quot;2023-11-15&quot;是符合ISO 8601日期格式的。","link":"/Hexo/2023/11/23/2023-H2/2023-11-23-13-15-59/"},{"title":"Vue3 setup路由进入以及变化问题","text":"1. 起因在Vue 3中，&lt;script setup&gt;语法糖提供了一种更加简洁和组合式的方式来定义组件。然而，由于&lt;script setup&gt;的特性，它不能直接使用beforeRouteEnter、beforeRouteUpdate和beforeRouteLeave这些导航守卫。 但是vue-router中有两个的类似函数可以触发路由离开和变化，只需要import一下就可以。 language-js123456789101112131415&lt;script setup&gt; import { onBeforeRouteLeave, onBeforeRouteUpdate } from &quot;vue-router&quot;; onBeforeRouteUpdate((to, from, next) =&gt; { console.log(&quot;onBeforeRouteUpdate&quot;,to,from, typeof next) next(); }) onBeforeRouteLeave((to, from, next)=&gt;{ console.log(&quot;beforeRouteLeave&quot;,to,from, typeof next) next() })&lt;/script&gt; 但是却没有beforeRouteEnter的替代品。 2. 浏览过的代替方法https://github.com/vuejs/rfcs/discussions/302#discussioncomment-2794537https://blog.richex.cn/vue3-how-to-use-beforerouteenter-in-script-setup-syntactic-sugar.htmlhttps://blog.csdn.net/oafzzl/article/details/125045087 但是都是在&lt;script setup&gt;之上新加了第二个&lt;script&gt;，用第二个&lt;script&gt;来使用无setup的beforeRouteEnter。限制很多，尤其是两个script之间互动很麻烦，甚至无法实现。 3. 还是Watchhttps://juejin.cn/post/7171489778230100004https://blog.csdn.net/m0_55986526/article/details/122827829 下面是一个当路由从&quot;/stock/move/moveDetail&quot;到&quot;/stock/move/moveSearch&quot;触发函数的例子。同时第一次进入时也会触发watch，就相当于beforeRouteEnter了。 language-js12345678910111213141516&lt;script setup&gt; import { watch} from &quot;vue&quot;; import { useRouter} from &quot;vue-router&quot;; let router = useRouter() // 监听当前路由变化 watch(() =&gt; router.currentRoute.value,(newPath, oldPath) =&gt; { if (newPath != null &amp;&amp; oldPath != null &amp;&amp; &quot;fullPath&quot; in newPath &amp;&amp; &quot;fullPath&quot; in oldPath &amp;&amp; newPath[&quot;fullPath&quot;] === &quot;/stock/move/moveSearch&quot; &amp;&amp; oldPath[&quot;fullPath&quot;] === &quot;/stock/move/moveDetail&quot;){ onSubmitQuiet() } }, { immediate: true});&lt;/script&gt;","link":"/Hexo/2023/11/23/2023-H2/2023-11-23-13-16-46/"},{"title":"JavaWeb el-upload图片上传SpringBoot保存并且前端使用img src直接访问（基于RuoYi-Vue3）","text":"一、Vue前端language-html123456789101112&lt;el-upload v-model:file-list=&quot;createParams.fileList&quot; action=&quot;http://localhost:8080/DataMgt/uploadPic&quot; :headers=&quot;{ Authorization: 'Bearer ' + getToken() }&quot; list-type=&quot;picture-card&quot; :on-success=&quot;handleSuccess&quot; :before-upload=&quot;handlePicBeforeUpload&quot; :on-preview=&quot;handlePictureCardPreview&quot; :on-remove=&quot;handleRemove&quot;&gt; &lt;el-icon&gt;&lt;Plus /&gt;&lt;/el-icon&gt;&lt;/el-upload&gt; 需要注意的是action填写后端api路径，同时header需要填写token不然会被拦截，其余的没有影响可以翻阅文档理解。 二、SpringBoot后端language-java12345678910111213141516@RestController@RequestMapping(&quot;/DataMgt&quot;)public class Home extends BaseController { private static String picDir = &quot;C:\\\\Users\\\\mumu\\\\Desktop\\\\images\\\\&quot;; @RequestMapping(&quot;/uploadPic&quot;) public AjaxResult uploadPic(MultipartFile file) throws IOException { String filePath = picDir+ UUID.randomUUID().toString() + file.getOriginalFilename().substring(file.getOriginalFilename().lastIndexOf('.')); File saveF = new File(filePath); logger.info(&quot;save pic:&quot;+filePath); file.transferTo(saveF); return success(filePath); }} picDir填写的是图片保存到哪个文件夹路径，无论你是windows开发环境还是linux生产环境，这个路径都应该是绝对路径。现在图片保存到了这个路径，那么我们前端img的src又如何才能经由后端直接访问图片呢？ 第一，需要通过SpringBoot的@Configuration配置一个映射，如下 language-java12345678910@Configurationpublic class StaticConfig implements WebMvcConfigurer { @Override public void addResourceHandlers(ResourceHandlerRegistry registry) { registry.addResourceHandler(&quot;/images/**&quot;) .addResourceLocations(&quot;file:C:\\\\Users\\\\mumu\\\\Desktop\\\\images\\\\&quot;); }} 意思是将C:\\\\Users\\\\mumu\\\\Desktop\\\\images\\\\路径映射到/images/，那么当你访问http://localhost:8080/images/1.png时其实就是在访问C:\\\\Users\\\\mumu\\\\Desktop\\\\images\\\\1.png 第二，需要在若依的com.ruoyi.framework.config.SecurityConfig的configure函数中中配置访问权限，将/images/添加其中，对所有人开放，如下 language-java1.antMatchers(HttpMethod.GET, &quot;/&quot;, &quot;/*.html&quot;, &quot;/**/*.html&quot;, &quot;/**/*.css&quot;, &quot;/**/*.js&quot;, &quot;/profile/**&quot;, &quot;/images/**&quot;).permitAll() 最后，在前端，像这样就可以经由后端访问图片啦。 language-html1&lt;el-image src=&quot;http://localhost:8080/images/1.png&quot; style=&quot;width: 200px;height: 200px&quot;&gt;&lt;/el-image&gt; 三、延伸这是多图片上传组件，但其实每张都会和后端交互一次。 如果这个图片墙和文字搭配在一起成为一个图文动态发布页面，那么创建主副数据表，主表保存id和text表示id和文字，副表保存master_id，name，表示主表id，图片名。当新建动态时，在前端即刻生成当前时间作为图文动态的唯一标识。当上传图片时，以唯一标识作为master_id并以保存的名称作为name插入副表。当动态提交时，以唯一标识作为id并以文本内容作为text插入主表。当取消时，以唯一标识为查询条件删除主副表相关数据和图片资源。","link":"/Hexo/2023/11/23/2023-H2/2023-11-23-13-17-06/"},{"title":"JavaWeb 若依RuoYi-Vue3框架将Mybatis切换成MybatisPlus","text":"这里是官方的做法 mybatis是SqlSessionFactoryBean，而mybatis-plus是MybatisSqlSessionFactoryBean，所以一般最好是项目中使用一个最好，当然想要共存也可以，mybatis-plus的版本最好要高。这里只讲如何切换成MyBatisPlus。 一、修改yml在application.yml中将mybatis配置注释并写上新的mybatisplus，如下所示 language-yaml12345678910111213## MyBatis配置#mybatis:# # 搜索指定包别名# typeAliasesPackage: com.ruoyi.**.domain# # 配置mapper的扫描，找到所有的mapper.xml映射文件# mapperLocations: classpath*:mapper/**/*Mapper.xml# # 加载全局的配置文件# configLocation: classpath:mybatis/mybatis-config.xmlmybatis-plus: # 配置要扫描的xml文件目录，classpath* 代表所有模块的resources目录 classpath 不加星号代表当前模块下的resources目录 mapper-locations: classpath*:mapper/**/*Mapper.xml # 实体扫描，*通配符 typeAliasesPackage: com.ruoyi.**.domain 二、maven导入mybatisplus包，如下language-xml12345&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-boot-starter&lt;/artifactId&gt; &lt;version&gt;最新版本&lt;/version&gt;&lt;/dependency&gt; 三、注释SqlSessionFactoryBean找到com.ruoyi.framework.config.MyBatisConfig，注释public SqlSessionFactory sqlSessionFactory(DataSource dataSource)如下 language-java1234567891011121314151617// @Bean// public SqlSessionFactory sqlSessionFactory(DataSource dataSource) throws Exception// { // String typeAliasesPackage = env.getProperty(&quot;mybatis.typeAliasesPackage&quot;);// String mapperLocations = env.getProperty(&quot;mybatis.mapperLocations&quot;);// String configLocation = env.getProperty(&quot;mybatis.configLocation&quot;);// typeAliasesPackage = setTypeAliasesPackage(typeAliasesPackage);// VFS.addImplClass(SpringBootVFS.class);//// final SqlSessionFactoryBean sessionFactory = new SqlSessionFactoryBean();// sessionFactory.setDataSource(dataSource);// sessionFactory.setTypeAliasesPackage(typeAliasesPackage);// sessionFactory.setMapperLocations(resolveMapperLocations(StringUtils.split(mapperLocations, &quot;,&quot;)));// sessionFactory.setConfigLocation(new DefaultResourceLoader().getResource(configLocation));// return sessionFactory.getObject();// } 到这里就完成了切换，快去试试 吧。 资料参考若依框架集成mybatis换成mybatis-plus记录","link":"/Hexo/2023/11/23/2023-H2/2023-11-23-13-18-02/"},{"title":"JavaWeb 自动编号器Utils，用于各种自增长的编号，单号等","text":"使用以下技术栈 springboot mybatisplus mysql 一、首先设计一张表表名假设为auto_numbering 名称 数据类型 备注 描述 id bigint 主键 name varchar(64) 编号名称 prefix varchar(8) 前缀 inti_value bigint 初始值 current_value bigint 当前值 length int 编号长度（不包含前缀） 假设有两条数据 id name prefix inti_value current_value length 1 stock_input SI 0 2 8 2 product_code PC 0 5 8 第一条表示入库单编号，编号的规则是，前缀为SI，当前编号数为2，长度为8，那么下一次使用入库单号时，对应的current_value加1变为3,得到的单号应该是字符串&quot;SI00000003&quot; 。第二条表示产品编号，同理，对应的current_value加1变为6，应该得到字符串&quot;PC00000006&quot;。 那么如何设计这样一个自动编号工具类呢？这个工具类的方法最好是static，这样可以直接得到自动编号器的返回值，同时又要去让数据表对应的current_value自增。 二、创建对应的Domain类、Mapper接口、编号名称枚举类domain language-java12345678910111213141516171819202122232425262728293031323334353637383940414243444546import lombok.Data;import lombok.EqualsAndHashCode;import lombok.experimental.Accessors;@Data@EqualsAndHashCode(callSuper = true)@Accessors(chain = true)@TableName(&quot;auto_numbering&quot;)public class AutoNumbering{ private static final long serialVersionUID = 1L; /** * 主键 */ @TableId(value = &quot;id&quot;, type = IdType.AUTO) private Long id; /** * 编号名称 */ private String name; /** * 前缀 */ private String prefix; /** * 初始值 */ private Long intiValue; /** * 当前值 */ private Long currentValue; /** * 编号长度（不包含前缀） */ private Integer length;} mapper language-java123456789import com.baomidou.mybatisplus.core.mapper.BaseMapper;import org.apache.ibatis.annotations.Mapper;@Mapperpublic interface AutoNumberingMapper extends BaseMapper&lt;AutoNumbering&gt; { } enum language-java1234567891011121314151617181920212223242526272829303132333435public enum AutoNumberingEnum { STOCK_INPUT(&quot;stock_input&quot;, &quot;入库编号&quot;), PRODUCT_CODE(&quot;product_code&quot;, &quot;产品编号&quot;); private final String name; private final String remark; AutoNumberingEnum(String name, String remark) { this.name = name; this.remark = remark; } /** * 获取枚举名称 * * @return name */ public String getName() { return this.name; } /** * 获取枚举描述 * * @return remark */ public String getRemark() { return this.remark; }} 三、写一个Service接口和实现类service接口类 language-java12345678910public interface AutoNumberingService { /** * 获取下一个编号 * @param param 自动编号枚举值 * @return 自动编号字符串 */ String getNextNo(AutoNumberingEnum param);} serviceimpl language-java12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455import com.baomidou.mybatisplus.core.conditions.query.LambdaQueryWrapper;import lombok.extern.slf4j.Slf4j;import org.apache.commons.io.IOUtils;import org.springframework.beans.factory.annotation.Autowired;import java.io.*;import java.util.ArrayList;import java.util.List;@Slf4j@Servicepublic class AutoNumberingServiceImpl implements AutoNumberingService { @Autowired private AutoNumberingMapper autoNumberingMapper ; /** * 自动编号方法 * * @param param 自动编号枚举值 * @return 编号 */ @Transactional public String getNextNo(AutoNumberingEnum param) { // 查找当前的采番配置信息 LambdaQueryWrapper&lt;AutoNumbering&gt; wrapper = new LambdaQueryWrapper&lt;&gt;(); wrapper.eq(AutoNumbering::getName, param.getName()); List&lt;AutoNumbering&gt; AutoNumberings = AutoNumberingMapper.selectList(wrapper); // 未获取到配置信息 if (AutoNumberings.isEmpty()) { return null; } else { // 规则获取 AutoNumbering autoNumbering = AutoNumberings.get(0); // 前缀 String prefix = autoNumbering.getPrefix(); // 长度 Integer length = autoNumbering.getLength(); // 顺番 Long currentNo = autoNumbering.getCurrentValue(); // 更新原数据 currentNo++; } autoNumbering.setCurrentValue(currentNo); AutoNumberingMapper.updateById(autoNumbering); // 生成编号 String formatNo = StringUtils.leftPad(String.valueOf(currentNo), length, &quot;0&quot;); return String.format(&quot;%s%s&quot;, prefix, formatNo); } } 四、写一个Utils类静态获取编号language-java123456789101112131415161718192021222324252627282930313233import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Component;@Componentpublic class NoGeneratorUtil { private static AutoNumberingService autoNumberingService; @Autowired public void setAutoNumberingService(AutoNumberingService autoNumberingService) { NoGeneratorUtil.autoNumberingService = autoNumberingService; } /** * 获取最新的入库单编号 * @return 最新的入库单编号 */ public static String getNextStockInputNo() { return autoNumberingService.getNextNo(AutoNumberingEnum.STOCK_INPUT); } /** * 获取最新的产品编号 * @return 最新的c'p 编号 */ public static String getNextProductNo() { return autoNumberingService.getNextNo(AutoNumberingEnum.PRODUCT_CODE); } 这段代码是SpringBoot框架中的一种常见用法，用于将SpringBoot管理的bean注入到静态变量中。那么，autoNumberingService是如何被注入的呢？实际上，当SpringBoot启动时，它会扫描所有的类，并为带有@Component（或者@Service等）注解的类创建实例。在创建NoGeneratorUtil实例的过程中，SpringBoot会调用所有带有@Autowired注解的setter方法，包括setAutoNumberingService方法，从而将AutoNumberingService的实现类注入到autoNumberingService静态变量中。 五、使用之后如下使用即可一行代码获取最新编号 language-java12String string1 = NoGeneratorUtil.getNextStockInputNo();String string2 = NoGeneratorUtil.getNextProductNo();","link":"/Hexo/2023/11/24/2023-H2/2023-11-24-09-29-25/"},{"title":"JavaWeb若依分页插件使用","text":"后端只需要在你本身的contoller调用service取得数据那条命令前后加上2行代码，就可以使用mybatis的分页插件。 language-java12345678@GetMapping(&quot;move/search&quot;)public AjaxResult moveSearch(StockMoveSearchDTO dto){ startPage();//第一句 List&lt;BztStockMoveHeadExp&gt; list = stockMgntService.moveSearch(dto);//这是自己本身的逻辑代码 TableDataInfo dataTable = getDataTable(list);//第二句 return success(dataTable);} 整体看起来，startPage像是加载了某些配置，然后基于这些配置getDataTable对你本来的逻辑进行了修改，实现了分页排序效果。 1.原理解析ctrl左键点击startPage()，两次追溯源码实现，可以看到以下代码 language-java12345678910public static void startPage(){ PageDomain pageDomain = TableSupport.buildPageRequest(); Integer pageNum = pageDomain.getPageNum(); Integer pageSize = pageDomain.getPageSize(); String orderBy = SqlUtil.escapeOrderBySql(pageDomain.getOrderBy()); Boolean reasonable = pageDomain.getReasonable(); PageHelper.startPage(pageNum, pageSize, orderBy).setReasonable(reasonable);} PageHelper.startPage(pageNum, pageSize, orderBy)是myabtis的分页插件， 第一个参数是当前页码 第二个参数是每一页数量 第三个参数是排序信息，包括排序列和排序顺序 PageHelper会拦截你的sql代码然后加上类似limit ，order by等语句实现所谓的分页排序查询，数据截取是在sql中完成的，很快，所以你不必担心这个插件是不是在数据选完之后再分割导致性能问题。 那么问题来了，pageNum, pageSize, orderBy这三个参数从哪里来？毋庸置疑，肯定是从前端来，但是却不需要你写在dto中，因为若依会从你传到后端的数据中截取这三个参数。ctrl左键点击buildPageRequest()，追溯源码实现，你会看到以下代码。 language-java1234567891011121314151617public static PageDomain getPageDomain(){ PageDomain pageDomain = new PageDomain(); pageDomain.setPageNum(Convert.toInt(ServletUtils.getParameter(PAGE_NUM), 1)); pageDomain.setPageSize(Convert.toInt(ServletUtils.getParameter(PAGE_SIZE), 10)); pageDomain.setOrderByColumn(ServletUtils.getParameter(ORDER_BY_COLUMN)); pageDomain.setIsAsc(ServletUtils.getParameter(IS_ASC)); pageDomain.setReasonable(ServletUtils.getParameterToBool(REASONABLE)); return pageDomain;}public static PageDomain buildPageRequest(){ return getPageDomain();} 大概意思就是会从你传到后端的数据从截取以下字段 pageNum pageSize orderByColumn isAscorderby由后两个字段组成。所以在你前端传到后端的数据中，添加这4个字段和值即可实现分页效果和排序效果。 2. 前端示例language-html123456789101112131415161718192021222324252627282930313233343536373839404142&lt;template&gt;&lt;el-table :data=&quot;tableList&quot; @sort-change=&quot;handleSortChange&quot;&gt; &lt;el-table-column prop=&quot;formCreateTime&quot; label=&quot;录入日期&quot; sortable=&quot;custom&quot; :sort-orders=&quot;['ascending', 'descending']&quot; &gt; &lt;template #default=&quot;scope&quot;&gt; { { new Date(scope.row.formCreateTime).toLocaleDateString() }} &lt;/template&gt; &lt;/el-table-column&gt;&lt;/template&gt;&lt;script setup&gt;const queryParams = reactive({ pageNum: undefined, pageSize: undefined, orderByColumn: 'formCreateTime', isAsc: 'descending',})const tableList = ref([])const handleSortChange=(column)=&gt;{ queryParams.orderByColumn = column.prop; queryParams.isAsc = column.order; onSubmitQuiet();}const onSubmitQuiet = () =&gt; { queryParams.pageNum = 1; queryParams.pageSize = 10; moveSearch(queryParams).then(rp =&gt; { // console.log(rp) tableList.value = rp.data.rows; pageTotal.value = rp.data.total; })}&lt;/script&gt; 这是一个简单的表格，只包含一列，当点击这一列表头时，触发handleSortChange，更新orderByColumn 和isAsc 然后重新从后端查询一遍，注意用Get方式。pageNum 和pageSize 可以通过el-pagination组件更新，这里就不写了。后端返回值包含rows表示具体数据是一个list，total表示数据量。需要注意的时传给后端的orderByColumn所代表的字符串（这里是formCreateTime）应该和后端对应domain对应的变量名一致。 3. 后端示例language-java12345678@GetMapping(&quot;move/search&quot;)public AjaxResult moveSearch(StockMoveSearchDTO dto){ startPage(); List&lt;BztStockMoveHeadExp&gt; list = stockMgntService.moveSearch(dto); TableDataInfo dataTable = getDataTable(list); return success(dataTable);} 其中List&lt;BztStockMoveHeadExp&gt; list = stockMgntService.moveSearch(dto);只需按照原来的逻辑写就行，不需要考虑分页或者排序。","link":"/Hexo/2023/11/27/2023-H2/2023-11-27-11-32-08/"},{"title":"基本正则表达式","text":"正则表达式在线测试https://c.runoob.com/front-end/854/ 一、基本规则1. 基本匹配正则表达式最基本的形式是一个由字母和数字组成的序列。这个序列可以精确匹配文本中的内容。 表达式 描述 abc 精确匹配 ‘abc’ 2. 量词量词定义了一个模式应该出现的次数。 表达式 描述 * 匹配前面的模式零次或多次 + 匹配前面的模式一次或多次 ? 匹配前面的模式零次或一次 {n} 匹配前面的模式 n 次 {n,} 匹配前面的模式至少 n 次 {n,m} 匹配前面的模式至少 n 次，但不超过 m 次 * 和 + 限定符都是贪婪的，因为它们会尽可能多的匹配文字，只有在它们的后面加上一个 ? 就可以实现非贪婪或最小匹配。 3. 字符类字符类允许我们定义一个字符集合，然后匹配其中任何一个字符。 表达式 描述 [abc] 匹配 ‘a’、’b’ 或 ‘c’ [a-z] 匹配任何小写字母 [A-Z] 匹配任何大写字母 [0-9] 匹配任何数字 4. 特殊字符含有特殊含义的字符 表达式 描述 \\ 将下一个字符标记为一个特殊字符、或一个原义字符、或一个 向后引用、或一个八进制转义符。例如，’n’ 匹配字符 “n”。’\\n’ 匹配一个换行符。序列 ‘\\‘ 匹配 “” 而 “(“ 则匹配 “(“。 . 匹配任何单个字符（除了换行符\\n） \\w 匹配任何单词字符（等同于 [a-zA-Z0-9_]） \\W 匹配任何非单词字符 \\d 匹配任何数字字符（等同于 [0-9]） \\D 匹配任何非数字字符 \\s 匹配任何空白字符 \\S 匹配任何非空白字符 \\n 匹配一个换行符 \\r 匹配一个回车符 \\t 匹配一个制表符 ^ 匹配输入字符串开始的位置 $ 匹配输入字符串结尾的位置 \\b 匹配一个单词边界，即字与空格间的位置 \\B 匹配一个非单词边界 5. 分组在正则表达式中，括号 () 用于创建一个分组。分组有两个主要的用途：捕获分组 ：括号中的表达式会作为一个单独的单元进行匹配，然后将匹配的内容保存起来以供后续使用。例如，表达式 (abc) 会匹配文本中的 ‘abc’，并将其保存为一个分组。量词应用：括号还可以让我们对一组字符应用量词。例如，表达式 (abc){2} 会匹配 ‘abcabc’，因为 {2} 量词应用于整个 ‘abc’ 分组，表示这个分组需要连续匹配两次。 以下是一些使用括号的例子：(abc)：匹配并捕获 ‘abc’。a(bc)：匹配并捕获 ‘bc’，前面有 ‘a’。(a|b)c：匹配 ‘ac’ 或 ‘bc’。 在正则表达式中，你可以通过反向引用来使用捕获到的内容。反向引用使用反斜杠 \\ 加上一个数字来表示，例如 \\1、\\2 等。这个数字表示的是捕获组的编号。捕获组的编号是根据左括号 ( 出现的顺序来确定的，从 1 开始计数。例如，在表达式 (a)(b)(c) 中，a 是第 1 组，b 是第 2 组，c 是第 3 组。 以下是一些使用反向引用的例子：(a)\\1：匹配 ‘aa’。\\1 是对第一组的引用，表示和第一组匹配的相同内容，也就是 ‘a’。(a)(b)\\2\\1：匹配 ‘abba’。\\2 是对第二组的引用，表示 ‘b’，\\1 是对第一组的引用，表示 ‘a’。 二、修饰符标记也称为修饰符，正则表达式的标记用于指定额外的匹配策略。标记不写在正则表达式里，标记位于表达式之外，格式如 language-bash1/pattern/flags 修饰符 含义 描述 i ignore - 不区分大小写 将匹配设置为不区分大小写，搜索时不区分大小写，如 A 和 a 没有区别。 g global - 全局匹配 查找所有的匹配项。 m multi line - 多行匹配 使边界字符 ^ 和 $ 匹配每一行的开头和结尾，记住是多行，而不是整个字符串的开头和结尾。 s 特殊字符圆点 . 中包含换行符 \\n 默认情况下的圆点 . 是匹配除换行符 \\n 之外的任何字符，加上 s 修饰符之后, . 中包含换行符 \\n。 三、优先级正则表达式从左到右进行计算，并遵循优先级顺序，这与算术表达式非常类似。相同优先级的从左到右进行运算，不同优先级的运算先高后低。 运算符 描述 \\ 转义符 (), (?:), (?=), [] 圆括号和方括号 *, +, ?, {n}, {n,}, {n,m} 限定符 ^, $, \\任何元字符、任何字符 定位点和序列（即：位置和顺序） | 替换，”或”操作 字符具有高于替换运算符的优先级，使得”m|food”匹配”m”或”food”。若要匹配”mood”或”food”，请使用括号创建子表达式，从而产生”(m|f)ood”。","link":"/Hexo/2023/11/28/2023-H2/2023-11-28-18-03-58/"},{"title":"JavaWeb MyBatisPlus添加一个能够批量插入的Mapper通用方法","text":"众所周知，mybatisplus提供的BaseMapper里只有单条插入的方法，没有批量插入的方法，而在Service层的批量插入并不是真的批量插入，实际上是遍历insert，但也不是一次insert就一次IO，而是到一定数量才会去IO一次，性能不是很差，但也不够好。 怎么才能实现真正的批量插入呢？ 这里是mybatisplus官方的演示仓库，可以先去了解一下。 一、注册自定义通用方法流程 把自定义方法写到BaseMapper，因为没法改BaseMapper，所以继承一下它 language-java12345public interface MyBaseMapper&lt;T&gt; extends BaseMapper&lt;T&gt; { int batchInsert(@Param(&quot;list&quot;) List&lt;T&gt; entityList);} MyBaseMapper扩展了原有的BaseMapper，所以你之后的Mapper层都继承自MyBaseMapper而不是BaseMapper即可。 把通用方法注册到mybatisplus language-java1234567891011@Componentpublic class MySqlInjector extends DefaultSqlInjector { @Override public List&lt;AbstractMethod&gt; getMethodList(Class&lt;?&gt; mapperClass, TableInfo tableInfo) { List&lt;AbstractMethod&gt; defaultMethodList = super.getMethodList(mapperClass, tableInfo); defaultMethodList.add(new BatchInsert(&quot;batchInsert&quot;)); return defaultMethodList; }} 关键的一句在于defaultMethodList.add(new BatchInsert(&quot;batchInsert&quot;));，意为注册一个新的方法叫batchInsert，具体实现在BatchInsert类。 实现BatchInsert类 language-java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566public class BatchInsert extends AbstractMethod { public BatchInsert(String name) { super(name); } @Override public MappedStatement injectMappedStatement(Class&lt;?&gt; mapperClass, Class&lt;?&gt; modelClass, TableInfo tableInfo) { KeyGenerator keyGenerator = NoKeyGenerator.INSTANCE; SqlMethod sqlMethod = SqlMethod.INSERT_ONE; String columnScript = getAllInsertSqlColumn(tableInfo.getFieldList()); String valuesScript = SqlScriptUtils.convertForeach(LEFT_BRACKET + getAllInsertSqlProperty(&quot;item.&quot;, tableInfo.getFieldList()) + RIGHT_BRACKET, LIST, null, &quot;item&quot;, COMMA); String keyProperty = null; String keyColumn = null; // 表包含主键处理逻辑,如果不包含主键当普通字段处理 if (StringUtils.isNotBlank(tableInfo.getKeyProperty())) { if (tableInfo.getIdType() == IdType.AUTO) { /* 自增主键 */ keyGenerator = Jdbc3KeyGenerator.INSTANCE; keyProperty = tableInfo.getKeyProperty(); // 去除转义符 keyColumn = SqlInjectionUtils.removeEscapeCharacter(tableInfo.getKeyColumn()); } else if (null != tableInfo.getKeySequence()) { keyGenerator = TableInfoHelper.genKeyGenerator(methodName, tableInfo, builderAssistant); keyProperty = tableInfo.getKeyProperty(); keyColumn = tableInfo.getKeyColumn(); } } String sql = String.format(sqlMethod.getSql(), tableInfo.getTableName(), columnScript, valuesScript); SqlSource sqlSource = super.createSqlSource(configuration, sql, modelClass); return this.addInsertMappedStatement(mapperClass, modelClass, methodName, sqlSource, keyGenerator, keyProperty, keyColumn); } /** * 获取 insert 时所有列名组成的sql片段 * @param fieldList 表字段信息列表 * @return sql 脚本片段 */ private String getAllInsertSqlColumn(List&lt;TableFieldInfo&gt; fieldList) { return LEFT_BRACKET + fieldList.stream() .map(TableFieldInfo::getColumn).filter(Objects::nonNull).collect(joining(COMMA + NEWLINE)) + RIGHT_BRACKET; } /** * 获取 insert 时所有属性值组成的sql片段 * @param prefix 前缀 * @param fieldList 表字段信息列表 * @return sql 脚本片段 */ private String getAllInsertSqlProperty(final String prefix, List&lt;TableFieldInfo&gt; fieldList) { final String newPrefix = prefix == null ? EMPTY : prefix; return fieldList.stream() .map(i -&gt; i.getInsertSqlProperty(newPrefix).replace(&quot;,&quot;, &quot;&quot;)) .filter(Objects::nonNull) .collect(joining(COMMA + NEWLINE)); }} 二、BatchInsert具体实现逻辑解析以如下简单的表user举例， 列名 描述 类型 id 主键,自增 bigint user_name 用户名 varchar(64) user_age 用户年龄 int 对于的entity大抵如下 language-java1234567891011@Data@EqualsAndHashCode(callSuper = true)@Accessors(chain = true)@TableName(&quot;user&quot;)public class User{ @TableId(value = &quot;id&quot;, type = IdType.AUTO) private Long id; private String userName; private int userAge;} 那么对于batchInsert，我们希望传入List&lt;User&gt;并希望得到类似如下的mybtaisplus xml sql语句 language-xml1234567891011121314&lt;insert id=&quot;batchInsert&quot; parameterType=&quot;java.util.List&quot;&gt; insert into user( id, user_name, user_age )values &lt;foreach collection=&quot;list&quot; item=&quot;item&quot; separator=&quot;,&quot;&gt; ( #{item.id}, #{item.userName}, #{item.userAge} ) &lt;/foreach&gt;&lt;/insert&gt; 但是我们并不自己写这个xml，不然这需要对每一个数据表都要写一个，就像不那么硬的硬代码一样，我们希望有段逻辑，只需要传入entity，就能自己解析其中列名和对应的属性名，生成这段xml实现批量插入的功能。 假设你的UserMapper已经继承自MyBaseMapper，如果调用UserMapper.bacthInsert(List&lt;User&gt; entityList)，那么会进入这个函数 language-java12@Overridepublic MappedStatement injectMappedStatement(Class&lt;?&gt; mapperClass, Class&lt;?&gt; modelClass, TableInfo tableInfo) 其中mapperClass是映射器类，modelClass是模型类，我们并不需要了解，最主要的是tableInfo，这是表信息，它包含了关于数据库表的各种信息，如表名、列名、主键等。这个参数提供了详细的表信息，这对于生成针对特定表的SQL语句是必要的。 然后执行如下 language-java1234567//如果你的表名没有主键，那么你需要指定keyGenerator 为NoKeyGenerator，//因为重写injectMappedStatement最后需要返回return this.addInsertMappedStatement//其中就需要KeyGenerator KeyGenerator keyGenerator = NoKeyGenerator.INSTANCE;//SqlMethod.INSERT_ONE就是&quot;INSERT INTO %s %s VALUES %s&quot;//我们依据表的信息生成列名sql片段和属性名sql片段后填入%s就可以得到近似最后的xml sqlSqlMethod sqlMethod = SqlMethod.INSERT_ONE; 然后执行如下 language-java123456789101112131415161718//tableInfo.getFieldList()会得到一个包含数据表列信息(不包含主键)的TableFieldInfo类组成的ListString columnScript = getAllInsertSqlColumn(tableInfo.getFieldList());//这行代码就是在调用这个函数private String getAllInsertSqlColumn(List&lt;TableFieldInfo&gt; fieldList) { return LEFT_BRACKET + fieldList.stream() //从TableFieldInfo中只拿取列名 .map(TableFieldInfo::getColumn) //过滤null .filter(Objects::nonNull) //在元素间以逗号和分行分割 .collect(joining(COMMA + NEWLINE)) + RIGHT_BRACKET;}//对于User表，这个函数返回以下String/*(user_name,user_age)*/ 然后执行如下 language-java12345678910111213141516171819202122232425262728293031323334353637383940414243//首先调用了getAllInsertSqlPropertyString valuesScript = SqlScriptUtils.convertForeach( // 这也是个内置函数，可以直接去看看 LEFT_BRACKET + getAllInsertSqlProperty(&quot;item.&quot;, tableInfo.getFieldList()) + RIGHT_BRACKET, LIST, null, &quot;item&quot;, COMMA);//LEFT_BRACKET + getAllInsertSqlProperty(&quot;item.&quot;, tableInfo.getFieldList()) + RIGHT_BRACKET//得到/*(#{userName},#{userAge})*///经过convertForeach函数后，得到如下字符串/*&lt;foreach collection=&quot;list&quot; item=&quot;item&quot; separator=&quot;,&quot;&gt;(#{userName},#{userAge}) &lt;/foreach&gt;*///getAllInsertSqlProperty函数如下private String getAllInsertSqlProperty(final String prefix, List&lt;TableFieldInfo&gt; fieldList) { //这里newPrefix 就是&quot;item.&quot; final String newPrefix = prefix == null ? EMPTY : prefix; return fieldList.stream() //i.getInsertSqlProperty(&quot;item.&quot;)是内置函数，假设i现在遍历到了user_name列 //那么得到的就是&quot;#{userName},&quot; //然后,被删了 //所以本来每个元素从TableFieldInfo变成了形如&quot;#{userName}&quot;的字符串 .map(i -&gt; i.getInsertSqlProperty(newPrefix).replace(&quot;,&quot;, &quot;&quot;)) .filter(Objects::nonNull) //在元素间插入逗号和分行 .collect(joining(COMMA + NEWLINE));}//对于User表，这个函数返回以下String/*#{userName},#{userAge}*/ 然后执行如下 language-java1234567891011121314151617181920212223 //定义主键属性名 String keyProperty = null; //定义主键列名 String keyColumn = null; // 表包含主键处理逻辑,如果不包含主键当普通字段处理 if (StringUtils.isNotBlank(tableInfo.getKeyProperty())) { if (tableInfo.getIdType() == IdType.AUTO) { /* 自增主键 */ keyGenerator = Jdbc3KeyGenerator.INSTANCE; keyProperty = tableInfo.getKeyProperty(); // 去除转义符 keyColumn = SqlInjectionUtils.removeEscapeCharacter(tableInfo.getKeyColumn()); } else if (null != tableInfo.getKeySequence()) { keyGenerator = TableInfoHelper.genKeyGenerator(methodName, tableInfo, builderAssistant); keyProperty = tableInfo.getKeyProperty(); keyColumn = tableInfo.getKeyColumn(); } }//这段代码没什么好说的，就是根据不同情况，得到三个变量//keyGenerator keyProperty keyColumn 然后执行如下 language-java123456789String sql = String.format(sqlMethod.getSql(), tableInfo.getTableName(), columnScript, valuesScript);//就是把表名user，列名片段，属性名片段，填入%s中，得到如下/*INSERT INTO user (user_name,user_age) VALUES &lt;foreach collection=&quot;list&quot; item=&quot;item&quot; separator=&quot;,&quot;&gt;(#{userName},#{userAge}) &lt;/foreach&gt;*/ 然后执行如下 language-java1234//这两句没有什么可说的，是重写injectMappedStatement函数的必要的操作//自定义的内容就在于sql和主键SqlSource sqlSource = super.createSqlSource(configuration, sql, modelClass);return this.addInsertMappedStatement(mapperClass, modelClass, methodName, sqlSource, keyGenerator, keyProperty, keyColumn);","link":"/Hexo/2023/12/01/2023-H2/2023-12-01-14-49-31/"},{"title":"Docker部署Nacos集群并用nginx反向代理负载均衡","text":"首先找到Nacos官网给的Github仓库，里面有docker compose可以快速启动Nacos集群。 一. 脚本概况我们要运行的脚本是example/cluster-hostname.yaml，可以看到里面包含了来自外界的${NACOS_VERSION}和加载外界env文件的env_file条目，于是我们可以找到本yaml所依赖的以下文件列表： example/.env env/mysql.env env/nacos-hostname.env 二. 自定义修改1. example/cluster-hostname.yaml找到mysql-healthcheck-test修改为 language-yaml123mysql: healthcheck: test: [ &quot;CMD&quot;, &quot;mysqladmin&quot; ,&quot;ping&quot;, &quot;-h&quot;, &quot;localhost&quot;, &quot;-u&quot;, &quot;root&quot;, &quot;-p${MYSQL_ROOT_PASSWORD}&quot; ] 这样做的原因是防止mysql容器测试时一直报错Access denied(password: No) 2. example/.env在后面运行docker compose时，会加载这个文件为环境变量，填入${NACOS_VERSION}和${MYSQL_ROOT_PASSWORD}。 language-bash12NACOS_VERSION=v2.3.0MYSQL_ROOT_PASSWORD=1009 NACOS_VERSION的版本选多少可以参考Nacos官方的对照表。 官方指出Nacos有一定向下兼容性，所以选择新一点的Nacos版本也没问题，同时，某些版本的Nacos已被指出存在部分问题。 MYSQL_ROOT_PASSWORD为数据库root密码。 3. env/mysql.env这是cluster-hostname.yaml中mysql容器使用的env_file language-bash12345MYSQL_ROOT_PASSWORD=1009MYSQL_DATABASE=nacosMYSQL_USER=nacosMYSQL_PASSWORD=nacosLANG=C.UTF-8 MYSQL_ROOT_PASSWORD为数据库root密码，和上面那个保持一致MYSQL_DATABASE为数据库名称MYSQL_USER为数据库用户名MYSQL_PASSWORD为用户(nacos)密码 4. env/nacos-hostname.env这是cluster-hostname.yaml中3个nacos容器使用的env_file language-bash123456789101112PREFER_HOST_MODE=hostnameNACOS_SERVERS=nacos1:8848 nacos2:8848 nacos3:8848SPRING_DATASOURCE_PLATFORM=mysqlMYSQL_SERVICE_HOST=mysqlMYSQL_SERVICE_DB_NAME=nacosMYSQL_SERVICE_PORT=3306MYSQL_SERVICE_USER=nacosMYSQL_SERVICE_PASSWORD=nacosMYSQL_SERVICE_DB_PARAM=characterEncoding=utf8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=true&amp;useSSL=false&amp;allowPublicKeyRetrieval=trueNACOS_AUTH_IDENTITY_KEY=2222NACOS_AUTH_IDENTITY_VALUE=2xxxNACOS_AUTH_TOKEN=SecretKey012345678901234567890123456789012345678901234567890123456789 关于docker nacos的环境变量，可以参考Nacos官方给的一张表格。 为什么NACOS_SERVERS填的是nacos1，nacos2，nacos3，不是具体的ip地址？为什么MYSQL_SERVICE_HOST(数据库连接地址)填的是”mysql”？同时MYSQL_SERVICE_PORT应该填mysql容器的端口还是映射到主机的端口？因为三个nacos容器和一个mysql在一个docker compose文件里，也就是cluster-hostname.yaml，那么在运行这个yaml文件时，docker会默认把这个yaml里所有的容器放到一个新的bridge网络中，于是，四个容器可以通过它们在这个bridge网络里的ip互相访问，同时也可以通过hostname互相访问，如果没有指明hostname，那么默认就是服务的名称(services)，比如mysql的就是mysql。同时这四个容器之间互相访问的端口是容器开放的端口，而不是映射到主机的端口。 三、运行在根目录运行docker-compose -f example/cluster-hostname.yaml up然后浏览器就可以访问localhost:port/nacos，port是三个nacos的8848端口映射到主机的三个端口之一。 四、nginx反向代理，负载均衡docker pull nginx:stable下载nginx的稳定版镜像然后用这个镜像随便启动一个容器，把里面的以下文件copy到主机，修改后做-v映射。 /etc/nginx/nginx.conf /etc/nginx/conf.d/default.conf 1. 配置文件修改其中nginx.conf无需修改default.conf参考以下示例 language-bash12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758upstream nacos-cluster { server 172.29.0.3:8848; server 172.29.0.4:8848; server 172.29.0.5:8848;}server { listen 80; listen [::]:80; server_name localhost; #access_log /var/log/nginx/host.access.log main; location / { proxy_pass http://nacos-cluster; # root /usr/share/nginx/html; # index index.html index.htm; } #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html { root /usr/share/nginx/html; } # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # #location ~ \\.php$ { # proxy_pass http://127.0.0.1; #} # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \\.php$ { # root html; # fastcgi_pass 127.0.0.1:9000; # fastcgi_index index.php; # fastcgi_param SCRIPT_FILENAME /scripts$fastcgi_script_name; # include fastcgi_params; #} # deny access to .htaccess files, if Apache's document root # concurs with nginx's one # #location ~ /\\.ht { # deny all; #}} 主要注意两个地方，一个是 language-bash123456upstream nacos-cluster { server 172.29.0.3:8848; server 172.29.0.4:8848; server 172.29.0.5:8848;} 这里面写明了3个nacos容器的ip和端口，其中ip是它们处于docker bridge小局域网中的ip，以及port也是容器服务的端口，这是因为我们最后会把nginx容器也加入这个bridge网络。 用以下命令查看三个nacos的ip language-bash1234567891011C:\\Users\\mumu\\IdeaProjects\\nacos-docker&gt;docker network lsNETWORK ID NAME DRIVER SCOPEfdfe3fcab913 bigdata bridge local45d79fa3e39e bridge bridge local2d784bdacaa1 example_default bridge local83b9f11eccaa host host locald138886a8b5b none null localC:\\Users\\mumu\\IdeaProjects\\nacos-docker&gt;docker network inspect example_default[ .....] 另一个是 language-bash123456location / { proxy_pass http://nacos-cluster; # root /usr/share/nginx/html; # index index.html index.htm;} 这里的意思是把/的url请求(/的话基本就是所有请求了)全部转发到上面定义的upstream nacos-cluster服务器集群中。这里默认是以轮询作为负载均衡的策略。 language-bash12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849！！！分配方式 Nginx的upstream支持5种分配方式，下面将会详细介绍，其中，前三种为Nginx原生支持的分配方式，后两种为第三方支持的分配方式： 1、轮询 轮询是upstream的默认分配方式，即每个请求按照时间顺序轮流分配到不同的后端服务器，如果某个后端服务器down掉后，能自动剔除。 upstream backend { server 192.168.200.131:8848; server 192.168.200.131:8849; server 192.168.200.131:8850; }2、weight 轮询的加强版，即可以指定轮询比率，weight和访问几率成正比，主要应用于后端服务器异质的场景下。 upstream backend { server 192.168.200.131:8848 weight=1; server 192.168.200.131:8849 weight=2; server 192.168.200.131:8850 weight=3; }3、ip_hash 每个请求按照访问ip（即Nginx的前置服务器或者客户端IP）的hash结果分配，这样每个访客会固定访问一个后端服务器，可以解决session一致问题。 upstream backend { ip_hash; server 192.168.200.131:8848; server 192.168.200.131:8849; server 192.168.200.131:8850; }4、fair fair顾名思义，公平地按照后端服务器的响应时间（rt）来分配请求，响应时间短即rt小的后端服务器优先分配请求。 upstream backend { server 192.168.200.131:8848; server 192.168.200.131:8849; server 192.168.200.131:8850; fair; }5、url_hash 与ip_hash类似，但是按照访问url的hash结果来分配请求，使得每个url定向到同一个后端服务器，主要应用于后端服务器为缓存时的场景下。 upstream backend { server 192.168.200.131:8848; server 192.168.200.131:8849; server 192.168.200.131:8850; hash $request_uri; hash_method crc32; } 其中，hash_method为使用的hash算法，需要注意的是：此时，server语句中不能加weight等参数。 2. 运行参考以下命令运行(cmd版) language-bash12345678docker run -id --name=nacos_nginx ^-p 80:80 ^-v C:\\Users\\mumu\\IdeaProjects\\nacos-docker\\nginx\\nginx.conf:/etc/nginx/nginx.conf ^-v C:\\Users\\mumu\\IdeaProjects\\nacos-docker\\nginx\\conf.d\\default.conf:/etc/nginx/conf.d/default.conf ^-v C:\\Users\\mumu\\IdeaProjects\\nacos-docker\\nginx\\logs:/var/log/nginx ^-v C:\\Users\\mumu\\IdeaProjects\\nacos-docker\\nginx\\html:/usr/share/nginx/html ^--network example_default ^nginx:stable 最后，访问localhost/nacos就可以访问nginx，nginx会通过负载均衡的策略将你的请求重定向到nacos集群中的某一个。","link":"/Hexo/2023/12/09/2023-H2/2023-12-09-21-11-12/"},{"title":"Vue3引用外部TTF字体，其实很简单！","text":"一、下载字体这里推荐一个网站字体天下 二、引入TTF字体 将已有的xx.ttf按照如下示例放入assets文件夹下 并且同级目录创建fonts.css写入以下内容 language-bash1234567@font-face { font-family: 'my-self-font'; src: url('./XiangJiaoDaJiangJunLingGanTi-2.ttf'); font-weight: normal; font-style: normal;} 其中font-family: 'my-self-font';就是你自定义字体的名字 在main.js引入fonts.css language-bash1import './assets/fonts/fonts.css' 三、使用字体language-html1&lt;span style=&quot;font-family: my-self-font&quot;&gt;你好啊&lt;/span&gt;","link":"/Hexo/2023/12/09/2023-H2/2023-12-09-21-49-48/"},{"title":"用Vue3+ElementPlus实现了一个CSS字体在线展示工具","text":"Vite App (xiamu-ssr.github.io)https://xiamu-ssr.github.io/FontFamilyCode/","link":"/Hexo/2023/12/10/2023-H2/2023-12-10-11-00-06/"},{"title":"Docker Compose怎么保证其他服务在Nacos完全启动后再启动","text":"首先，docker compose有一个关键字depends_on是可以一定程度解决services之间的依赖问题，但是depends_on仅仅只是指定了services的启动顺序，并不能保证，前置service完全启动后，后置service才启动。 此时，需要另一个关键字叫healthcheck。 样例nacos版本为v2.3.0 language-yaml1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556 mysql_nacos: container_name: mysql_nacos build: context: . dockerfile: ./image/mysql/5.7/Dockerfile image: example/mysql:5.7 env_file: - ../env/mysql.env volumes: - ./mysql:/var/lib/mysql# ports:# - &quot;3307:3306&quot; healthcheck: test: [ &quot;CMD&quot;, &quot;mysqladmin&quot; ,&quot;ping&quot;, &quot;-h&quot;, &quot;localhost&quot;, &quot;-u&quot;, &quot;root&quot;, &quot;-p${MYSQL_ROOT_PASSWORD}&quot; ] interval: 10s timeout: 10s retries: 10 nacos1: hostname: nacos1 container_name: nacos1 image: nacos/nacos-server:${ NACOS_VERSION} volumes: - ./cluster-logs/nacos1:/home/nacos/logs# ports:# - &quot;7848:7848&quot;# - &quot;8845:8848&quot;# - &quot;9868:9848&quot;# - &quot;9850:9849&quot; env_file: - ../env/nacos-hostname.env# restart: always healthcheck: test: [ &quot;CMD&quot;, &quot;curl&quot;, &quot;-f&quot;, &quot;http://localhost:8848/nacos/v1/console/health/readiness&quot; ] interval: 10s timeout: 10s retries: 10 depends_on: mysql_nacos: condition: service_healthy nginx_nacos: hostname: nginx_nacos image: nginx:stable container_name: nginx_nacos volumes: - ../nginx_nacos/nginx.conf:/etc/nginx/nginx.conf - ../nginx_nacos/conf.d/default.conf:/etc/nginx/conf.d/default.conf - ../nginx_nacos/logs:/var/log/nginx - ../nginx_nacos/html:/usr/share/nginx/html ports: - &quot;80:80&quot; depends_on: nacos1: condition: service_healthy 这是一个双层依赖，nginx_nacos依赖于nacos1，同时nacos1依赖于mysql_nacos。 mysql_nacos基于 healthcheck:test: [ &quot;CMD&quot;, &quot;mysqladmin&quot; ,&quot;ping&quot;, &quot;-h&quot;, &quot;localhost&quot;, &quot;-u&quot;, &quot;root&quot;, &quot;-p${MYSQL_ROOT_PASSWORD}&quot; ]来确认自己的健康状态，只有当test内容执行成功并返回状态码0，才会认为此service已完全执行成功。 同理nacos服务是基于healthcheck:test: [ &quot;CMD&quot;, &quot;curl&quot;, &quot;-f&quot;, &quot;http://localhost:8848/nacos/v1/console/health/readiness&quot; ]来判断健康状态的。","link":"/Hexo/2023/12/12/2023-H2/2023-12-12-12-23-27/"},{"title":"云服务器部署可视化Docker私有仓库（Ubuntu）","text":"这里测试的机器为ubuntu22.04 一、环境安装docker安装就不赘述了先升级，再从官方仓库安装docker compose language-bash123apt updateapt upgradeapt install docker-compose 二、部署私有仓库UIDocker提供了一个叫registry的镜像，给大家搭建私有仓库，但是没有可视化界面。https://hub.docker.com/r/joxit/docker-registry-ui这个镜像在registry基础之上，开发了网页可视化。 1. 创建一个文件夹Docker_Registry2. 进入其中继续创建registry-data文件夹和docker-compose.yaml文件3. yaml文件language-yaml12345678910111213141516171819202122232425262728293031323334353637version: '3.8'services: registry-ui: image: joxit/docker-registry-ui:main restart: always ports: - 8090:80 #这里8090改成可视化网页服务端口 environment: - SINGLE_REGISTRY=true - REGISTRY_TITLE=Xiamu Docker Registry UI #这里可以修改标题 - DELETE_IMAGES=true - SHOW_CONTENT_DIGEST=true - NGINX_PROXY_PASS_URL=http://registry-server:5000 - SHOW_CATALOG_NB_TAGS=true - CATALOG_MIN_BRANCHES=1 - CATALOG_MAX_BRANCHES=1 - TAGLIST_PAGE_SIZE=100 - REGISTRY_SECURED=false - CATALOG_ELEMENTS_LIMIT=1000 container_name: registry-ui depends_on: - registry-server registry-server: image: registry:2.8.2 restart: always environment: REGISTRY_HTTP_HEADERS_Access-Control-Origin: '[http://your_server_ip]' # 这里改成你的云服务ip，启用CORS REGISTRY_HTTP_HEADERS_Access-Control-Allow-Methods: '[HEAD,GET,OPTIONS,DELETE]' REGISTRY_HTTP_HEADERS_Access-Control-Credentials: '[true]' REGISTRY_HTTP_HEADERS_Access-Control-Allow-Headers: '[Authorization,Accept,Cache-Control]' REGISTRY_HTTP_HEADERS_Access-Control-Expose-Headers: '[Docker-Content-Digest]' REGISTRY_STORAGE_DELETE_ENABLED: 'true' volumes: - ./registry-data:/var/lib/registry container_name: registry-server 4. 部署进入Docker_Registry目录，执行 language-bash1docker-compose -f ./docker-compose.yaml up 三、访问通过http://your_server_ip:8090 访问UI 四、上传和拉取镜像打开vi /etc/docker/daemon.json添加以下内容： language-txt1&quot;insecure-registries&quot;:[&quot;http://your_server_ip:8090&quot;] 这样docker才会信任你的私有仓库。 假设你的服务器ip为192.168.750.101，port为8090推送镜像到私有镜像服务必须先tag,步骤如下: 重新tag本地镜像，名称前缀为私有仓库的地址: 192.168.150.101:8090/ language-dart1docker tag nginx:latest 192.168.150.101:8090/nginx:1.0 推送镜像 language-dart1docker push 192.168.150.101:8090/nginx:1.0 拉取镜像 language-dart1docker pull 192.168.150.101:8090/nginx:1.0","link":"/Hexo/2023/12/12/2023-H2/2023-12-12-15-39-39/"},{"title":"Docker单点部署[8.11.3] Elasticsearch + Kibana + ik分词器 + pinyin分词器","text":"这里记录一次成功简单登陆Kibana的实际经验。 一、Elasticsearch运行Elasticsearch容器 language-shell12345678910111213docker run -d \\ --name es \\ -e &quot;ES_JAVA_OPTS=-Xms512m -Xmx512m&quot; \\ -e &quot;discovery.type=single-node&quot; \\ -e &quot;xpack.security.enabled=true&quot; \\ -e &quot;xpack.security.enrollment.enabled=true&quot; \\ -v your_host_es_data_path:/usr/share/elasticsearch/data \\ #宿主机绝对路径挂载 -v your_host_es_plugins_path:/usr/share/elasticsearch/plugins \\ #宿主机绝对路径挂载 --privileged \\ --network es-net \\ -p 9200:9200 \\ -p 9300:9300 \\elasticsearch:8.11.3 重置elastic密码，记住这段密码 language-shell1docker exec -it es /usr/share/elasticsearch/bin/elasticsearch-reset-password -u elastic 重置kibana_system 密码，记住这段密码 language-shell1docker exec -it es /usr/share/elasticsearch/bin/elasticsearch-reset-password -u kibana_system 二、Kibana运行Kibana容器，账户密码填kibana_system 的 language-shell12345678docker run -d \\ --name kibana \\ -e ELASTICSEARCH_HOSTS=http://es:9200 \\ -e ELASTICSEARCH_USERNAME=kibana_system \\ -e ELASTICSEARCH_PASSWORD=kibana_system_passwrod \\ #刚才获得的kibana_system 密码 --network=es-net \\ -p 5601:5601 \\kibana:8.11.3 三、访问访问http://localhost:5601用elastic的账号密码登录。 四、其他关于一些报错 kibana容器创建时不允许用elastic用户连接elasticsearch 运行docker exec -it es01 /usr/share/elasticsearch/bin/elasticsearch-create-enrollment-token -s kibana报错SSL错误 等等各种因为使用了不是8.11.3版本的安全验证方法遇到的错误 这里是官方的install with docker教程，也是一坨shit。https://www.elastic.co/guide/en/kibana/current/docker.html 这里是官方关于安全配置的docs，遇到什么问题就多翻翻。https://www.elastic.co/guide/en/elasticsearch/reference/master/manually-configure-security.html 或者来社区多讨论讨论。https://discuss.elastic.co/latest 五、ik分词器这里是官方仓库https://github.com/medcl/elasticsearch-analysis-ik推荐有两种安装方式 第一种：在线安装language-bash12345678910# 进入容器内部docker exec -it es /bin/bash# 在线下载并安装#退出exit#重启容器docker restart esdocker restart kibana 如果遇到ik版本和es版本不匹配问题请看下面 第二种：离线安装 在发行版下载页面，找到和es版本最接近的ik版本(博主这里是ik8.11.1 + es8.11.3)https://github.com/medcl/elasticsearch-analysis-ik/releases 在您的 your_host_es_plugins_path 目录下，创建一个名为 ik 的新文件夹。 将下载的 elasticsearch-analysis-ik-8.11.1.zip 文件解压到刚刚创建的 ik 文件夹中 修改plugin-descriptor.properties文件 !如无需要请跳过，可能造成无法预估的bug language-bash12345678# 'version': plugin's versionversion=8.11.3# 'elasticsearch.version' version of elasticsearch compiled against# You will have to release a new version of the plugin for each new# elasticsearch release. This version is checked when the plugin# is loaded so Elasticsearch will refuse to start in the presence of# plugins with the incorrect elasticsearch.version.elasticsearch.version=8.11.3 重启容器 language-bash12docker restart esdocker restart kibana 安装好了之后，登录kinaba，找到Dev Tools - Console language-bash123456789101112131415#测试分词器GET /_analyze{ &quot;text&quot;:&quot;我爱吃冰淇淋，也喜欢小淇，i want to eat her&quot;, &quot;analyzer&quot;:&quot;ik_smart&quot;}#测试分词器GET /_analyze{ &quot;text&quot;:&quot;我爱吃冰淇淋，也喜欢小淇，i want to eat her&quot;, &quot;analyzer&quot;:&quot;ik_max_word&quot;} 这里的句子分词ik_smart和ik_max_word区别不明显，可以换用”程序员”试试。 六、ik分词器的扩展和停用1. 配置ik分词器并不能准确识别最新的网络流行词，以及禁用敏感词。我们可以手动配置来实现这两点。 修改IKAnalyzer.cfg.xml文件如下 language-xml1234567891011121314&lt;?xml version=&quot;1.0&quot; encoding=&quot;UTF-8&quot;?&gt;&lt;!DOCTYPE properties SYSTEM &quot;http://java.sun.com/dtd/properties.dtd&quot;&gt;&lt;properties&gt; &lt;comment&gt;IK Analyzer 扩展配置&lt;/comment&gt; &lt;!--用户可以在这里配置自己的扩展字典 --&gt; &lt;entry key=&quot;ext_dict&quot;&gt;ext.dic&lt;/entry&gt; &lt;!--用户可以在这里配置自己的扩展停止词字典--&gt; &lt;entry key=&quot;ext_stopwords&quot;&gt;stopword.dic&lt;/entry&gt; &lt;!--用户可以在这里配置远程扩展字典 --&gt; &lt;!-- &lt;entry key=&quot;remote_ext_dict&quot;&gt;words_location&lt;/entry&gt; --&gt; &lt;!--用户可以在这里配置远程扩展停止词字典--&gt; &lt;!-- &lt;entry key=&quot;remote_ext_stopwords&quot;&gt;words_location&lt;/entry&gt; --&gt;&lt;/properties&gt; 这里的意思是，使用同目录下的ext.dic作为扩展词汇；使用同目录下的stopword.dic作为禁用词汇。这两个文件有就用，没有就新建。 最后记得重启es容器 2. 测试language-bash1234567#测试分词器GET /_analyze{ &quot;text&quot;:&quot;程序员墨扛教育的课程可以白嫖啊，而且就业率高达95%哦，奥利给！嘤&quot;, &quot;analyzer&quot;:&quot;ik_smart&quot;} language-bash12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485{ &quot;tokens&quot;: [ { &quot;token&quot;: &quot;程序员&quot;, &quot;start_offset&quot;: 0, &quot;end_offset&quot;: 3, &quot;type&quot;: &quot;CN_WORD&quot;, &quot;position&quot;: 0 }, { &quot;token&quot;: &quot;墨扛教育&quot;, &quot;start_offset&quot;: 3, &quot;end_offset&quot;: 7, &quot;type&quot;: &quot;CN_WORD&quot;, &quot;position&quot;: 1 }, { &quot;token&quot;: &quot;课程&quot;, &quot;start_offset&quot;: 8, &quot;end_offset&quot;: 10, &quot;type&quot;: &quot;CN_WORD&quot;, &quot;position&quot;: 2 }, { &quot;token&quot;: &quot;可以&quot;, &quot;start_offset&quot;: 10, &quot;end_offset&quot;: 12, &quot;type&quot;: &quot;CN_WORD&quot;, &quot;position&quot;: 3 }, { &quot;token&quot;: &quot;白嫖&quot;, &quot;start_offset&quot;: 12, &quot;end_offset&quot;: 14, &quot;type&quot;: &quot;CN_WORD&quot;, &quot;position&quot;: 4 }, { &quot;token&quot;: &quot;而且&quot;, &quot;start_offset&quot;: 16, &quot;end_offset&quot;: 18, &quot;type&quot;: &quot;CN_WORD&quot;, &quot;position&quot;: 5 }, { &quot;token&quot;: &quot;就业率&quot;, &quot;start_offset&quot;: 18, &quot;end_offset&quot;: 21, &quot;type&quot;: &quot;CN_WORD&quot;, &quot;position&quot;: 6 }, { &quot;token&quot;: &quot;高达&quot;, &quot;start_offset&quot;: 21, &quot;end_offset&quot;: 23, &quot;type&quot;: &quot;CN_WORD&quot;, &quot;position&quot;: 7 }, { &quot;token&quot;: &quot;95&quot;, &quot;start_offset&quot;: 23, &quot;end_offset&quot;: 25, &quot;type&quot;: &quot;ARABIC&quot;, &quot;position&quot;: 8 }, { &quot;token&quot;: &quot;奥利给&quot;, &quot;start_offset&quot;: 28, &quot;end_offset&quot;: 31, &quot;type&quot;: &quot;CN_WORD&quot;, &quot;position&quot;: 9 } ]} 七、pinyin分词器离线安装 在发行版下载页面，找到和es版本最接近的版本(博主这里是pinyin8.11.1 + es8.11.3)https://github.com/medcl/elasticsearch-analysis-pinyin 在您的 your_host_es_plugins_path 目录下，创建一个名为 py 的新文件夹。 将下载的 elasticsearch-analysis-pinyin-8.11.1.zip 文件解压到刚刚创建的 py 文件夹中 修改plugin-descriptor.properties文件 !如无需要请跳过，可能造成无法预估的bug language-bash12345678# 'version': plugin's versionversion=8.11.3# 'elasticsearch.version' version of elasticsearch compiled against# You will have to release a new version of the plugin for each new# elasticsearch release. This version is checked when the plugin# is loaded so Elasticsearch will refuse to start in the presence of# plugins with the incorrect elasticsearch.version.elasticsearch.version=8.11.3 重启容器 language-bash12docker restart esdocker restart kibana 安装好了之后，登录kinaba，找到Dev Tools - Console language-bash1234567#测试分词器POST /_analyze{ &quot;text&quot;:&quot;如家酒店还不错&quot;, &quot;analyzer&quot;:&quot;pinyin&quot;} 注意事项pinyin分词器默认时有很多缺点，比如每个字都拆分变成拼音，不符合一般需求，并且如果使用pinyin分词器，默认的中文索引就没了，只剩下pinyin索引了。所以，需要完善以下几点： 分词时不仅包含汉字，还需包含拼音 分词时按词分，不是字 使用汉字查询时，不会查询到同音词条目docs 为了做到这几点，需要在创建索引库时构建一个自定义分词器，如下 language-json12345678910111213141516171819202122232425262728293031323334353637383940414243PUT /test{ &quot;settings&quot;: { &quot;analysis&quot;: { &quot;analyzer&quot;: { &quot;my_analyzer&quot;:{ &quot;tokenizer&quot;:&quot;ik_max_word&quot;, &quot;filter&quot;:&quot;py&quot; } }, &quot;filter&quot;: { &quot;py&quot;:{ &quot;type&quot;:&quot;pinyin&quot;, &quot;keep_full_pinyin&quot;:false, &quot;keep_joined_full_pinyin&quot;:true, &quot;keep_original&quot;:true, &quot;limit_first_letter_length&quot;:16, &quot;remove_duplicated_term&quot;:true, &quot;none_chinese_pinyin_tokenize&quot;:false } } } }, &quot;mappings&quot;: { &quot;properties&quot;: { &quot;name&quot;:{ &quot;type&quot;: &quot;text&quot;, &quot;analyzer&quot;: &quot;my_analyzer&quot;, &quot;search_analyzer&quot;: &quot;ik_smart&quot; } } }} 我们自定义了三步之中的tokenizer和filter，前者用ik分词，后者用pinyin分词，同时自定义了pinyin分词器的一些设置，分词时同时保留汉字和拼音，具体设置看pinyin分词器的github官网。同时设定了存入数据时使用分词器my_analyzer，搜索时，使用分词器ik_smart。 存入两个数据，如下 language-json12345678910111213POST /test/_doc/1{ &quot;id&quot;:1, &quot;name&quot;:&quot;狮子&quot;}POST /test/_doc/2{ &quot;id&quot;:2, &quot;name&quot;:&quot;虱子&quot;} 那么现在，索引库的具体内容如下所示因为搜索时使用的是ik_smart分词器，不是自定义分词器，所以这里已经解决了同音词的问题。","link":"/Hexo/2023/12/24/2023-H2/2023-12-24-20-01-28/"},{"title":"Kafka基础框架图推演","text":"1. 单点模型1. 名词概念 Broker：是指Kafka集群中的一个节点。一个Kafka集群由多个Broker组成，这些Broker共同协作来处理消息的存储、传输和消费。Broker管理一个或多个分区。 Topic：生产者将消息发送到指定的Topic，消费者订阅Topic以获取消息。Topic本身只是一个逻辑上的分组，不具有物理存储的概念。 Partition：是Topic的子集，是Kafka中实际存储和处理消息的基本单元。每个Topic可以分成多个Partition，每个Partition都是一个有序的、不可变的消息序列。 Replica：分区可以存在多副本。 Leader Broker：分区的多副本下，负责处理所有的读写请求的分区所处的broker。 FollowerBroker：分区的多副本下，负责同步Leader的数据的分区所处的broker。 生产者把消息（record）发送到kafka，消费者通过偏移量（offset，类似数组的下标）获取数据。 同时每个分区会有自己的Log文件，kafka使用log文件来把数据保存到磁盘。 2. 分布式集群-横向扩展1. Topic多分区 关于生产生产者通过Bootstrap Broker连接到Kafka集群。这一步是为了建立初始连接，并获取集群的元数据。 一旦生产者获取了这些元数据，它就知道每个分区的Leader Broker是谁，从而可以将消息直接发送到正确的Leader Broker。 生产者发送消息时必须指定Topic，但是分区是可选的。 不指定分区：如果生产者没有手动指定分区，Kafka会根据默认的分区策略将消息分配到分区。默认的分区策略如下： 如果消息有键（Key），Kafka会根据键的哈希值来确定分区。相同的键总是被分配到同一个分区。 如果消息没有键（Key），Kafka会使用轮询或随机的方式将消息分配到分区，以确保消息分布均匀。 指定分区：生产者也可以在发送消息时明确指定分区。这样，消息会直接发送到指定的分区。 在Kafka中，生产者将消息发送到Broker时，Broker的第一个操作就是将消息记录到磁盘中，以确保消息的持久性和可靠性。 关于消费Kafka中的消费者通常属于一个消费者组（Consumer Group）。每个消费者组有一个唯一的组ID。消费者组的概念用于实现消息的负载均衡和并行消费。 当多个消费者属于同一个组时，Kafka会将Topic的分区分配给组内的消费者。**每个分区只能由组内的一个消费者消费**，这样可以实现负载均衡。 单个消费者订阅一个Topic： 如果只有一个消费者订阅了一个Topic，那么该消费者会接收到该Topic中的所有消息。 多个消费者属于同一个组： Topic中的分区会在组内的消费者之间进行分配。每个分区只会被组内的一个消费者消费。 如果消费者数量多于分区数，多余的消费者将不会分配到任何分区，处于空闲状态。这些消费者可以在有其他消费者退出时自动接管其分区，从而实现高可用性。 如果消费者数量少于分区数，有些消费者会被分配多个分区。 多个消费者属于不同的组： 每个组都会独立消费Topic中的所有消息。也就是说，消息会被广播到所有组中的消费者。 关于分区新增Kafka会在集群中创建新的分区。这些新的分区会被分配到不同的Broker，以实现数据的均衡存储和高可用性。Kafka不会自动将现有分区的数据重新分配或均衡到新的分区。新的分区从创建时开始是空的，只有在后续生产者发送消息时，才会向这些新的分区写入数据。消费者组会感知到分区数量的变化，并触发重新平衡。 2. 分区多副本 Kafka允许每个分区有多个副本（Replica），这些副本存储在不同的Broker上。一个副本被称为Leader，负责处理所有的读写请求，其他副本为Follower，负责同步Leader的数据。 多个副本同时只有一个副本可以读写，这就是Leader副本，其他副本成为Follower副本，用作备份。","link":"/Hexo/2024/07/10/2024-H2/2024-07-10-20-47-43/"},{"title":"docker部署简单的Kafka","text":"1. 拉取镜像选择一组兼容性好的版本。 12docker pull bitnami/kafka:3.6.1docker pull bitnami/zookeeper:3.8.2 2. 运行创建网络首先，创建一个名为 kafka 的 Docker bridge 网络： 1docker network create kafka 运行 ZooKeeper 容器然后，运行 ZooKeeper 容器并将其连接到 kafka 网络： 1docker run -d --name zookeeper --network kafka -e ALLOW_ANONYMOUS_LOGIN=yes bitnami/zookeeper:3.8.2 运行 Kafka 容器最后，运行 Kafka 容器并将其连接到 kafka 网络： 1docker run -d --name kafka --network kafka -e KAFKA_BROKER_ID=1 -e KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181 -e ALLOW_PLAINTEXT_LISTENER=yes -e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092 -p 9092:9092 bitnami/kafka:3.6.1 这些命令将使 ZooKeeper 和 Kafka 容器在同一个 Docker 网络中运行，并确保它们可以相互通信。 3. 简单的校验要判断 ZooKeeper 和 Kafka 容器是否正常运行，可以通过以下几个步骤进行检查： 1. 检查容器状态首先，检查 ZooKeeper 和 Kafka 容器是否正在运行： 1docker ps 输出应包含类似以下内容： 123CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES&lt;zookeeper_id&gt; bitnami/zookeeper:3.8.2 &quot;/opt/bitnami/script…&quot; &lt;some_time_ago&gt; Up &lt;some_time&gt; 2181/tcp zookeeper&lt;kafka_id&gt; bitnami/kafka:3.6.1 &quot;/opt/bitnami/script…&quot; &lt;some_time_ago&gt; Up &lt;some_time&gt; 0.0.0.0:9092-&gt;9092/tcp, :::9092-&gt;9092/tcp kafka 2. 检查 ZooKeeper 日志查看 ZooKeeper 容器的日志，以确保它已成功启动并正在运行： 1docker logs zookeeper 日志中应包含类似以下内容： 12INFO Started AdminServer on address 0.0.0.0, port 8080INFO binding to port 0.0.0.0/0.0.0.0:2181 3. 检查 Kafka 日志查看 Kafka 容器的日志，以确保它已成功连接到 ZooKeeper 并正在运行： 1docker logs kafka 日志中应包含类似以下内容： 12INFO [KafkaServer id=1] started (kafka.server.KafkaServer)INFO [ZooKeeperClient] Connected. (org.apache.zookeeper.ClientCnxn) 4. 使用 Kafka 命令行工具检查进入 Kafka 容器内部，并使用 Kafka 命令行工具检查 Kafka 和 ZooKeeper 的状态： 1234docker exec -it kafka /bin/bash# 列出 Kafka 主题kafka-topics.sh --list --bootstrap-server kafka:9092 如果可以成功列出 Kafka 主题，则表示 Kafka 和 ZooKeeper 正常运行。 5. 创建和删除测试主题可以尝试创建一个测试主题，并查看是否成功： 12345678# 创建一个名为 test-topic 的主题kafka-topics.sh --create --topic test-topic --partitions 1 --replication-factor 1 --bootstrap-server kafka:9092# 列出所有主题，确认 test-topic 是否存在kafka-topics.sh --list --bootstrap-server kafka:9092# 删除 test-topic 主题kafka-topics.sh --delete --topic test-topic --bootstrap-server kafka:9092 通过以上步骤，可以确认 ZooKeeper 和 Kafka 容器是否正常运行并相互通信。","link":"/Hexo/2024/07/03/2024-H2/2024-07-03-16-23-53/"},{"title":"Kafka基础组件图推演","text":"1. Controller Broker Kafka集群中有一个Controller Broker，负责元数据管理和协调。 Kafka使用Zookeeper作为集群元数据的存储和管理工具。Zookeeper保存了集群的状态信息，包括所有的Topic、分区、Leader和副本信息等。 当集群状态发生变化时，Controller Broker会将变更信息写入Zookeeper。 当现任Controller Broker发生故障时，Kafka集群中的其他Broker会检测到这一情况，并通过Zookeeper进行选举。 一个Broker成功竞选为新的Controller Broker后，会从Zookeeper读取最新的集群元数据。 保障机制 持久化元数据：Zookeeper持久化存储集群的元数据，确保在任何时刻都可以获取到最新的状态信息。 心跳机制：Broker与Zookeeper之间通过心跳机制保持连接，快速检测Controller Broker的故障。 选举机制：通过Zookeeper的选举机制，能够快速选举出新的Controller Broker，并从Zookeeper同步元数据。 2. 组件架构 1. Log ManagerLogManager主要负责管理Kafka日志（log）的存储和检索。 比如：生产者将消息发送到Partition0的Leader Broker1。LogManager在Broker1上将消息写入Partition0的日志文件。 2. Replication ManagerReplicationManager主要负责管理分区数据的复制和同步。 每个分区的Leader和Follower之间的同步是独立进行的。也就是说，每个分区都有自己的同步过程，不依赖于其他分区。 虽然每个分区的同步过程是独立的，但每个Broker会为它所管理的每个分区（无论是Leader还是Follower）启动相应的复制线程，这些线程负责处理具体的同步任务。 比如：ReplicationManager在Broker1上将新写入的消息推送到Partition0的Follower Broker2和Broker3。ReplicationManager在Broker2和Broker3上处理从Broker1接收的复制请求，将消息写入它们各自的日志文件。 3. SocketServerSocketServer是Kafka Broker中的一个组件，负责处理网络连接和I/O操作。它负责接受来自客户端和其他Broker的连接请求，并为每个连接分配一个线程进行处理。 4. NetworkServerNetworkServer是Kafka的网络通信框架的一个核心部分，负责管理和调度网络请求。它使用了NIO（非阻塞I/O）来处理高并发的网络连接。 5. ZKClient与Zookeeper通信的组件。","link":"/Hexo/2024/07/10/2024-H2/2024-07-10-21-37-54/"},{"title":"Docker Compose部署Kafka集群并在宿主机Windows连接开发","text":"Docker for Windows 4.23.0 windows 11 Java 17 1. 常用参数kafka容器常用参数如下 -e KAFKA_BROKER_ID=1：设置 Kafka broker 的 ID 为 1。每个 Kafka broker 都需要一个唯一的 ID。 -e KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181：指定 Kafka 连接到 Zookeeper 的地址，这里假设 Zookeeper 容器的名称为 zookeeper，并且它在 2181 端口监听。 -e ALLOW_PLAINTEXT_LISTENER=yes：允许 Kafka 使用纯文本监听器。即允许非加密的通信。 -e KAFKA_LISTENERS=PLAINTEXT://0.0.0.0:9092：Kafka broker 实际监听在容器内的 0.0.0.0:9092 上。这意味着 Kafka 接受来自任何网络接口的连接。 -e KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092：指定 Kafka 广播其监听器地址，客户端将使用该地址连接到 broker。在这个例子中，Kafka 广播它在 localhost:9092 上监听。 KAFKA_LISTENER_SECURITY_PROTOCOL_MAP：指定 Kafka 使用的监听器协议映射。例如：PLAINTEXT:PLAINTEXT,SSL:SSL。 KAFKA_INTER_BROKER_LISTENER_NAME：指定 broker 间通信使用的监听器名称。例如：PLAINTEXT。 2. 理解参数和原理KAFKA_LISTENERS是broker实际监听的地址。 KAFKA_ADVERTISED_LISTENERS是broker注册在zookeeper或者controller broker里面的元数据，当消费者或者生产者使用Bootstrap-Server去连接kafka集群时，集群会返回元数据等信息到客户端，客户端会根据每个broker提供的KAFKA_ADVERTISED_LISTENERS去连接对应的broker。 所以首先，集群之间，broker之间需要通信，所以每个kafka容器需要设置一个KAFKA_ADVERTISED_LISTENERS用于告诉别的容器如何连接到自己，如果容器都是处于同一bridge网络，那么直接使用容器名即可。 其次，我们想要在宿主机比如windows的idea开发，我们一般只能通过docker容器-p暴露的端口去连接kafka，所以每个kafka容器还需要设置一个KAFKA_ADVERTISED_LISTENERS来告诉宿主机的客户端，如何连接到自己，这里需要使用localhost+暴露在宿主机的端口。 那么如果KAFKA_ADVERTISED_LISTENERS里面有2个地址，如何保证broker之间的连接使用的是容器名，而宿主机客户端使用的是localhost呢？ 这需要KAFKA_INTER_BROKER_LISTENER_NAME来指定前者。 并且由于KAFKA_ADVERTISED_LISTENERS里面有2个地址，所以我们还需要KAFKA_LISTENER_SECURITY_PROTOCOL_MAP来映射监听器名字。 3. Docker Compose123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566version: '3.8'services: zookeeper: image: bitnami/zookeeper:3.8.2 container_name: zookeeper environment: - ALLOW_ANONYMOUS_LOGIN=yes networks: - kafka kafka1: image: bitnami/kafka:3.6.1 container_name: kafka1 depends_on: - zookeeper ports: - &quot;19092:9092&quot; environment: - KAFKA_BROKER_ID=1 - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181 - KAFKA_LISTENERS=INTERNAL://0.0.0.0:9093,EXTERNAL://0.0.0.0:9092 - KAFKA_ADVERTISED_LISTENERS=INTERNAL://kafka1:9093,EXTERNAL://localhost:19092 - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT - KAFKA_INTER_BROKER_LISTENER_NAME=INTERNAL networks: - kafka kafka2: image: bitnami/kafka:3.6.1 container_name: kafka2 depends_on: - zookeeper ports: - &quot;29092:9092&quot; environment: - KAFKA_BROKER_ID=2 - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181 - KAFKA_LISTENERS=INTERNAL://0.0.0.0:9093,EXTERNAL://0.0.0.0:9092 - KAFKA_ADVERTISED_LISTENERS=INTERNAL://kafka2:9093,EXTERNAL://localhost:29092 - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT - KAFKA_INTER_BROKER_LISTENER_NAME=INTERNAL networks: - kafka kafka3: image: bitnami/kafka:3.6.1 container_name: kafka3 depends_on: - zookeeper ports: - &quot;39092:9092&quot; environment: - KAFKA_BROKER_ID=3 - KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181 - KAFKA_LISTENERS=INTERNAL://0.0.0.0:9093,EXTERNAL://0.0.0.0:9092 - KAFKA_ADVERTISED_LISTENERS=INTERNAL://kafka3:9093,EXTERNAL://localhost:39092 - KAFKA_LISTENER_SECURITY_PROTOCOL_MAP=INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT - KAFKA_INTER_BROKER_LISTENER_NAME=INTERNAL networks: - kafkanetworks: kafka: driver: bridge 可以看到每个容器都设置了INTERNAL，因为指定了KAFKA_INTER_BROKER_LISTENER_NAME=INTERNAL，所以这是用于broker之间的连接，其监听在本地的0.0.0.0:9093，广播给其它broker的通信地址是&lt;容器名&gt;:9093，使用PLAINTEXT（明文）方式通信。 除此之外还设置了EXTERNAL，监听在本地的0.0.0.0:9092，广播给客户端的地址是localhost:19092、localhost:29092、localhost:39092，也就是windows上的客户端通过localhost:19092访问broker，这会被docker的-p映射到对应容器的9092，被0.0.0.0:9092对接。 4. 验证连接到某个容器。创建test主题。 1kafka-topics.sh --create --topic test --partitions 3 --replication-factor 3 --bootstrap-server kafka1:9093 查看分区和副本情况，可以看到在不同的broker上，输出中显示的是Broker ID。 12345I have no name!@7212060b6e3d:/$ kafka-topics.sh --describe --topic test --bootstrap-server kafka1:9093Topic: test TopicId: Lo1eQ6aCQj6WiFcNiVBrcw PartitionCount: 3 ReplicationFactor: 3 Configs: Topic: test Partition: 0 Leader: 2 Replicas: 2,3,1 Isr: 2,3,1 Topic: test Partition: 1 Leader: 3 Replicas: 3,1,2 Isr: 3,1,2 Topic: test Partition: 2 Leader: 1 Replicas: 1,2,3 Isr: 1,2,3 引入pom包 1234567891011121314151617&lt;dependency&gt; &lt;groupId&gt;org.apache.kafka&lt;/groupId&gt; &lt;artifactId&gt;kafka-clients&lt;/artifactId&gt; &lt;version&gt;3.6.1&lt;/version&gt; &lt;/dependency&gt; &lt;!-- SLF4J API --&gt; &lt;dependency&gt; &lt;groupId&gt;org.slf4j&lt;/groupId&gt; &lt;artifactId&gt;slf4j-api&lt;/artifactId&gt; &lt;version&gt;1.7.36&lt;/version&gt; &lt;/dependency&gt; &lt;!-- Logback classic (SLF4J implementation) --&gt; &lt;dependency&gt; &lt;groupId&gt;ch.qos.logback&lt;/groupId&gt; &lt;artifactId&gt;logback-classic&lt;/artifactId&gt; &lt;version&gt;1.2.11&lt;/version&gt; &lt;/dependency&gt; 生产者代码，通过localhost:19092连接到集群。 1234567891011121314151617181920212223242526272829303132333435package org.dragon.producer;import org.apache.kafka.clients.producer.KafkaProducer;import org.apache.kafka.clients.producer.ProducerConfig;import org.apache.kafka.clients.producer.ProducerRecord;import org.apache.kafka.common.serialization.StringSerializer;import java.util.HashMap;public class KafkaProducerTest { public static void main(String[] args) throws InterruptedException { //创建producer HashMap&lt;String, Object&gt; config = new HashMap&lt;&gt;(); config.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;localhost:19092&quot;); config.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); config.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); KafkaProducer&lt;String, String&gt; producer = new KafkaProducer&lt;String, String&gt;(config); for (int i = 0; i &lt; 10; i++) { //创建record ProducerRecord&lt;String, String&gt; record = new ProducerRecord&lt;String, String&gt;( &quot;test&quot;, &quot;key&quot;+i, &quot;我是你爹&quot;+i ); //发送record producer.send(record); Thread.sleep(500); } //关闭producer producer.close(); }} 消费者代码， 123456789101112131415161718192021222324252627282930313233343536373839package org.dragon.consumer;import org.apache.kafka.clients.consumer.ConsumerConfig;import org.apache.kafka.clients.consumer.ConsumerRecords;import org.apache.kafka.clients.consumer.KafkaConsumer;import org.apache.kafka.common.serialization.StringDeserializer;import org.apache.kafka.common.serialization.StringSerializer;import java.util.Collections;import java.util.HashMap;public class KafkaConsumerTest { public static void main(String[] args) { // 创建消费者对象 HashMap&lt;String, Object&gt; config = new HashMap&lt;&gt;(); config.put(ConsumerConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;localhost:19092&quot;); config.put(ConsumerConfig.KEY_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName()); config.put(ConsumerConfig.VALUE_DESERIALIZER_CLASS_CONFIG, StringDeserializer.class.getName()); config.put(ConsumerConfig.GROUP_ID_CONFIG, &quot;mkl&quot;); KafkaConsumer&lt;String, String&gt; kafkaConsumer = new KafkaConsumer&lt;String, String&gt;(config); // 消费者订阅主题 kafkaConsumer.subscribe(Collections.singletonList(&quot;test&quot;)); try { while (true){ // 消费者拉取消息 ConsumerRecords&lt;String, String&gt; records = kafkaConsumer.poll(100); records.forEach(System.out::println); } }finally { // 消费者关闭 kafkaConsumer.close(); } }} 都启动后，消费者和生产者日志正常。","link":"/Hexo/2024/07/11/2024-H2/2024-07-11-21-12-28/"},{"title":"新增了一些新的封面","text":"","link":"/Hexo/2024/07/11/2024-H2/2024-07-11-21-47-58/"},{"title":"关于Kafka Topic分区和Replication分配的策略","text":"1. Topic多分区 如图，是一个多分区Topic在Kafka集群中可能得分配情况。 P0-RL代表分区0，Leader副本。 这个Topic是3分区2副本的配置。分区尽量均匀分在不同的Broker上，分区的Follower副本尽量不和Leader在一个Broker上。 2. 理想的策略假设有3个Topic在含有3个Broker的Kafka集群上。 Topic1有1个分区，2个副本。 Topic2有2个分区，2个副本。 Topic3有3个分区，2个副本。 可能如下图所示。不同颜色表示不同Topic。 似乎不是特别理想，我们再调整一下，如下图 不仅每个Broker的副本数一样了，更关键的是，并且每个Broker的主Leader副本也一样的。这样更适合负载均衡。 3. 实际的策略我们使用Kafka tool，来以此创建上述3个Topic。 首先看test1 然后看test2 然后是test3 按照上面的信息，画出来的分配结果如下图 似乎并不和我们想的一样。 查看源码，Breadcrumbskafka/server-common/src/main/java/org/apache/kafka/admin/AdminUtils.java中一段代码 12345678910111213141516171819202122private static Map&lt;Integer, List&lt;Integer&gt;&gt; assignReplicasToBrokersRackUnaware(int nPartitions, int replicationFactor, List&lt;Integer&gt; brokerList, int fixedStartIndex, int startPartitionId) { Map&lt;Integer, List&lt;Integer&gt;&gt; ret = new HashMap&lt;&gt;(); int startIndex = fixedStartIndex &gt;= 0 ? fixedStartIndex : RAND.nextInt(brokerList.size()); int currentPartitionId = Math.max(0, startPartitionId); int nextReplicaShift = fixedStartIndex &gt;= 0 ? fixedStartIndex : RAND.nextInt(brokerList.size()); for (int i = 0; i &lt; nPartitions; i++) { if (currentPartitionId &gt; 0 &amp;&amp; (currentPartitionId % brokerList.size() == 0)) nextReplicaShift += 1; int firstReplicaIndex = (currentPartitionId + startIndex) % brokerList.size(); List&lt;Integer&gt; replicaBuffer = new ArrayList&lt;&gt;(); replicaBuffer.add(brokerList.get(firstReplicaIndex)); for (int j = 0; j &lt; replicationFactor - 1; j++) replicaBuffer.add(brokerList.get(replicaIndex(firstReplicaIndex, nextReplicaShift, j, brokerList.size()))); ret.put(currentPartitionId, replicaBuffer); currentPartitionId += 1; } return ret; } 例子（来自尚硅谷） 4. 如何自定义策略12345678910111213141516171819202122232425262728public class AdminTopicTest { public static void main(String[] args) { //定义kafka集群配置 Map&lt;String, Object&gt; config = new HashMap&lt;&gt;(); config.put(AdminClientConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;localhost:19092&quot;); //创建Admin管理员对象 Admin admin = Admin.create(config); //定义Topic属性 HashMap&lt;Integer, List&lt;Integer&gt;&gt; map = new HashMap&lt;&gt;(); // 分区0，Leader副本在3上，第二个副本在1上。 map.put(0, Arrays.asList(3, 1)); map.put(1, Arrays.asList(2, 3)); map.put(2, Arrays.asList(1, 2)); NewTopic test4 = new NewTopic(&quot;test2&quot;, map); //创建Topic CreateTopicsResult result = admin.createTopics( Arrays.asList( test4 ) ); admin.close(); }} 不过在手动分配时，确实需要了解每个broker的负载情况，以便做出更优的分配策略。你可以使用Kafka的AdminClient类来获取集群的状态信息","link":"/Hexo/2024/07/14/2024-H2/2024-07-14-19-34-53/"},{"title":"Kafka Producer之拦截器","text":"1. Producer流程 新建ProducerRecord类后，传入topic、key、value等数据构建Record之后，距离发送至kafka集群还需要经历若干过程。 拦截器列表，对数据进行过滤，更改等行为，处理异常不会导致流程终止。 获取Kafka集群元数据 对数据进行序列化 根据元数据选择分区和Broker 数据校验 进入数据发送缓存区，批次发送 send 2. 代码测试123456789101112131415161718192021222324252627public class KafkaProducerInterceptorTest { public static void main(String[] args) throws InterruptedException { //创建producer HashMap&lt;String, Object&gt; config = new HashMap&lt;&gt;(); config.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;localhost:19092&quot;); config.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); config.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); //指定拦截器 config.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, ValueInterceptorTest.class.getName()); KafkaProducer&lt;String, String&gt; producer = new KafkaProducer&lt;String, String&gt;(config); for (int i = 0; i &lt; 10; i++) { //创建record ProducerRecord&lt;String, String&gt; record = new ProducerRecord&lt;String, String&gt;( &quot;test1&quot;, &quot;key&quot;+i, &quot;我是你爹&quot;+i ); //发送record producer.send(record); Thread.sleep(500); } //关闭producer producer.close(); }} 拦截器自定义类 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162package org.dragon.producer;import org.apache.kafka.clients.producer.ProducerInterceptor;import org.apache.kafka.clients.producer.ProducerRecord;import org.apache.kafka.clients.producer.RecordMetadata;import java.util.Map;/** * 自定义value拦截器试验&lt;br/&gt; * 1. 实现接口 * 2. 定义泛型 * 3. 重写方法 * * * @author mumu * @date 2024/07/15 */public class ValueInterceptorTest implements ProducerInterceptor&lt;String, String&gt; { /** * 发送数据时会调用这个方法&lt;br/&gt; * 让value复制2次 * * @param producerRecord 生产者记录 * @return {@link ProducerRecord}&lt;{@link String}, {@link String}&gt; */ @Override public ProducerRecord&lt;String, String&gt; onSend(ProducerRecord&lt;String, String&gt; producerRecord) { return new ProducerRecord&lt;String, String&gt;(producerRecord.topic(), producerRecord.key(), producerRecord.value() + producerRecord.value()); } /** * 发送数据完毕，服务器返回的响应，会调用此方法。 * * @param recordMetadata 记录元数据 * @param e e */ @Override public void onAcknowledgement(RecordMetadata recordMetadata, Exception e) { } /** * 生产者关闭，会调用此方法 */ @Override public void close() { } /** * 创建生产者对象时调用 * * @param map 地图 */ @Override public void configure(Map&lt;String, ?&gt; map) { }} 3. 测试结果可以看到value是复制了2次，成功。","link":"/Hexo/2024/07/15/2024-H2/2024-07-15-20-34-18/"},{"title":"Kafka Producer发送消息流程之分区器和数据收集器","text":"1. Partitioner分区器 clients/src/main/java/org/apache/kafka/clients/producer/KafkaProducer.java，中doSend方法，记录了生产者将消息发送的流程，其中有一步就是计算当前消息应该发送往对应Topic哪一个分区， 1int partition = partition(record, serializedKey, serializedValue, cluster); 12345678910111213141516171819202122232425262728293031323334private final Partitioner partitioner;private int partition(ProducerRecord&lt;K, V&gt; record, byte[] serializedKey, byte[] serializedValue, Cluster cluster) { //当record的分区已存在，则直接返回，这对应了创建Record时可以手动传入partition参数 if (record.partition() != null) return record.partition(); // 如果存在partitioner分区器，则使用Partitioner.partition方法计算分区数据 if (partitioner != null) { int customPartition = partitioner.partition( record.topic(), record.key(), serializedKey, record.value(), serializedValue, cluster); if (customPartition &lt; 0) { throw new IllegalArgumentException(String.format( &quot;The partitioner generated an invalid partition number: %d. Partition number should always be non-negative.&quot;, customPartition)); } return customPartition; } // 如果没有分区器的情况 if (serializedKey != null &amp;&amp; !partitionerIgnoreKeys) { // hash the keyBytes to choose a partition return BuiltInPartitioner.partitionForKey(serializedKey, cluster.partitionsForTopic(record.topic()).size()); } else { return RecordMetadata.UNKNOWN_PARTITION; } }// 利用键的哈希值来选择分区public static int partitionForKey(final byte[] serializedKey, final int numPartitions) { return Utils.toPositive(Utils.murmur2(serializedKey)) % numPartitions; } 2. 自定义分区器新建类实现Partitioner接口，key是字符串数字，奇数送到分区0，偶数送到分区1 。 12345678910111213141516171819202122232425262728293031323334public class MyKafkaPartitioner implements Partitioner { @Override public int partition(String s, Object key, byte[] bytes, Object o1, byte[] bytes1, Cluster cluster) { // Ensure the key is a non-null string if (key == null || !(key instanceof String)) { throw new IllegalArgumentException(&quot;Key must be a non-null String&quot;); } // Parse the key as an integer int keyInt; try { keyInt = Integer.parseInt((String) key); } catch (NumberFormatException e) { throw new IllegalArgumentException(&quot;Key must be a numeric string&quot;, e); } // Determine the partition based on the key's odd/even nature if (keyInt % 2 == 0) { return 1; // Even keys go to partition 2 } else { return 0; // Odd keys go to partition 0 } } @Override public void close() { } @Override public void configure(Map&lt;String, ?&gt; map) { }} 新建一个存在多分区的Topic。 123456789101112131415161718192021222324252627282930public class KafkaProducerPartitionorTest { public static void main(String[] args) throws InterruptedException { //创建producer HashMap&lt;String, Object&gt; config = new HashMap&lt;&gt;(); config.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;localhost:19092&quot;); config.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); config.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); //指定拦截器 config.put(ProducerConfig.INTERCEPTOR_CLASSES_CONFIG, ValueInterceptorTest.class.getName()); //指定分区器 config.put(ProducerConfig.PARTITIONER_CLASS_CONFIG, MyKafkaPartitioner.class.getName()); KafkaProducer&lt;String, String&gt; producer = new KafkaProducer&lt;String, String&gt;(config); for (int i = 0; i &lt; 10; i++) { //创建record ProducerRecord&lt;String, String&gt; record = new ProducerRecord&lt;String, String&gt;( &quot;test1&quot;, &quot;key&quot;+i, &quot;我是你爹&quot;+i ); //发送record producer.send(record); Thread.sleep(500); } //关闭producer producer.close(); }} 配置好PARTITIONER_CLASS_CONFIG后发送消息。 可以分区器成功起作用了。 3. RecordAccumulator数据收集器通过数据校验后，数据从分区器来到数据收集器。 数据收集器的工作机制 队列缓存：RecordAccumulator为每个分区维护一个队列。默认情况下，每个队列的批次大小（buffer size）是16KB，这个大小可以通过配置参数batch.size来调整。 缓冲区管理： 每个分区都有一个或多个批次，每个批次包含多条消息。 当一个批次填满（即达到batch.size），或者达到发送条件（如linger.ms时间窗口，即发送消息前等待的时间）时，批次会被标记为可发送状态，并被传递给Sender线程。 满批次处理： 当某个分区的队列中的某个批次大小超过了16KB（默认值）或满足linger.ms的时间条件，RecordAccumulator会将该批次加入到一个待发送的队列中。 Sender线程会从待发送队列中获取这些满批次并将其发送到Kafka集群。","link":"/Hexo/2024/07/16/2024-H2/2024-07-16-20-05-34/"},{"title":"Kafka Producer发送消息流程之Sender发送线程和在途请求缓存区","text":"1. Sender发送数据Sender线程负责将已经在RecordAccumulator中准备好的消息批次发送到Kafka集群。虽然消息在RecordAccumulator中是按照分区组织的，但Sender线程在发送这些消息时，会按照broker而不是分区来组织发送。这有助于提高发送效率和减少网络开销。 1. 发送数据的详细过程： 拉取批次：Sender线程从RecordAccumulator中拉取已准备好发送的消息批次。这些批次可能来自多个分区。 按broker组织批次：Sender线程会将这些批次按目标broker进行组织，因为一个broker通常负责多个分区的消息处理。这个过程涉及以下步骤： 确定每个分区的leader broker。 将属于同一个broker的所有分区的批次组合在一起。 发送请求：Sender线程会为每个broker创建一个或多个Produce请求（ProduceRequest），然后通过网络将这些请求发送到对应的broker。这些请求包含了该broker负责的所有分区的消息批次。 处理响应：Sender线程会等待broker的响应。响应中包含了每个分区的消息是否成功写入的信息。 如果某个分区的消息写入失败，Sender线程会根据重试机制重试发送这些消息。 如果所有消息都成功写入，Sender线程会从RecordAccumulator中移除这些消息批次。 2. 关键参数配置以下是一些关键参数，可以影响Sender线程的行为： max.in.flight.requests.per.connection：每个连接允许的最大未完成请求数。默认值为5。如果这个值过大，可能会导致消息重排序。 request.timeout.ms：请求超时时间。默认值为30秒。如果broker在此时间内没有响应，Sender线程会重试或失败。 retries：重试次数。默认值为0。指定Sender线程在发送消息失败时的重试次数。 retry.backoff.ms：重试间隔时间。默认值为100ms。指定每次重试之间的等待时间。 通过这些配置，Kafka生产者可以在不同的网络条件和负载下优化消息发送的效率和可靠性。 在Kafka生产者的Sender线程工作流程中，如果一次任务中包含了来自多个分区的批次，并且这些批次涉及到多个broker，那么Sender线程会分别向这些broker发送请求 2. 在途请求缓存区 存储在途请求：当Sender线程将消息批次发送到broker后，这些请求会存储在在途请求缓存区中，直到收到broker的确认响应。这个缓存区的大小由配置参数max.in.flight.requests.per.connection决定。 重试机制：如果某个请求在指定时间内没有收到响应，生产者会根据配置的重试机制重新发送这些请求。重试机制配置参数包括retries和retry.backoff.ms。 顺序保证：max.in.flight.requests.per.connection参数设置了每个连接（每个生产者和Kafka的连接）允许的最大未完成请求数。默认值是5。如果这个值设置过大，可能会导致消息重排序问题，特别是在启用了重试机制时。设置合适的值可以平衡并发性能和消息顺序保证。 资源管理：在途请求缓存区的大小会影响生产者的内存使用和性能。如果在途请求过多，可能会占用大量内存资源，导致生产者性能下降。因此，合理设置这个缓存区的大小是优化生产者性能的关键。","link":"/Hexo/2024/07/16/2024-H2/2024-07-16-20-42-33/"},{"title":"Kafka Producer之消息异步发送和同步发送","text":"1. 异步发送Kafka默认就是异步发送，在Main线程中的多条消息，没有严格的先后顺序，Sender发送后就继续下一条，异步接受结果。 12345678910111213141516171819202122232425262728293031public class KafkaProducerCallbackTest { public static void main(String[] args) throws InterruptedException { //创建producer HashMap&lt;String, Object&gt; config = new HashMap&lt;&gt;(); config.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;localhost:19092&quot;); config.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); config.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); KafkaProducer&lt;String, String&gt; producer = new KafkaProducer&lt;String, String&gt;(config); for (int i = 0; i &lt; 10; i++) { //创建record ProducerRecord&lt;String, String&gt; record = new ProducerRecord&lt;String, String&gt;( &quot;test2&quot;, &quot;&quot;+i, &quot;我是你爹&quot;+i ); //发送record producer.send(record, new Callback() { @Override public void onCompletion(RecordMetadata recordMetadata, Exception e) { System.out.println(&quot;回调信息：消息发送成功&quot;); } }); System.out.println(&quot;发送数据&quot;); } //关闭producer producer.close(); }} Main线程中，对于多条数据，下一条消息的发送并不等待上一条消息的确认，而是继续发送。 1234567891011121314151617181920212223242024-07-17 21:43:46.052 [kafka-producer-network-thread | producer-1] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: BqIgDGtwTeeusL_ygHtn2w发送数据发送数据发送数据发送数据发送数据发送数据发送数据发送数据发送数据发送数据2024-07-17 21:43:46.075 [main] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.2024-07-17 21:43:46.280 [kafka-producer-network-thread | producer-1] INFO o.a.k.c.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId set to 6000 with epoch 0回调信息：消息发送成功回调信息：消息发送成功回调信息：消息发送成功回调信息：消息发送成功回调信息：消息发送成功回调信息：消息发送成功回调信息：消息发送成功回调信息：消息发送成功回调信息：消息发送成功回调信息：消息发送成功2024-07-17 21:43:46.569 [main] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed 可以看到先是main线程循环发送完了多条数据，然后再异步收到通知。 2. 同步发送消息有严格的先后顺序，下一条消息必须等到上一条消息的回调确认后，再发送，这是一个效率极低的过程。 按照流程图，上一条消息需要从生产者一直流转，多个步骤，到数据收集器，到Sender，最后还要等待回调确认，才可以开始下一条消息的流转。 1234567891011121314151617181920212223242526272829303132public class KafkaProducerCallbackTest { public static void main(String[] args) throws InterruptedException, ExecutionException { //创建producer HashMap&lt;String, Object&gt; config = new HashMap&lt;&gt;(); config.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;localhost:19092&quot;); config.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); config.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); KafkaProducer&lt;String, String&gt; producer = new KafkaProducer&lt;String, String&gt;(config); for (int i = 0; i &lt; 10; i++) { //创建record ProducerRecord&lt;String, String&gt; record = new ProducerRecord&lt;String, String&gt;( &quot;test2&quot;, &quot;&quot;+i, &quot;我是你爹&quot;+i ); //发送record Future&lt;RecordMetadata&gt; send = producer.send(record, new Callback() { @Override public void onCompletion(RecordMetadata recordMetadata, Exception e) { System.out.println(&quot;回调信息：消息发送成功&quot;); } }); System.out.println(&quot;发送数据&quot;); send.get(); } //关闭producer producer.close(); }} 12345678910111213141516171819202122232024-07-17 21:49:19.586 [kafka-producer-network-thread | producer-1] INFO o.a.k.c.producer.internals.TransactionManager - [Producer clientId=producer-1] ProducerId set to 5000 with epoch 0发送数据回调信息：消息发送成功发送数据回调信息：消息发送成功发送数据回调信息：消息发送成功发送数据回调信息：消息发送成功发送数据回调信息：消息发送成功发送数据回调信息：消息发送成功发送数据回调信息：消息发送成功发送数据回调信息：消息发送成功发送数据回调信息：消息发送成功发送数据回调信息：消息发送成功2024-07-17 21:49:19.823 [main] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.2024-07-17 21:49:19.838 [main] INFO org.apache.kafka.common.metrics.Metrics - Metrics scheduler closed","link":"/Hexo/2024/07/17/2024-H2/2024-07-17-21-37-28/"},{"title":"Kafka Producer之ACKS应答机制","text":"1. 应答机制异步发送的效率高，但是不安全，同步发送安全，但是效率低。 无论哪一种，有一个关键的步骤叫做回调，也就是ACKS应答机制。 其中ACKS也分为3个等级。默认等级是all。 等级 效率 安全 all（-1） 效率低 安全性高 1 效率中 安全性中 0 效率高 安全性低 2. 等级0 生产者发送消息到Kafka集群。 消息进入网络发送队列。 生产者立即返回（认为消息已发送），不等待任何Broker的确认。 3. 等级1 生产者发送消息到Kafka集群。 Leader分区接收消息，将消息写入本地日志。 Leader分区将消息同步到磁盘（如果配置了日志刷新）。 Leader分区返回确认（ACK）给生产者。 生产者收到ACK，继续处理下一条消息。 4. 等级all 生产者发送消息到Kafka集群。 Leader分区接收消息，将消息写入本地日志。 Leader分区将消息同步到磁盘（如果配置了日志刷新）。 Leader分区将消息发送给所有同步副本（ISR）。 每个同步副本（Follower）将消息写入本地日志并返回确认给Leader。 Leader分区收到所有同步副本的确认后，返回ACK给生产者。 生产者收到ACK，继续处理下一条消息。 5. 设置等级123456789//创建producerHashMap&lt;String, Object&gt; config = new HashMap&lt;&gt;();config.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;localhost:19092&quot;);config.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());config.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());//配置acks等级config.put(ProducerConfig.ACKS_CONFIG, &quot;-1&quot;);KafkaProducer&lt;String, String&gt; producer = new KafkaProducer&lt;String, String&gt;(config); 6. ISRISR的定义： 成员：ISR包括Leader和所有与Leader保持同步的Follower分区。保持同步的标准是Follower分区的日志不落后于Leader分区超过指定的时间（由replica.lag.time.max.ms配置）。 目的：确保在Leader发生故障时，可以迅速从ISR中选举一个新的Leader，从而保证分区的高可用性。 ISR的动态调整： Kafka会动态调整ISR的成员。如果一个Follower分区落后于Leader超过一定的时间，Kafka会将其从ISR中移除。 当该Follower分区重新追上Leader并满足同步标准时，Kafka会将其重新加入ISR。","link":"/Hexo/2024/07/17/2024-H2/2024-07-17-21-49-43/"},{"title":"Kafka Producer之数据重复和乱序问题","text":"为了可靠性，Kafka有消息重试机制，但是同时也带来了2大问题 1. 数据重复 消息发送到broker后，broker记录消息数据到log中，但是由于网络问题，producer没有收到acks，于是再次发送消息。 除此之外，也可能是其他场景，导致了消息的重复。 2. 数据乱序 如图，消息2、3发送到了broker，但是data1因为网络问题没有到broker，然后被producer重试了，第二次到了，但是顺序乱了。","link":"/Hexo/2024/07/18/2024-H2/2024-07-18-21-02-23/"},{"title":"Kafka Producer之幂等性","text":"幂等性通过消耗时间和性能的方式，解决乱序和重复问题。 但是只能保证同一生产者在一个分区中的幂等性。 1. 启用幂等性1234567891011121314//创建producerHashMap&lt;String, Object&gt; config = new HashMap&lt;&gt;();config.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;localhost:19092&quot;);config.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());config.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName());//配置acks等级config.put(ProducerConfig.ACKS_CONFIG, &quot;-1&quot;);//启用幂等性config.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, true);// 消息失败重试次数config.put(ProducerConfig.RETRIES_CONFIG, 5);config.put(ProducerConfig.REQUEST_TIMEOUT_MS_CONFIG, 3000);KafkaProducer&lt;String, String&gt; producer = new KafkaProducer&lt;String, String&gt;(config); 幂等性操作要求： ACKS = -1 开启重试机制 在途请求缓冲区不能大于5 2. 底层变化消息会被标记，包含生产者ID和消息序列号。 ( 如果生产者重启，那么ID会变化，这会使得下图记录无效，幂等性短暂失效。) 并且broker中的ProducerState会记录每个分区的生产者状态，包括最新5个消息的序列号。 3. 数据不重复消息来到broker分区，经由ProducerState的数据进行对比， 重复则丢弃消息，返回ack。 否则Broker存储消息并返回ack。 4. 数据有序消息来到broker分区，经由ProducerState的数据进行对比， 如果新消息的序列号是连续的，Broker会接受并存储该消息，然后更新最新序列号。 如果新消息的序列号不连续，Broker会认为这是重复消息或乱序消息，根据配置，它可能会丢弃或拒绝该消息。 无论消息被接受还是丢弃，Broker都会返回一个ack给生产者。 不连续时可能拒绝多个消息，那么这些消息都会返回生产者重新发送，直到按顺序下一个消息到来，才存储并更新。","link":"/Hexo/2024/07/18/2024-H2/2024-07-18-21-10-28/"},{"title":"Kafka Producer之事务性","text":"事务性可以防止跨会话幂等性失效，同时也可以保证单个生产者的指定数据，要么全部成功要么全部失败，不限分区。不可以多个生产者共用相同的事务ID。 1. 跨会话幂等性失效幂等性开启后，broker会对每个分区记录生产者状态，并且生产者具有PID，消息被标记为PID加上序列号，数据重复和有序都是在其基础之上运作的。 生产者重启等因素会导致PID变化，导致幂等性短暂失效。 2. 开启事务因为事务是基于幂等性的，所以幂等性的配置都要有。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263package org.dragon.producer;import org.apache.kafka.clients.producer.*;import org.apache.kafka.common.serialization.StringSerializer;import java.util.HashMap;import java.util.concurrent.ExecutionException;import java.util.concurrent.Future;public class KafkaProducerTransactionTest { public static void main(String[] args) throws InterruptedException, ExecutionException { //创建producer HashMap&lt;String, Object&gt; config = new HashMap&lt;&gt;(); config.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, &quot;localhost:19092&quot;); config.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); config.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, StringSerializer.class.getName()); //配置acks等级 config.put(ProducerConfig.ACKS_CONFIG, &quot;-1&quot;); config.put(ProducerConfig.ENABLE_IDEMPOTENCE_CONFIG, true); config.put(ProducerConfig.RETRIES_CONFIG, 5); // 把buffer改小一点，让测试数据组成更多batch config.put(ProducerConfig.BATCH_SIZE_CONFIG, 5); config.put(ProducerConfig.REQUEST_TIMEOUT_MS_CONFIG, 3000); // 事务ID config.put(ProducerConfig.TRANSACTIONAL_ID_CONFIG, &quot;my-tx-id&quot;); KafkaProducer&lt;String, String&gt; producer = new KafkaProducer&lt;String, String&gt;(config); //初始化事务 producer.initTransactions(); try { // 开启事务 producer.beginTransaction(); for (int i = 0; i &lt; 10; i++) { //创建record ProducerRecord&lt;String, String&gt; record = new ProducerRecord&lt;String, String&gt;( &quot;test2&quot;, &quot;&quot; + i, &quot;我是你爹&quot; + i ); //发送record Future&lt;RecordMetadata&gt; send = producer.send(record, new Callback() { @Override public void onCompletion(RecordMetadata recordMetadata, Exception e) { System.out.println(&quot;回调信息：消息发送成功&quot;); } }); System.out.println(&quot;发送数据&quot;); send.get(); } // 提交事务 producer.commitTransaction(); }catch(Exception e) { // 中止事务 producer.abortTransaction(); e.printStackTrace(); }finally{ //关闭producer producer.close(); } }} 3. 事务流程原理 查找联系事务管理器 根据设置的TRANSACTIONAL_ID_CONFIG计算PID，计算方式为哈希值%分区数量 初始化事务 将涉及到的分区信息发送给事务管理器，方便事务管理器管理和监控这些分区的事务状态。 生成数据，发送数据到对应Broker 对应Broker把分区信息发送给事务管理器，为了确认哪些分区确实已经收到了事务中的消息 对应Broker返回ACKS 生产者发起结束事务的请求 修改事务状态为准备提交 事务管理器将事务标记为成功或者失败，并通知对应broker。 修改事务状态为已提交","link":"/Hexo/2024/07/19/2024-H2/2024-07-19-21-29-10/"},{"title":"Kafka之存储设计","text":"1. 分区和副本的存储结构在一个多 broker 的 Kafka 集群中，topic 的分区和副本在各个 broker 上的存储文件夹分布如下： 假设有以下设置： 一个 Kafka 集群包含 3 个 broker（broker 0, broker 1, broker 2）。 一个 topic my-topic，有 3 个分区（partition 0, partition 1, partition 2）。 每个分区有 2 个副本。 1. 分区和副本的分布Kafka 会在多个 broker 之间分配分区和副本。假设分配如下： partition 0： leader: broker 0 follower: broker 1 partition 1： leader: broker 1 follower: broker 2 partition 2： leader: broker 2 follower: broker 0 2. 存储目录结构每个 broker 的数据目录结构如下（假设 log.dirs 配置为 /var/lib/kafka/data）： Broker 0 (/var/lib/kafka/data) 123456789/var/lib/kafka/data└── my-topic-0 # partition 0 leader ├── 00000000000000000000.log ├── 00000000000000000000.index ├── 00000000000000000000.timeindex└── my-topic-2 # partition 2 follower ├── 00000000000000000000.log ├── 00000000000000000000.index ├── 00000000000000000000.timeindex Broker 1 (/var/lib/kafka/data) 123456789/var/lib/kafka/data└── my-topic-0 # partition 0 follower ├── 00000000000000000000.log ├── 00000000000000000000.index ├── 00000000000000000000.timeindex└── my-topic-1 # partition 1 leader ├── 00000000000000000000.log ├── 00000000000000000000.index ├── 00000000000000000000.timeindex Broker 2 (/var/lib/kafka/data) 123456789/var/lib/kafka/data└── my-topic-1 # partition 1 follower ├── 00000000000000000000.log ├── 00000000000000000000.index ├── 00000000000000000000.timeindex└── my-topic-2 # partition 2 leader ├── 00000000000000000000.log ├── 00000000000000000000.index ├── 00000000000000000000.timeindex 3. 文件描述每个分区目录包含多个文件： .log 文件：存储实际的消息数据。 .index 文件：存储消息偏移量索引，以便快速定位消息。 .timeindex 文件：存储消息时间戳索引，以便基于时间进行查找。 2. 相关配置在 Apache Kafka 中，消息到达 leader broker 后，实际上是先写入操作系统的页缓存，然后由操作系统决定何时将数据刷入磁盘。 Kafka 允许通过配置参数来控制消息何时刷入磁盘。主要有以下几个重要的参数： log.flush.interval.messages：指定在写入多少条消息后，强制将数据刷入磁盘。默认为 Long.MAX_VALUE，即不基于消息数量进行刷盘。 log.flush.interval.ms：指定时间间隔（以毫秒为单位），强制将数据刷入磁盘。默认为 Long.MAX_VALUE，即不基于时间进行刷盘。 log.flush.scheduler.interval.ms：默认值为 3000 毫秒。这只是一个检查的频率，实际的刷盘行为是由 log.flush.interval.ms 决定的。当调度器检查时，如果发现已经超过了 log.flush.interval.ms 设置的时间间隔，就会触发刷盘操作。 log.segment.bytes：控制单个日志段文件的最大大小，当一个日志段文件达到指定大小时，Kafka 会创建一个新的日志段文件，默认值1G。 log.segment.delete.delay.ms：控制日志段文件在被删除之前的延迟时间。当一个日志段文件被标记为删除后，Kafka 会等待指定的延迟时间才会真正删除该文件。这为潜在的恢复操作提供了缓冲时间。默认值60000 ms。 log.roll.ms 和 log.roll.hours：控制日志段文件的滚动时间间隔，无论日志段文件的大小如何，当达到指定的时间间隔时，Kafka 会创建一个新的日志段文件。log.roll.hours默认值168 小时（7 天）。 3. 数据文件类型 .index 文件： 描述：这是 Kafka 的偏移量索引文件。它用于快速查找消息在日志文件中的位置。 命名格式：00000000000000000000.index 作用：通过这个索引文件，Kafka 可以快速定位消息在日志文件中的物理位置，以便更快地读取消息。 .log 文件： 描述：这是 Kafka 的日志文件，存储实际的消息数据。 命名格式：00000000000000000000.log 作用：包含了生产者发送的消息内容。每个日志文件是一个分区的一部分，日志文件的命名表示消息的起始偏移量。 .timeindex 文件： 描述：这是 Kafka 的时间戳索引文件，存储消息的时间戳索引。 命名格式：00000000000000000000.timeindex 作用：通过这个文件，Kafka 可以根据时间戳快速查找消息。这个文件对于实现基于时间的消息查找非常重要。 .snapshot 文件： 描述：这是 Kafka 的快照文件，记录了日志段的元数据快照。 命名格式：00000000000000000016.snapshot 作用：用于恢复日志段的元数据，保证在崩溃恢复时能够正确地重建索引和时间戳数据。 leader-epoch-checkpoint 文件： 描述：这是 Kafka 用于记录 leader 选举周期的检查点文件。 作用：记录了分区的 leader 副本在不同的选举周期中的偏移量信息，帮助 Kafka 在故障恢复时确定正确的 leader 和消息偏移量。 partition.metadata 文件： 描述：这是 Kafka 的分区元数据文件。 作用：存储分区的基本元数据信息，如分区的 leader、replica 列表等，用于分区的管理和协调。 4. 数据定位原理log等文件直接打开会乱码，使用以下工具可以解析到控制台。 1kafka-run-class.sh kafka.tools.DumpLogSegments --files /path/to/log-file.log --print-data-log 一个log文件里面有如下内容， Kafka 日志文件中的内容并不是简单的按行排列的消息，而是采用了批处理（batch）的方式来存储消息。 那么.index文件中可能是如下内容： 1offset: 3 position: 95 .index 文件并不会为每一条消息都记录映射关系，而是每隔一定的字节数（由配置 log.index.interval.bytes 决定，默认4096）记录一次。 如上图， LogSegment 类LogSegment 主要负责一个段的日志管理。它包括： 日志文件（.log）：存储实际的消息数据。 偏移量索引文件（.index）：存储消息偏移量到物理位置的映射。 时间戳索引文件（.timeindex）：存储消息时间戳到物理位置的映射。 UnifiedLog 类UnifiedLog 管理一个分区的所有日志段。它通过跳表(ConcurrentSkipListMap)实现多个 LogSegment 日志的连续存储。UnifiedLog 的主要职责包括： 消息写入：将消息追加到当前活动的 LogSegment 中。如果当前日志段已满，滚动到新的日志段。 消息读取：根据偏移量或时间戳查找并读取消息，可能跨越多个日志段。 日志截断：根据保留策略（如日志保留时间或大小），截断过期或不需要的日志段。 数据恢复：在 broker 重启或故障恢复时，从日志段中恢复数据。 如图，要查询偏移量为7的数据： 通过跳表定位到对应的LogSegment 通过.index，经由二分法等高效定位指定偏移量的位置（如果没记录，则使用最大的小于偏移量位置） 按照指定位置快速定位到偏移量7的位置（或更前面一些） 5. 副本数据同步 follower会定时向leader拉取数据。 HW水位线 水位线（HW）是 Kafka 中每个分区的一个偏移量，它表示已经被所有同步副本（leader 和 follower）确认并复制的最高偏移量。 数据一致性：HW 确保只有那些已经被所有同步副本成功复制的消息才会对消费者可见。这样可以防止数据不一致的问题，防止读取到未被完全复制的消息。 数据可靠性：HW 确保了在系统发生故障时，数据不会丢失，并且消费者读取到的数据是可靠的。如果设置了 acks=all，那么只有当所有同步副本都确认收到消息后，HW 才会更新。这确保了数据已经被多个副本存储，防止数据丢失。 故障恢复：当 leader 副本故障时，Kafka 会从同步副本中选举一个新的 leader 副本。新的 leader 会从 HW 位置开始，确保它拥有所有已提交的消息。 提高数据处理的可靠性和简化系统设计。生产者和消费者不需要处理复杂的数据一致性逻辑，只需依赖 Kafka 的 HW 机制。消费者读取的数据都是已经被确认的可靠数据，避免处理未确认数据带来的复杂性和错误。 LEO末端偏移量LEO（Log End Offset）是 Kafka 中的一个重要概念，代表一个分区的日志末端偏移量。具体来说，LEO 是指分区中下一条待写入消息的偏移量。 HW更新原理Leader会记录所有副本的LEO，以及HW。 Follower会记录自己的LEO，以及HW。 消息来到Leader，Leader更新自身LEO。 Follower向Leader同步数据，同步发送自身LEO，Leader更新LEO数据，并更新HW。 Leader将数据返回到Follower，并携带HW，Followe同步HW的值，并更新自身LEO。 如此反复，LEO和HW就在不断地更新。 6. 数据清除 log.retention.hours，log.retention.minutes，log.retention.ms：日志保留的时间。超过这个时间的日志文件将被删除。log.retention.hours默认值为168（即 7 天） log.retention.check.interval.ms：指定 Kafka Broker 多长时间检查一次日志文件，并根据配置的日志保留策略删除或压缩过期的日志文件。默认值：300000 毫秒（即 5 分钟）. log.retention.bytes：每个分区保留的最大日志大小，超过这个大小的日志将被删除。默认值：-1（表示没有大小限制）。 log.cleanup.policy：日志清理策略，支持 delete 和 compact 两种模式。delete 模式表示根据保留策略删除旧日志，compact 模式表示日志压缩。默认值为delete。 log.cleaner.min.cleanable.ratio：日志分段中可以被清理的最小比例。仅当分段中可清理的日志比例超过此值时，才会触发日志压缩。 log.cleaner.delete.retention.ms：被标记为删除的记录在清理前的保留时间（以毫秒为单位）。在此时间之后，记录将从日志中永久删除。 关于 log.cleanup.policy=compact，因为数据会丢失，所以这种策略只适用于保存数据最新状态的特殊场景。压缩步骤如下： 标记旧数据：Kafka会通过定期扫描日志分段（log segment）来查找每个key的最新值。对于同一个key，Kafka会将旧的值标记为删除（通常是通过在记录上设置一个删除标记）。 合并过程：Kafka在后台运行一个合并过程（compaction process），这个过程会将分段中旧的key值对删除，保留最新的key值对。合并过程是增量进行的，Kafka并不会在每次写入消息时都触发这个过程。 实际删除：被标记为删除的key值对并不会立即从日志分段中删除。Kafka的压缩过程是定期进行的，时间间隔和触发条件可以通过配置参数来调整。默认情况下，Kafka会在后台线程中异步执行这个压缩过程。","link":"/Hexo/2024/07/20/2024-H2/2024-07-20-19-59-46/"},{"title":"Kafka Consumer","text":"1. Consumer基本流程 初始化消费者 首先，创建一个 Kafka 消费者实例，并设置必要的配置属性，例如 Kafka 集群地址、消费者组 ID、序列化器等。 12345678Properties props = new Properties();props.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;);props.put(&quot;group.id&quot;, &quot;my-group&quot;);props.put(&quot;key.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);props.put(&quot;value.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;);props.put(&quot;isolation.level&quot;, &quot;read_committed&quot;); // 可选，确保事务性消息的一致性KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;&gt;(props); 订阅主题 创建消费者实例后，订阅一个或多个主题，以便消费者能够从这些主题中获取消息。 1consumer.subscribe(Arrays.asList(&quot;my-topic&quot;)); 轮询消息 消费者使用 poll 方法从 Kafka 中拉取消息。poll 方法会阻塞指定的时间，并返回拉取到的消息记录。 1234567while (true) { ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofMillis(100)); for (ConsumerRecord&lt;String, String&gt; record : records) { // 处理消息 System.out.printf(&quot;offset = %d, key = %s, value = %s%n&quot;, record.offset(), record.key(), record.value()); }} 处理消息 在轮询到消息后，需要对消息进行处理。处理逻辑根据具体业务需求来实现。 1234for (ConsumerRecord&lt;String, String&gt; record : records) { // 处理消息的业务逻辑 process(record);} 提交偏移量 为了保证消息不会被重复处理或丢失，消费者需要提交已经处理过的消息偏移量。可以选择自动提交或手动提交偏移量。 自动提交：自动提交偏移量由 enable.auto.commit 属性控制。如果设置为 true，消费者会定期自动提交偏移量。 12props.put(&quot;enable.auto.commit&quot;, &quot;true&quot;);props.put(&quot;auto.commit.interval.ms&quot;, &quot;1000&quot;); 手动提交：手动提交提供了更细粒度的控制。可以在处理完一批消息后手动提交偏移量。 12345678910111213141516try { while (true) { ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofMillis(100)); for (ConsumerRecord&lt;String, String&gt; record : records) { // 处理消息 process(record); } consumer.commitSync(); // 同步提交偏移量 // 或者使用异步提交 // consumer.commitAsync(); }} catch (Exception e) { e.printStackTrace();} finally { consumer.close();} 关闭消费者 在应用程序关闭时，确保关闭消费者以释放资源。close 方法会确保任何未提交的偏移量被提交，并关闭网络连接。 1consumer.close(); 以下是一个完整的消费者示例代码： 1234567891011121314151617181920212223242526272829303132333435import org.apache.kafka.clients.consumer.ConsumerRecord;import org.apache.kafka.clients.consumer.ConsumerRecords;import org.apache.kafka.clients.consumer.KafkaConsumer;import java.time.Duration;import java.util.Arrays;import java.util.Properties;public class KafkaConsumerExample { public static void main(String[] args) { Properties props = new Properties(); props.put(&quot;bootstrap.servers&quot;, &quot;localhost:9092&quot;); props.put(&quot;group.id&quot;, &quot;my-group&quot;); props.put(&quot;key.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;); props.put(&quot;value.deserializer&quot;, &quot;org.apache.kafka.common.serialization.StringDeserializer&quot;); props.put(&quot;isolation.level&quot;, &quot;read_committed&quot;); KafkaConsumer&lt;String, String&gt; consumer = new KafkaConsumer&lt;&gt;(props); consumer.subscribe(Arrays.asList(&quot;my-topic&quot;)); try { while (true) { ConsumerRecords&lt;String, String&gt; records = consumer.poll(Duration.ofMillis(100)); for (ConsumerRecord&lt;String, String&gt; record : records) { System.out.printf(&quot;offset = %d, key = %s, value = %s%n&quot;, record.offset(), record.key(), record.value()); } consumer.commitSync(); } } catch (Exception e) { e.printStackTrace(); } finally { consumer.close(); } }} 2. 数据消费偏移量问题consumer默认会定时把当前消费到哪里的偏移量更新到Kafka 的内部主题 __consumer_offsets 中。这是一个特殊的主题，用于存储消费者组的偏移量信息。但是这会存在一些问题。比如 默认每5000ms(由auto.commit.interval.ms决定)自动更新一次偏移量，当consumer这次拉取了100条数据，我消费到了第50条时consumer崩溃了，此时还未更新偏移量，下一次consumer启动后，会重复消费那50条数据。 即使换成手动提交，也存在同样的问题，消费到一半，consumer崩溃了，还没走到手动提交那一步，kafka记录的偏移量是过时的，所有下一次consumer重启，一样会重复消费。 3. 事务级别的问题即使生产者使用了事务，却仍然可以导致consumer消费到不该消费的数据。 Kafka 的事务机制 事务性生产者： 当一个事务性生产者开始一个事务时，它会生成一个唯一的 transactional.id，并通过 beginTransaction() 开始事务。 所有在这个事务中的消息会被标记为事务性的，并且这些消息的状态（已提交或已中止）会被记录在事务日志中。 当事务成功完成时，调用 commitTransaction()，所有的消息都会被原子地标记为已提交。 如果事务失败，调用 abortTransaction()，所有在这个事务中的消息都会被标记为已中止，并不会对外可见。 事务协调器： Kafka 的事务协调器负责管理事务的状态。 它确保所有涉及的分区的一致性，并在事务提交或中止时更新事务日志。 消费者的隔离级别Kafka 消费者有两种隔离级别： read_uncommitted（默认值）： 在这种隔离级别下，消费者可以读取到所有的消息，包括未提交的事务性消息。 这种隔离级别可能会导致消费者读取到事务中止后的消息，从而出现消费者消费到未提交或中止事务的数据的情况。 read_committed： 在这种隔离级别下，消费者只能读取到已提交的事务性消息。 消费者会过滤掉未提交和已中止的事务消息，确保只消费到已经成功提交的消息。 使用这种隔离级别可以确保端到端的精确一次语义。 1consumerConfig.put(ConsumerConfig.ISOLATION_LEVEL_CONFIG, &quot;read_committed&quot;); 如果消费者的隔离级别设置为 read_uncommitted，那么它会读取到所有消息，包括未提交的事务性消息。因此，即使事务中止，消费者也可能已经读取到这些消息。 4. 消费者组一个消费者组只能订阅多个主题，组内的消费者共同消费这些主题。 一个分区只能由组内的一个消费者消费。 如果消费者组的消费者数量大于topic的分区数，那么有的consumer将会空闲，用作备用。 如果小于topic分区数，那么有的消费者会消费多个分区。 当消费者组的消费者数量大于topic的分区时，此时有消费者崩溃，那么空闲的消费者会代替它，那么如何从刚才消费的位置继续消费呢？ 当消费者处理完一批消息并提交偏移量时，会将偏移量信息写入到 __consumer_offsets 主题中。 记录的键包括消费者组 ID、主题名称和分区号，值是该分区的最新偏移量。 在消费者组重新平衡后，新分配到分区的消费者会从 __consumer_offsets 主题中读取对应的偏移量信息。 由于使用了消费者组 ID、主题名称和分区号的组合键，新的消费者能够准确读取到该分区的最新提交偏移量。 这些过程对于消费者都是透明的，并不需要代码手动操作。 分区分配策略消费者组的平衡过程中，分区和消费者没有强绑定关系，意味着某个分区之前由消费者A消费，也许之后会由消费者B消费。 至于如何分配，是由Leader决定的，第一个加入组的消费者成为Leader（群主）。 在 Apache Kafka 中，分区具体分配给组内消费者的过程是由消费者组协调器（称为群主）决定的。Kafka 提供了多种分区分配策略，以便更好地适应不同的使用场景和需求。主要的分配策略包括： RangeAssignor（范围分配）： 每个主题的分区列表按照范围进行划分，将连续的一组分区分配给一个消费者。 如果有多个主题，每个主题独立进行分区分配。 比如5分区3消费者，就是[1,2], [3,4], [5] RoundRobinAssignor（轮询）： 将所有订阅的主题的分区视为一个统一的分区列表，按照轮询的方式将分区依次分配给消费者。 这种策略通常能够实现较为均匀的分区分配，无论分区数和消费者数是否均匀。 StickyAssignor（粘性）： 第一次分配后，组成员保留分配给自己的分区信息 尝试在每次再平衡时保持分区分配的稳定性，尽量减少分区的重新分配。 有助于减少消费者的重新分配和重启开销。 CooperativeStickyAssignor（优化粘性）： 前面的基于EAGER协议，平衡时会让所有消费者放弃当前分区，关闭连接，清理资源，全部统一平衡。 CooperativeStickyAssignor 使用COOPERATIVE协议，小规模平衡 基于 StickyAssignor 进一步优化，减少在再平衡过程中的分区重新分配次 Custom Assignor： 用户可以实现自己的分区分配策略，只需实现 org.apache.kafka.clients.consumer.ConsumerPartitionAssignor 接口，并在配置中指定自定义的分配策略。 选择合适的分区分配策略取决于具体的使用场景和需求。例如，如果需要较高的分区分配稳定性，可以选择 StickyAssignor 或 CooperativeStickyAssignor；如果需要较为均匀的分区分配，可以选择 RoundRobinAssignor。 配置分配策略时，可以在消费者配置中指定 partition.assignment.strategy 属性，例如： 123partition.assignment.strategy=org.apache.kafka.clients.consumer.RoundRobinAssignor//orconfig.put(ConsumerConfig.PARTITION_ASSIGNMENT_STRATEGY_CONFIG, RoundRobinAssignor.class.getName()); Leader选举当一个新的消费者加入现有的消费者组时，Kafka 确实会触发消费者组的重新平衡（rebalance）。在重新平衡过程中，所有消费者会暂时断开与消费者组协调器的连接，然后重新加入消费者组。这是为了确保分区可以被均匀地重新分配给所有的消费者。 短暂中断： 在重新平衡过程中，消费者组内的所有消费者会有一个短暂的中断期，这段时间内不会有消息被消费。 负载均衡： 重新平衡确保分区能够均匀地分配给所有活跃的消费者，实现负载均衡。 领导者变化： 领导者消费者可能会发生变化，但这不会影响消息消费的整体流程，只是内部管理机制的一部分。 一般来说，消费者组的消费者的PARTITION_ASSIGNMENT_STRATEGY_CONFIG策略都保持一致，因此leader的更换并不会改变分区分配策略。","link":"/Hexo/2024/07/30/2024-H2/2024-07-30-18-58-27/"},{"title":"Kafka 更多延伸讨论","text":"1. 脑裂因为网络问题，导致kafka出现多个controller，那么剩余的broker应该认为谁是真正的controller呢？ 在zookeeper中引入controllor_epoch，表示纪元，每次controller变化，都会更新纪元值，这样其余的broker就能判断出来自controller的消息哪些是真controller，哪些是可以忽略的。 2. 零拷贝如下图是一种消息数据传输过程，需要把数据从磁盘中读取到页缓存，然后转化成用户态，再转移数据，再转化成内核态，在把数据传输，整个流程的效率是非常低的。 优化之后，利用系统接口调用，让数据流转不需要再内核和用户之间转化，并且流程更短，复制次数更少，效率更高。 零拷贝不是数据不经过拷贝，而是对于用户空间的Kafka来说，不需要拷贝。 3. 顺写日志顺写日志是一种数据结构，其中所有的写操作都是追加（append）到日志的末尾，而不是在日志中间进行随机写入。Kafka 的日志文件采用顺写日志结构，消息被顺序地追加到日志文件的末尾，每条消息都有一个唯一的偏移量（offset）用于标识其在日志中的位置。 当生产者发送消息给 Kafka broker 时，这些消息会被顺序地追加到对应分区的日志文件末尾。顺序写入意味着磁盘的写操作可以以很高的速度完成，因为硬盘（尤其是传统的磁盘驱动器）对于顺序写入的性能非常高，远高于随机写入。 消费者从 Kafka 读取消息时，是根据偏移量从日志中顺序读取消息的。由于日志文件是顺序写入的，消费者可以高效地顺序读取消息。消费者可以选择从特定的偏移量开始读取消息，以便实现灵活的消息处理。 为了管理日志文件的大小，Kafka 将每个分区的日志文件分为多个段（segment）。当一个段达到预设的大小或时间限制时，会关闭当前段并创建一个新的段。这种分段机制使得 Kafka 能够高效地管理日志文件，同时支持日志的删除和压缩。 Kafka 的顺写日志是其高性能和高可靠性的关键基础。通过将所有写入操作顺序追加到日志末尾，Kafka 能够高效地处理大量消息，并提供持久性保证和灵活的消费模式。顺写日志的结构使得 Kafka 在分布式环境中能够简单而高效地实现复制和故障恢复，同时支持日志保留和压缩，以适应不同的业务需求。 4. Kafka简单优化1. 操作系统Kafka 的网络客户端底层使用Java NI0的 Selector 方式，而 Selector 在 Linux 的实现是 epoll，在 Windows 上实现机制为 select。因此 Kafka 部署在 Linux 会有更高效的I/0 性能。数据在磁盘和网络之间进行传输时候，在 Linux 上可以享受到零拷贝机制带来的快捷和便利高效，而 Windows 在一定程度上会使用零拷贝操作。所以建议 Kafka 部署在Linux操作系统上。 2. 磁盘选择Kafka 存储方式为顺序读写，机械硬盘的最大劣势在于随机读写慢。所以使用机械硬盘并不会造成性能低下。所以磁盘选用普通机械硬盘即可，Kafka自身已经有冗余机制，而且通过分区的设计，实现了负载均衡的功能。不做磁盘组raid阵列也是可以的。使用机械磁盘成本也低得多。 3. 网络带宽设计场景:如果机房为干兆带宽，我们需要在一小时内处理 1TB的数据，需要多少台kafka 服务器？ 由于带宽为干兆网，1000Mbps=1Gbps，则每秒钟每个服务器能收到的数据量为1)1Gb=1000Mb假设 Kafka 占用整个服务器网络的 70%(其他 30%为别的服务预留)，则 Kafka可以使用到 700Mb的带宽，但是如果从常规角度考虑，我们不能总让 Katka顶满带宽峰值，所以需要预留出 2/3 甚至 3/4的资源，也就是说，Kanka 单台服务器使用带宽实际应为 700Mb/3=240Mb 3)1小时需要处理 1TB 数据，1TB=102410248M6-8000000Mb，则一秒钟处理数据量为:8000000Mb/3600s=2330Mb数据。需要的服务器台数为:2330Mb/240Mb~10 台。考虑到消息的副本数如果为 2，则需要 20 台服务器，副本如果为 3，则需要 30台服务器。 4. 内存配置Katka 运行过程中设计到的内存主要为 JVM的堆内存和操作系统的页缓存，每个Broker 节点的堆内存建议 10-15G内存，而数据文件(默认为 1G)的 25%在内存就可以了综合上述，Kafka 在大数据场景下能够流畅稳定运行至少需要11G，建议安装Kafka的服务器节点的内存至少大于等于 16G。 5. CPU在生产环境中，建议 CPU核数最少为 16 核，建议 32核以上，方可保证大数据环境中的 Katka集群正常处理与运行。 6. 集群容错 副本分配策略：一般建议2个及以上副本来保证高可用。 故障转移方案：Kafka某Broker故障后，会将其负责的分区副本转移到其他存活的Broker下，并自动选择新的主分区。 数据备份和恢复：kafka基于日志文件的存储方式，每个Broker上都有副本数据，可以通过配置策略来优化这部分。 7. 参数优化 参数名 默认参数值 位置 优化场景 备注 num.network.threads 3 服务端 低延迟 num.io.threads 8 服务端 低延迟 socket.send.buffer.bytes 102400 (100K) 服务端 高吞吐 socket.receive.buffer.bytes 65536 (64K) 服务端 高吞吐场景 max.in.flight.requests.per.connection 5 生产端 并等 buffer.memory 33554432 (32M) 生产端 高吞吐 batch.size 16384 (16K) 生产端 提高性能 linger.ms 0 生产端 提高性能 fetch.min.bytes 1 消费端 提高性能 网络交互次数 max.poll.records 500 消费端 批量处理 控制批量获取消息数量 fetch.max.bytes 57671680 (55M) 消费端 批量处理 控制批量获取消息字节大小 8. 压缩算法 压缩算法 压缩比率 压缩效率 解压缩效率 snappy 2.073 580m/s 2020m/s lz4 2.101 800m/s 4220m/s zstd 2.884 520m/s 1600m/s","link":"/Hexo/2024/07/31/2024-H2/2024-07-31-18-11-56/"},{"title":"Docker单点部署Seata(2.0.0) + Nacos(v2.3.0) + Mysql(5.7)","text":"系统环境docker desktop for windows v4.23.0nacos、mysql、seata三者都在bridge网络中 一、部署Nacoslanguage-bash123456docker run -itd \\ -e MODE=standalone -e NACOS_SERVER_PORT=8848 -p 8848:8848 --name=nacos_standalone nacos/nacos-server:v2.3.0 二、部署Mysqllanguage-bash12345docker run -itd \\ -e MYSQL_ROOT_PASSWORD=1009 -p 3306:3306 --name=mysql_itcast mysql:5.7 三、Seata准备工作1. 记住nacos、mysql、宿主机的iplanguage-bash1$ docker network inspect bridge 假设这里nacos是172.17.0.3，mysql是172.17.0.2 language-bash1ipconfig /all 这里假设宿主机ip为192.168.1.102 之后遇到上述三个ip，记得写成自己的 2. 建立数据库在mysql_itcast中新建seata数据库，然后导入以下脚本 language-sql12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273-- -------------------------------- The script used when storeMode is 'db' ---------------------------------- the table to store GlobalSession dataCREATE TABLE IF NOT EXISTS `global_table`( `xid` VARCHAR(128) NOT NULL, `transaction_id` BIGINT, `status` TINYINT NOT NULL, `application_id` VARCHAR(32), `transaction_service_group` VARCHAR(32), `transaction_name` VARCHAR(128), `timeout` INT, `begin_time` BIGINT, `application_data` VARCHAR(2000), `gmt_create` DATETIME, `gmt_modified` DATETIME, PRIMARY KEY (`xid`), KEY `idx_status_gmt_modified` (`status` , `gmt_modified`), KEY `idx_transaction_id` (`transaction_id`)) ENGINE = InnoDB DEFAULT CHARSET = utf8mb4;-- the table to store BranchSession dataCREATE TABLE IF NOT EXISTS `branch_table`( `branch_id` BIGINT NOT NULL, `xid` VARCHAR(128) NOT NULL, `transaction_id` BIGINT, `resource_group_id` VARCHAR(32), `resource_id` VARCHAR(256), `branch_type` VARCHAR(8), `status` TINYINT, `client_id` VARCHAR(64), `application_data` VARCHAR(2000), `gmt_create` DATETIME(6), `gmt_modified` DATETIME(6), PRIMARY KEY (`branch_id`), KEY `idx_xid` (`xid`)) ENGINE = InnoDB DEFAULT CHARSET = utf8mb4;-- the table to store lock dataCREATE TABLE IF NOT EXISTS `lock_table`( `row_key` VARCHAR(128) NOT NULL, `xid` VARCHAR(128), `transaction_id` BIGINT, `branch_id` BIGINT NOT NULL, `resource_id` VARCHAR(256), `table_name` VARCHAR(32), `pk` VARCHAR(36), `status` TINYINT NOT NULL DEFAULT '0' COMMENT '0:locked ,1:rollbacking', `gmt_create` DATETIME, `gmt_modified` DATETIME, PRIMARY KEY (`row_key`), KEY `idx_status` (`status`), KEY `idx_branch_id` (`branch_id`), KEY `idx_xid` (`xid`)) ENGINE = InnoDB DEFAULT CHARSET = utf8mb4;CREATE TABLE IF NOT EXISTS `distributed_lock`( `lock_key` CHAR(20) NOT NULL, `lock_value` VARCHAR(20) NOT NULL, `expire` BIGINT, primary key (`lock_key`)) ENGINE = InnoDB DEFAULT CHARSET = utf8mb4;INSERT INTO `distributed_lock` (lock_key, lock_value, expire) VALUES ('AsyncCommitting', ' ', 0);INSERT INTO `distributed_lock` (lock_key, lock_value, expire) VALUES ('RetryCommitting', ' ', 0);INSERT INTO `distributed_lock` (lock_key, lock_value, expire) VALUES ('RetryRollbacking', ' ', 0);INSERT INTO `distributed_lock` (lock_key, lock_value, expire) VALUES ('TxTimeoutCheck', ' ', 0); 3. Nacos远程配置文件访问Nacos网页，一般是http://localhost:8848/nacos/，新建一个配置seataServer.properties 具体内容如下： language-puppet12345678910111213141516171819202122232425262728293031323334353637383940414243444546store.mode=db#-----db-----store.db.datasource=druidstore.db.dbType=mysql# 需要根据mysql的版本调整driverClassName# mysql8及以上版本对应的driver：com.mysql.cj.jdbc.Driver# mysql8以下版本的driver：com.mysql.jdbc.Driverstore.db.driverClassName=com.mysql.jdbc.Driverstore.db.url=jdbc:mysql://172.17.0.2:3306/seata?useUnicode=true&amp;characterEncoding=utf8&amp;connectTimeout=1000&amp;socketTimeout=3000&amp;autoReconnect=true&amp;useSSL=falsestore.db.user= rootstore.db.password=1009# 数据库初始连接数store.db.minConn=1# 数据库最大连接数store.db.maxConn=20# 获取连接时最大等待时间 默认5000，单位毫秒store.db.maxWait=5000# 全局事务表名 默认global_tablestore.db.globalTable=global_table# 分支事务表名 默认branch_tablestore.db.branchTable=branch_table# 全局锁表名 默认lock_tablestore.db.lockTable=lock_tablestore.db.distributedLockTable=distributed_lock# 查询全局事务一次的最大条数 默认100store.db.queryLimit=100# undo保留天数 默认7天,log_status=1（附录3）和未正常清理的undoserver.undo.logSaveDays=7# undo清理线程间隔时间 默认86400000，单位毫秒server.undo.logDeletePeriod=86400000# 二阶段提交重试超时时长 单位ms,s,m,h,d,对应毫秒,秒,分,小时,天,默认毫秒。默认值-1表示无限重试# 公式: timeout&gt;=now-globalTransactionBeginTime,true表示超时则不再重试# 注: 达到超时时间后将不会做任何重试,有数据不一致风险,除非业务自行可校准数据,否者慎用server.maxCommitRetryTimeout=-1# 二阶段回滚重试超时时长server.maxRollbackRetryTimeout=-1# 二阶段提交未完成状态全局事务重试提交线程间隔时间 默认1000，单位毫秒server.recovery.committingRetryPeriod=1000# 二阶段异步提交状态重试提交线程间隔时间 默认1000，单位毫秒server.recovery.asynCommittingRetryPeriod=1000# 二阶段回滚状态重试回滚线程间隔时间 默认1000，单位毫秒server.recovery.rollbackingRetryPeriod=1000# 超时状态检测重试线程间隔时间 默认1000，单位毫秒，检测出超时将全局事务置入回滚会话管理器server.recovery.timeoutRetryPeriod=1000 四、部署Seata宿主机新建一个application.yml文件，内容如下 language-yaml12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455server: port: 7091spring: application: name: seata-serverlogging: config: classpath:logback-spring.xml file: path: ${ user.home}/logs/seata extend: logstash-appender: destination: 127.0.0.1:4560 kafka-appender: bootstrap-servers: 127.0.0.1:9092 topic: logback_to_logstashconsole: user: username: seata password: seataseata: config: # support: nacos, consul, apollo, zk, etcd3 type: nacos nacos: server-addr: 172.17.0.3:8848 namespace: group: DEFAULT_GROUP username: nacos password: nacos data-id: seataServer.properties registry: # support: nacos, eureka, redis, zk, consul, etcd3, sofa type: nacos nacos: application: seata-tc-server server-addr: 172.17.0.3:8848 group: DEFAULT_GROUP namespace: # tc集群名称 cluster: SH username: nacos password: nacos # server: # service-port: 8091 #If not configured, the default is '${server.port} + 1000' security: secretKey: SeataSecretKey0c382ef121d778043159209298fd40bf3850a017 tokenValidityInMilliseconds: 1800000 ignore: urls: /,/**/*.css,/**/*.js,/**/*.html,/**/*.map,/**/*.svg,/**/*.png,/**/*.ico,/console-fe/public/**,/api/v1/auth/login 然后用以下命令运行seata容器 language-bash123456789docker run --name seata-server \\ -itd \\ -p 8091:8091 \\ -p 7091:7091 \\ -e STORE_MODE=db \\ -e SEATA_IP=&quot;192.168.1.102&quot; \\ -e SEATA_PORT=8091 \\ -v &quot;path/to/application.yml:/seata-server/resources/application.yml&quot; \\ seataio/seata-server:2.0.0 五、初步检验Seata部署情况访问Seata网页，这里是http://192.168.1.102:7091/，输入两个seata后进入系统。 Nacos网页上查看Seata服务详情，ip为宿主机ip，不要是docker容器内网ip就行。 六、微服务使用Seata1.引入依赖language-xml12345678910111213141516171819&lt;!--seata--&gt;&lt;dependency&gt; &lt;groupId&gt;com.alibaba.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-alibaba-seata&lt;/artifactId&gt; &lt;exclusions&gt; &lt;!--版本较低，1.3.0，因此排除--&gt; &lt;exclusion&gt; &lt;artifactId&gt;seata-spring-boot-starter&lt;/artifactId&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;!--seata starter 采用1.4.2版本--&gt;&lt;dependency&gt; &lt;groupId&gt;io.seata&lt;/groupId&gt; &lt;artifactId&gt;seata-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.4.2&lt;/version&gt;&lt;!--2.0.0貌似有点问题，TCC模式BusinessActionContextParameter无效--&gt;&lt;/dependency&gt; 2. application.yml配置language-yaml123456789101112131415seata: registry: type: nacos nacos: # tc server-addr: localhost:8848 namespace: &quot;&quot; group: DEFAULT_GROUP application: seata-tc-server # tc服务在nacos中的服务名称 cluster: SH username: nacos password: nacos tx-service-group: seata-demo # 事务组，根据这个获取tc服务的cluster名称 service: vgroup-mapping: # 事务组与TC服务cluster的映射关系 seata-demo: SH 启动微服务后，除了可以看微服务的日志外，还可以看Seata容器日志，出现类似以下日志即为正常 language-txt12345672023-12-30 21:37:35 digest=seata-demo,192.168.222.1,17039434536432023-12-30 21:37:35 timestamp=17039434536432023-12-30 21:37:35 authVersion=V42023-12-30 21:37:35 vgroup=seata-demo2023-12-30 21:37:35 ip=192.168.222.12023-12-30 21:37:35 '},channel:[id: 0x7f82356a, L:/172.17.0.4:8091 - R:/172.17.0.1:35092],client version:2.0.02023-12-30 21:37:36 21:37:36.389 INFO --- [rverHandlerThread_1_6_500] [rocessor.server.RegRmProcessor] [ onRegRmMessage] [] : RM register success,message:RegisterRMRequest{resourceIds='jdbc:mysql://localhost:3306/seata_demo', version='2.0.0', applicationId='order-service', transactionServiceGroup='seata-demo', extraData='null'},channel:[id: 0x3a9f4e29, L:/172.17.0.4:8091 - R:/172.17.0.1:35096],client version:2.0.0 七、遇到的坑1. Nacos显示Seata服务的ip为容器内网ip导致微服务无法访问网上看到以下各种方法均无效 使用host网络 application.yml指定spring.cloud.nacos.discovery.ip 以下方法有效 容器创建时使用 -e SEATA_IP=&quot;宿主机ip&quot; 2. 使用host宿主机网络一开始为了图方便，给Nacos用过host网络，结果容器程序运行正常，打不开网页，玄学的一批。也给Seata使用host网络，为了配置文件里面不用自己手动查询nacos和mysql的ip，结果然并卵。 3. seata The distribute lock table is not config, please create the target table and config it这个是因为很多文档，都只有3张表，少了一张。官方文档说store.db.distributedLockTable是 1.5.1版本新增的参数。https://seata.io/zh-cn/docs/user/configurations但是很多文档和博客，都只有3张表，第4张在哪里呢？在这里https://seata.io/zh-cn/docs/ops/deploy-by-docker-compose.html里面写到nacos注册中心，db存储时会提供 [建表脚本]以及最后最重要的是，要在Nacos配置中心配置seataServer.properties时，要多加一行 language-bash1store.db.distributedLockTable=distributed_lock 这点在官网文档都没有提及。 4. 高版本中BusinessActionContextParameter和TwoPhaseBusinessAction推荐都放在实现类中，接口上的做法后续将会废除具体参考这个Issue2.0.0 TCC模式@BusinessActionContextParameter修饰的参数失效，无法在BusinessActionContext获取","link":"/Hexo/2024/01/04/2024-H1/2024-01-04-15-48-34/"},{"title":"安装Cygwin的包管理器apt-cyg并安装tree命令","text":"一、从官网添加必要软件包1. 安装因为第一次安装cygwin时走的都是默认选项，所以这里是二次添加额外包。打开官网，下载安装程序。 下载好后运行 一路确定直到软件包选择页面添加以下包,双击对应行的新增列即可添加包。 dos2unix wget 下一步会展示包的更改，在里面检查有没有上述两个包。然后一路确认。 2. 检查回到cygwin命令行看看确认一下 language-txt123456789$ wget -VGNU Wget 1.21.4 在 cygwin 上编译。$ dos2unix -Vdos2unix 7.5.1 (2023-08-29)Cygwin版本。有Unicode UTF-16 支持。 二、安装apt-cyg1. 下载安装这里是apt-cyg的官方仓库在cygwin命令行中用git去下载它，或者浏览器下载复制到cygwin当中。 language-bash12345678#使用以下命令从GitHub克隆apt-cyggit clone https://github.com/transcode-open/apt-cyg#进入apt-cyg目录cd apt-cyg#将apt-cyg安装到/bin目录下install apt-cyg /bin#使用apt-cyg安装tree命令apt-cyg install tree 你可能会遇到以下报错 language-txt1234$ apt-cyg install tree/usr/bin/apt-cyg: 行 25: $'\\r': 未找到命令/usr/bin/apt-cyg: 行 121: 未预期的记号 &quot;$'{\\r'&quot; 附近有语法错误'usr/bin/apt-cyg: 行 121: `function wget { 如果遇到就看下面修复章节 2.修复受windows文件系统影响，apt-cyg一些特殊符号不被linux认识。具体可以参考以下帖子： Errors when i run apt-cyg command 使用dos2unix将apt-cyg从windows系统版本转为linux系统版本。 language-txt12$ dos2unix /usr/bin/apt-cyg dos2unix: 正在转换文件 /usr/bin/apt-cyg 为Unix格式... 三、安装tree命令1. 安装修复好后，再次执行apt-cyg install tree安装即可。 language-bash12345678910111213141516171819mumu@DESKTOP-DPT8S0M ~/Software/apt-cyg$ apt-cyg install treeInstalling treetree-1.7.0-1.tar.xz: 失败sha512sum: 警告：1 个校验和不匹配--2024-01-05 17:41:48-- https://mirrors.163.com/cygwin//x86_64/release/tree/tree-1.7.0-1.tar.xz正在解析主机 mirrors.163.com (mirrors.163.com)... 60.191.80.11正在连接 mirrors.163.com (mirrors.163.com)|60.191.80.11|:443... 已连接。已发出 HTTP 请求，正在等待回应... 200 OK长度：46456 (45K) [application/octet-stream]正在保存至: &quot;tree-1.7.0-1.tar.xz&quot;tree-1.7.0-1.tar.xz 100%[==================================================================================================================================&gt;] 45.37K 88.5KB/s 用时 0.5s 2024-01-05 17:41:50 (88.5 KB/s) - 已保存 &quot;tree-1.7.0-1.tar.xz&quot; [46456/46456])tree-1.7.0-1.tar.xz: 成功Unpacking...Package tree installed 2.检验language-bash1234567891011$ tree -L 3.└── Software └── apt-cyg ├── apt-cyg ├── changelog.md ├── LICENSE ├── readme.md └── status.md2 directories, 5 files","link":"/Hexo/2024/01/05/2024-H1/2024-01-05-17-45-30/"},{"title":"Docker-Compose部署Redis(v7.2)哨兵模式","text":"环境 docker desktop for windows 4.23.0 redis 7.2 一、前提准备1. 主从集群首先需要有一个redis主从集群，才能接着做redis哨兵。具体可以参考下面这篇文章Docker-Compose部署Redis(v7.2)主从模式(之后简称”主从模式博文“) 2. 文件夹结构和主从模式不同的是，redis sentinel（哨兵）会更改你的conf文件，无论是redis server节点还是sentinel节点本身，都可能被修改，所以这里需要注意文件权限问题。不然会一直警告Sentinel was not able to save the new configuration on disk。 有兴趣可以参考以下几个帖子，或者接着本文做就行了。 WARNING: Sentinel was not able to save the new configuration on disk!!!: Device or resource busy Redis sentinel 6.0.9 in docker: Could not create tmp config file (Permission denied) #8172 WARNING: Sentinel was not able to save the new configuration on disk!!!: Device or resource busy #287 总的来说，需要对主从模式博文里提到的文件夹结构做一定改善和添加，具体如下： language-txt1234567891011121314151617181920cluster/├── docker-compose.yaml├── master│ └── conf│ └── redis.conf├── replica1│ └── conf│ └── redis.conf├── replica2│ └── conf│ └── redis.conf├── sentinel1│ └── conf│ └── sentinel.conf├── sentinel2│ └── conf│ └── sentinel.conf└── sentinel3 └── conf └── sentinel.conf 其中redis.conf和docker-compose.yaml和主从模式博文内容暂时保持一致，其余的都是新增的，暂时保持空白即可。 二、配置文件1. redis server配置文件保持不变 2. redis sentinel配置文件对于上述三个sentinel.conf内容都填入以下 language-sql12345sentinel monitor mymaster 172.30.1.2 6379 2sentinel down-after-milliseconds mymaster 5000sentinel failover-timeout mymaster 60000sentinel auth-pass mymaster 1009dir &quot;/data&quot; 意思分别是 监控的主节点：通过 sentinel monitor 指定要监控的主节点。这包括一个用户定义的名称（如 mymaster）、主节点的地址、端口号和一个”仲裁”阈值，后者表示要进行故障转移所需的最小 Sentinel 投票数量。 故障检测：设置 Sentinel 判断主节点是否下线所需的时间 故障转移设置：配置故障转移的行为，如故障转移的超时时间 认证密码（如果主节点设置了密码）：如果主节点设置了密码，Sentinel 需要这个密码来连接主节点和副本节点 设置 Sentinel 的工作目录 3. docker compose文件language-yaml1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495969798version: '3.8'networks: redis-network: driver: bridge ipam: driver: default config: - subnet: 172.30.1.0/24services: redis-master: container_name: redis-master image: redis:7.2 volumes: - ./master/conf:/usr/local/etc/redis# - ./master/data:/data ports: - &quot;7001:6379&quot; command: [&quot;redis-server&quot;, &quot;/usr/local/etc/redis/redis.conf&quot;] networks: redis-network: ipv4_address: 172.30.1.2 redis-replica1: container_name: redis-replica1 image: redis:7.2 volumes: - ./replica1/conf:/usr/local/etc/redis# - ./replica1/data:/data ports: - &quot;7002:6379&quot; command: [&quot;redis-server&quot;, &quot;/usr/local/etc/redis/redis.conf&quot;] depends_on: - redis-master networks: redis-network: ipv4_address: 172.30.1.3 redis-replica2: container_name: redis-replica2 image: redis:7.2 volumes: - ./replica2/conf:/usr/local/etc/redis# - ./replica2/data:/data ports: - &quot;7003:6379&quot; command: [&quot;redis-server&quot;, &quot;/usr/local/etc/redis/redis.conf&quot;] depends_on: - redis-master networks: redis-network: ipv4_address: 172.30.1.4 redis-sentinel1: container_name: redis-sentinel1 image: redis:7.2 volumes: - ./sentinel1/conf:/usr/local/etc/redis ports: - &quot;27001:26379&quot; command: [&quot;redis-sentinel&quot;, &quot;/usr/local/etc/redis/sentinel.conf&quot;] depends_on: - redis-master networks: redis-network: ipv4_address: 172.30.1.11 redis-sentinel2: container_name: redis-sentinel2 image: redis:7.2 volumes: - ./sentinel2/conf:/usr/local/etc/redis ports: - &quot;27002:26379&quot; command: [ &quot;redis-sentinel&quot;, &quot;/usr/local/etc/redis/sentinel.conf&quot; ] depends_on: - redis-master networks: redis-network: ipv4_address: 172.30.1.12 redis-sentinel3: container_name: redis-sentinel3 image: redis:7.2 volumes: - ./sentinel3/conf:/usr/local/etc/redis ports: - &quot;27003:26379&quot; command: [ &quot;redis-sentinel&quot;, &quot;/usr/local/etc/redis/sentinel.conf&quot; ] depends_on: - redis-master networks: redis-network: ipv4_address: 172.30.1.13 需要注意以下几点 和主从模式博文不同，这里所有的配置文件挂载都采用文件夹挂载而非单文件挂载 这里自定义了bridge子网并限定了范围，如果该范围已经被使用，请更换。 这里没有对data进行-v挂载，如果要挂载，请注意宿主机对应文件夹权限问题。 主节点地址为172.30.1.2，如果更改请注意sentinel.conf中也需要更改。 三、运行 在运行之前，记得备份一下所有的conf文件，因为sentinel会修改挂载到容器的conf。 language-bash1docker-compose -p redis-cluster up -d 查看其中一个sentinel节点的日志，可以看到监听端口是26379，同时监测主节点mymaster 172.30.1.2 6379，以及添加了172.30.1.4 6379和172.30.1.3 6379两个从节点，并且感应到了位于172.30.1.13 26379和172.30.1.12 26379两个同为sentinel节点的服务。 language-txt1234567891011122024-01-05 18:06:40 1:X 05 Jan 2024 10:06:40.758 * Running mode=sentinel, port=26379.2024-01-05 18:06:40 1:X 05 Jan 2024 10:06:40.789 * Sentinel new configuration saved on disk2024-01-05 18:06:40 1:X 05 Jan 2024 10:06:40.790 * Sentinel ID is 499007c98c0a165b13e026a4443ceb890695c1912024-01-05 18:06:40 1:X 05 Jan 2024 10:06:40.790 # +monitor master mymaster 172.30.1.2 6379 quorum 22024-01-05 18:06:40 1:X 05 Jan 2024 10:06:40.791 * +slave slave 172.30.1.4:6379 172.30.1.4 6379 @ mymaster 172.30.1.2 63792024-01-05 18:06:40 1:X 05 Jan 2024 10:06:40.815 * Sentinel new configuration saved on disk2024-01-05 18:06:42 1:X 05 Jan 2024 10:06:42.055 * +sentinel sentinel bcfaed15fb01e7ad03b013fe5e964479c1a1f138 172.30.1.13 26379 @ mymaster 172.30.1.2 63792024-01-05 18:06:42 1:X 05 Jan 2024 10:06:42.093 * Sentinel new configuration saved on disk2024-01-05 18:06:42 1:X 05 Jan 2024 10:06:42.356 * +sentinel sentinel 92d9a1419be1256d1715df2aa17cea4bbacfdf60 172.30.1.12 26379 @ mymaster 172.30.1.2 63792024-01-05 18:06:42 1:X 05 Jan 2024 10:06:42.376 * Sentinel new configuration saved on disk2024-01-05 18:06:50 1:X 05 Jan 2024 10:06:50.823 * +slave slave 172.30.1.3:6379 172.30.1.3 6379 @ mymaster 172.30.1.2 63792024-01-05 18:06:50 1:X 05 Jan 2024 10:06:50.837 * Sentinel new configuration saved on disk 四、测试直接让redis-master容器停止运行，查看sentinel日志，可以看到sentinel监测到master节点挂掉后，选举了172.30.1.3为新的主节点，并将其余两个作为slave节点。 language-txt1234567891011121314151617181920212223242024-01-05 18:10:08 1:X 05 Jan 2024 10:10:08.896 # +sdown master mymaster 172.30.1.2 63792024-01-05 18:10:08 1:X 05 Jan 2024 10:10:08.968 # +odown master mymaster 172.30.1.2 6379 #quorum 2/22024-01-05 18:10:08 1:X 05 Jan 2024 10:10:08.968 # +new-epoch 12024-01-05 18:10:08 1:X 05 Jan 2024 10:10:08.968 # +try-failover master mymaster 172.30.1.2 63792024-01-05 18:10:08 1:X 05 Jan 2024 10:10:08.987 * Sentinel new configuration saved on disk2024-01-05 18:10:08 1:X 05 Jan 2024 10:10:08.987 # +vote-for-leader 499007c98c0a165b13e026a4443ceb890695c191 12024-01-05 18:10:08 1:X 05 Jan 2024 10:10:08.990 * 92d9a1419be1256d1715df2aa17cea4bbacfdf60 voted for 92d9a1419be1256d1715df2aa17cea4bbacfdf60 12024-01-05 18:10:09 1:X 05 Jan 2024 10:10:09.021 * bcfaed15fb01e7ad03b013fe5e964479c1a1f138 voted for 499007c98c0a165b13e026a4443ceb890695c191 12024-01-05 18:10:09 1:X 05 Jan 2024 10:10:09.054 # +elected-leader master mymaster 172.30.1.2 63792024-01-05 18:10:09 1:X 05 Jan 2024 10:10:09.054 # +failover-state-select-slave master mymaster 172.30.1.2 63792024-01-05 18:10:09 1:X 05 Jan 2024 10:10:09.125 # +selected-slave slave 172.30.1.3:6379 172.30.1.3 6379 @ mymaster 172.30.1.2 63792024-01-05 18:10:09 1:X 05 Jan 2024 10:10:09.125 * +failover-state-send-slaveof-noone slave 172.30.1.3:6379 172.30.1.3 6379 @ mymaster 172.30.1.2 63792024-01-05 18:10:09 1:X 05 Jan 2024 10:10:09.209 * +failover-state-wait-promotion slave 172.30.1.3:6379 172.30.1.3 6379 @ mymaster 172.30.1.2 63792024-01-05 18:10:10 1:X 05 Jan 2024 10:10:10.033 * Sentinel new configuration saved on disk2024-01-05 18:10:10 1:X 05 Jan 2024 10:10:10.033 # +promoted-slave slave 172.30.1.3:6379 172.30.1.3 6379 @ mymaster 172.30.1.2 63792024-01-05 18:10:10 1:X 05 Jan 2024 10:10:10.033 # +failover-state-reconf-slaves master mymaster 172.30.1.2 63792024-01-05 18:10:10 1:X 05 Jan 2024 10:10:10.094 * +slave-reconf-sent slave 172.30.1.4:6379 172.30.1.4 6379 @ mymaster 172.30.1.2 63792024-01-05 18:10:10 1:X 05 Jan 2024 10:10:10.262 * +slave-reconf-inprog slave 172.30.1.4:6379 172.30.1.4 6379 @ mymaster 172.30.1.2 63792024-01-05 18:10:10 1:X 05 Jan 2024 10:10:10.262 * +slave-reconf-done slave 172.30.1.4:6379 172.30.1.4 6379 @ mymaster 172.30.1.2 63792024-01-05 18:10:10 1:X 05 Jan 2024 10:10:10.338 # +failover-end master mymaster 172.30.1.2 63792024-01-05 18:10:10 1:X 05 Jan 2024 10:10:10.338 # +switch-master mymaster 172.30.1.2 6379 172.30.1.3 63792024-01-05 18:10:10 1:X 05 Jan 2024 10:10:10.338 * +slave slave 172.30.1.4:6379 172.30.1.4 6379 @ mymaster 172.30.1.3 63792024-01-05 18:10:10 1:X 05 Jan 2024 10:10:10.338 * +slave slave 172.30.1.2:6379 172.30.1.2 6379 @ mymaster 172.30.1.3 63792024-01-05 18:10:10 1:X 05 Jan 2024 10:10:10.373 * Sentinel new configuration saved on disk 接着让我们看看172.30.1.3的日志，也就是redis-replica1的日志，可以看到与主节点连接失败后，它开启了主节点模式MASTER MODE enabled。 language-txt12345678910112024-01-05 18:10:03 1:S 05 Jan 2024 10:10:03.812 * Reconnecting to MASTER 172.30.1.2:63792024-01-05 18:10:03 1:S 05 Jan 2024 10:10:03.813 * MASTER &lt;-&gt; REPLICA sync started2024-01-05 18:10:03 1:S 05 Jan 2024 10:10:03.813 # Error condition on socket for SYNC: Connection refused2024-01-05 18:10:04 1:S 05 Jan 2024 10:10:04.582 * Connecting to MASTER 172.30.1.2:63792024-01-05 18:10:04 1:S 05 Jan 2024 10:10:04.582 * MASTER &lt;-&gt; REPLICA sync started2024-01-05 18:10:09 1:M 05 Jan 2024 10:10:09.209 * Discarding previously cached master state.2024-01-05 18:10:09 1:M 05 Jan 2024 10:10:09.209 * Setting secondary replication ID to 5032654a1279c56d758c93a4eb1c4b89c99975a9, valid up to offset: 40756. New replication ID is d3464601d550e1159d91234567a366fa1f1a0b5e2024-01-05 18:10:09 1:M 05 Jan 2024 10:10:09.209 * MASTER MODE enabled (user request from 'id=8 addr=172.30.1.11:55710 laddr=172.30.1.3:6379 fd=13 name=sentinel-499007c9-cmd age=199 idle=0 flags=x db=0 sub=0 psub=0 ssub=0 multi=4 qbuf=188 qbuf-free=20286 argv-mem=4 multi-mem=169 rbs=2048 rbp=1024 obl=45 oll=0 omem=0 tot-mem=23717 events=r cmd=exec user=default redir=-1 resp=2 lib-name= lib-ver=')2024-01-05 18:10:09 1:M 05 Jan 2024 10:10:09.229 * CONFIG REWRITE executed with success.2024-01-05 18:10:10 1:M 05 Jan 2024 10:10:10.120 * Replica 172.30.1.4:6379 asks for synchronization2024-01-05 18:10:10 1:M 05 Jan 2024 10:10:10.120 * Partial resynchronization request from 172.30.1.4:6379 accepted. Sending 567 bytes of backlog starting from offset 40756. 并且还有redis-replica2的日志，里面会显示将数据同步请求地址变成了172.30.1.3而不是先前的172.30.1.2。 接着连接redis-replica1容器看看，发现这个节点以前作为从节点时是只读节点，现在可以写入数据了。 language-txt1234567root@1eefea35001f:/data# redis-cli 127.0.0.1:6379&gt; auth 1009OK127.0.0.1:6379&gt; set num 8766OK127.0.0.1:6379&gt; get num&quot;8766&quot; 并且会发现另外两个节点变成只读了，同时，即使先前的主节点又恢复正常了，它不会去夺回master地位。 测试成功。","link":"/Hexo/2024/01/05/2024-H1/2024-01-05-18-20-53/"},{"title":"Docker-Compose部署Redis(v7.2)主从模式","text":"环境 docker desktop for windows 4.23.0 redis 7.2 一、前提准备1. redis配置文件因为Redis 7.2 docker镜像里面没有配置文件，所以需要去redis官网下载一个复制里面的redis.conf博主这里用的是7.2.3版本的redis.conf，这个文件就在解压后第一层文件夹里。 2. 下载redis镜像language-bash1docker pull redis:7.2 3. 文件夹结构如下建立cluster文件夹，并复制出三份conf文件到如图位置。 二、docker-composedocker-compose文件具体内容如下。 language-yaml1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253version: '3.8'networks: redis-network: driver: bridge ipam: driver: default config: - subnet: 172.30.1.0/24services: redis-master: container_name: redis-master image: redis:7.2 volumes: - ./master/redis.conf:/usr/local/etc/redis/redis.conf# - ./master/data:/data ports: - &quot;7001:6379&quot; command: [&quot;redis-server&quot;, &quot;/usr/local/etc/redis/redis.conf&quot;] networks: redis-network: ipv4_address: 172.30.1.2 redis-replica1: container_name: redis-replica1 image: redis:7.2 volumes: - ./replica1/redis.conf:/usr/local/etc/redis/redis.conf# - ./replica1/data:/data ports: - &quot;7002:6379&quot; command: [&quot;redis-server&quot;, &quot;/usr/local/etc/redis/redis.conf&quot;] depends_on: - redis-master networks: redis-network: ipv4_address: 172.30.1.3 redis-replica2: container_name: redis-replica2 image: redis:7.2 volumes: - ./replica2/redis.conf:/usr/local/etc/redis/redis.conf# - ./replica2/data:/data ports: - &quot;7003:6379&quot; command: [&quot;redis-server&quot;, &quot;/usr/local/etc/redis/redis.conf&quot;] depends_on: - redis-master networks: redis-network: ipv4_address: 172.30.1.4 需要注意以下几点 这里自定义了bridge子网并限定了范围，如果该范围已经被使用，请更换。 这里没有对data进行-v挂载，如果要挂载，请注意宿主机对应文件夹权限问题。 三、主从配置1.主节点配置文件主节点对应的配置文件是master/redis.conf，需要做以下修改 bind将bind 127.0.0.1 -::1修改为bind 0.0.0.0，监听来自任意网络接口的连接。 protected-mode将protected-mode设置为no，关闭保护模式，接收远程连接。 masterauth将masterauth设置为1009，这是从节点连接到主节点的认证密码，你可以指定为其他的。 requirepass将requirepass设置为1009，这是客户端连接到本节点的认证密码，你可以指定为其他的。 2.从节点配置文件把上面主节点的配置文件复制粘贴，然后继续做以下更改，就可以作为从节点配置文件了 replicaof旧版本添加一行replicaof redis-master 6379，表示本节点为从节点，并且主节点ip为redis-master，端口为6379。这里你也可以把ip填成172.30.1.2，因为在docker-compose中我们为各节点分配了固定的ip，以及端口是6379而不是映射的700x，这些都是docker的知识，这里不再赘述。 redis在5.0引入了replica的概念来替换slave，所以后续的新版本推荐使用replicaof，即便slaveof目前仍然支持。 四、运行配置好三个节点的配置文件后，用以下命令运行整个服务 language-shell1docker-compose -p redis-cluster up -d 查看主节点日志，可以看到主节点向172.30.1.3和172.30.1.4两个从节点同步数据，并且连接正常，以及一系列success。 language-bash1234567891011121314151617182024-01-05 15:12:59 1:M 05 Jan 2024 07:12:59.008 * Opening AOF incr file appendonly.aof.1.incr.aof on server start2024-01-05 15:12:59 1:M 05 Jan 2024 07:12:59.008 * Ready to accept connections tcp2024-01-05 15:13:00 1:M 05 Jan 2024 07:13:00.996 * Replica 172.30.1.4:6379 asks for synchronization2024-01-05 15:13:00 1:M 05 Jan 2024 07:13:00.996 * Full resync requested by replica 172.30.1.4:63792024-01-05 15:13:00 1:M 05 Jan 2024 07:13:00.996 * Replication backlog created, my new replication IDs are '5bef8fa8e58042f1aee8eae528c6e10228a0c96b' and '0000000000000000000000000000000000000000'2024-01-05 15:13:00 1:M 05 Jan 2024 07:13:00.996 * Delay next BGSAVE for diskless SYNC2024-01-05 15:13:01 1:M 05 Jan 2024 07:13:01.167 * Replica 172.30.1.3:6379 asks for synchronization2024-01-05 15:13:01 1:M 05 Jan 2024 07:13:01.167 * Full resync requested by replica 172.30.1.3:63792024-01-05 15:13:01 1:M 05 Jan 2024 07:13:01.167 * Delay next BGSAVE for diskless SYNC2024-01-05 15:13:05 1:M 05 Jan 2024 07:13:05.033 * Starting BGSAVE for SYNC with target: replicas sockets2024-01-05 15:13:05 1:M 05 Jan 2024 07:13:05.033 * Background RDB transfer started by pid 202024-01-05 15:13:05 20:C 05 Jan 2024 07:13:05.035 * Fork CoW for RDB: current 0 MB, peak 0 MB, average 0 MB2024-01-05 15:13:05 1:M 05 Jan 2024 07:13:05.035 * Diskless rdb transfer, done reading from pipe, 2 replicas still up.2024-01-05 15:13:05 1:M 05 Jan 2024 07:13:05.052 * Background RDB transfer terminated with success2024-01-05 15:13:05 1:M 05 Jan 2024 07:13:05.052 * Streamed RDB transfer with replica 172.30.1.4:6379 succeeded (socket). Waiting for REPLCONF ACK from replica to enable streaming2024-01-05 15:13:05 1:M 05 Jan 2024 07:13:05.052 * Synchronization with replica 172.30.1.4:6379 succeeded2024-01-05 15:13:05 1:M 05 Jan 2024 07:13:05.052 * Streamed RDB transfer with replica 172.30.1.3:6379 succeeded (socket). Waiting for REPLCONF ACK from replica to enable streaming2024-01-05 15:13:05 1:M 05 Jan 2024 07:13:05.052 * Synchronization with replica 172.30.1.3:6379 succeeded 接着看看从节点日志，可以看到Connecting to MASTER redis-master:6379，向主节点连接并申请同步数据，以及一系列success。 language-bash1234567891011121314151617181920212223242024-01-05 15:13:01 1:S 05 Jan 2024 07:13:01.166 * Connecting to MASTER redis-master:63792024-01-05 15:13:01 1:S 05 Jan 2024 07:13:01.166 * MASTER &lt;-&gt; REPLICA sync started2024-01-05 15:13:01 1:S 05 Jan 2024 07:13:01.166 * Non blocking connect for SYNC fired the event.2024-01-05 15:13:01 1:S 05 Jan 2024 07:13:01.167 * Master replied to PING, replication can continue...2024-01-05 15:13:01 1:S 05 Jan 2024 07:13:01.167 * Partial resynchronization not possible (no cached master)2024-01-05 15:13:05 1:S 05 Jan 2024 07:13:05.033 * Full resync from master: 5bef8fa8e58042f1aee8eae528c6e10228a0c96b:02024-01-05 15:13:05 1:S 05 Jan 2024 07:13:05.035 * MASTER &lt;-&gt; REPLICA sync: receiving streamed RDB from master with EOF to disk2024-01-05 15:13:05 1:S 05 Jan 2024 07:13:05.038 * MASTER &lt;-&gt; REPLICA sync: Flushing old data2024-01-05 15:13:05 1:S 05 Jan 2024 07:13:05.038 * MASTER &lt;-&gt; REPLICA sync: Loading DB in memory2024-01-05 15:13:05 1:S 05 Jan 2024 07:13:05.056 * Loading RDB produced by version 7.2.32024-01-05 15:13:05 1:S 05 Jan 2024 07:13:05.056 * RDB age 0 seconds2024-01-05 15:13:05 1:S 05 Jan 2024 07:13:05.056 * RDB memory usage when created 0.90 Mb2024-01-05 15:13:05 1:S 05 Jan 2024 07:13:05.056 * Done loading RDB, keys loaded: 1, keys expired: 0.2024-01-05 15:13:05 1:S 05 Jan 2024 07:13:05.057 * MASTER &lt;-&gt; REPLICA sync: Finished with success2024-01-05 15:13:05 1:S 05 Jan 2024 07:13:05.057 * Creating AOF incr file temp-appendonly.aof.incr on background rewrite2024-01-05 15:13:05 1:S 05 Jan 2024 07:13:05.057 * Background append only file rewriting started by pid 212024-01-05 15:13:05 21:C 05 Jan 2024 07:13:05.067 * Successfully created the temporary AOF base file temp-rewriteaof-bg-21.aof2024-01-05 15:13:05 21:C 05 Jan 2024 07:13:05.068 * Fork CoW for AOF rewrite: current 0 MB, peak 0 MB, average 0 MB2024-01-05 15:13:05 1:S 05 Jan 2024 07:13:05.084 * Background AOF rewrite terminated with success2024-01-05 15:13:05 1:S 05 Jan 2024 07:13:05.084 * Successfully renamed the temporary AOF base file temp-rewriteaof-bg-21.aof into appendonly.aof.5.base.rdb2024-01-05 15:13:05 1:S 05 Jan 2024 07:13:05.084 * Successfully renamed the temporary AOF incr file temp-appendonly.aof.incr into appendonly.aof.5.incr.aof2024-01-05 15:13:05 1:S 05 Jan 2024 07:13:05.093 * Removing the history file appendonly.aof.4.incr.aof in the background2024-01-05 15:13:05 1:S 05 Jan 2024 07:13:05.093 * Removing the history file appendonly.aof.4.base.rdb in the background2024-01-05 15:13:05 1:S 05 Jan 2024 07:13:05.101 * Background AOF rewrite finished successfully 五、测试用你喜欢的docker容器连接工具或者redis连接工具来连接主节点redis服务，只要能进入redis-cli就行。这里以docker容器连接为例。 主节点设置一个字段并查看从节点信息 language-txt12345678910111213141516171819202122root@ac1ecfc4e3a5:/data# redis-cli 127.0.0.1:6379&gt; auth 1009OK127.0.0.1:6379&gt; set num 67899OK127.0.0.1:6379&gt; get num&quot;67899&quot;127.0.0.1:6379&gt; INFO replication# Replicationrole:masterconnected_slaves:2slave0:ip=172.30.1.4,port=6379,state=online,offset=3388,lag=1slave1:ip=172.30.1.3,port=6379,state=online,offset=3388,lag=1master_failover_state:no-failovermaster_replid:5bef8fa8e58042f1aee8eae528c6e10228a0c96bmaster_replid2:0000000000000000000000000000000000000000master_repl_offset:3388second_repl_offset:-1repl_backlog_active:1repl_backlog_size:1048576repl_backlog_first_byte_offset:1repl_backlog_histlen:3388 从节点获取 language-txt12345root@a3016db388e3:/data# redis-cli 127.0.0.1:6379&gt; auth 1009OK127.0.0.1:6379&gt; get num&quot;67899&quot; 测试成功。","link":"/Hexo/2024/01/05/2024-H1/2024-01-05-18-21-20/"},{"title":"Idea连接Docker在本地(Windows)开发SpringBoot","text":"当一些需要的服务在docker容器中运行时，因为docker网络等种种原因，不得不把在idea开发的springboot项目放到docker容器中才能做测试或者运行。 1. 新建运行配置 2. 修改运行目标 3. 设置新目标Docker推荐使用openjdk镜像即可，运行选项就是平时运行Docker的形参，--rm是指当容器停止时自动删除，-p暴露端口，一般都需要。包括--network指定网络有需要也可以加上。 等待idea自动执行完成，下一步 保持默认即可，创建。 4. 选择运行主类 根据自己的情况选择一个。 5. 运行 成功。","link":"/Hexo/2024/01/05/2024-H1/2024-01-05-21-24-28/"},{"title":"SpringBoot基于哨兵模式的Redis(7.2)集群实现读写分离","text":"环境 docker desktop for windows 4.23.0 redis 7.2 Idea 一、前提条件先根据以下文章搭建一个Redis集群 Docker-Compose部署Redis(v7.2)主从模式 Docker-Compose部署Redis(v7.2)哨兵模式 部署完后，redis集群看起来大致如下图 二、SpringBoot访问Redis集群1. 引入依赖需要注意的是lettuce-core版本问题，不能太旧，否则不兼容新版的Redis。 language-xml123456789&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.lettuce&lt;/groupId&gt; &lt;artifactId&gt;lettuce-core&lt;/artifactId&gt; &lt;version&gt;6.1.4.RELEASE&lt;/version&gt; &lt;!-- 或更高版本 --&gt; &lt;/dependency&gt; 2. yaml配置在application.yml加入以下配置。第一个password是用于sentinel节点验证，第二个password用于数据节点验证。 language-yaml12345678910spring: redis: sentinel: master: mymaster nodes: - 172.30.1.11:26379 - 172.30.1.12:26379 - 172.30.1.13:26379 password: 1009 password: 1009 这里关于sentinel的ip问题后面会讲解。 3. 设置读写分离在任意配置类中写一个Bean，本文简单起见，直接写在SpringBoot启动类了。 language-java12345@Beanpublic LettuceClientConfigurationBuilderCustomizer clientConfigurationBuilderCustomizer(){ return clientConfigurationBuilder -&gt; clientConfigurationBuilder.readFrom(ReadFrom.REPLICA_PREFERRED);} 这里的ReadFrom是配置Redis的读取策略，是一个枚举，包括下面选择： MASTER：从主节点读取 MASTER_PREFERRED:优先从master节点读取，master不可用才读取replica REPLICA:从slave (replica)节点读取 REPLICA_PREFERRED：优先从slave （replica）节点读取，所有的slave都不可用才读取master 至于哪些节点支持读，哪些支持写，因为redis 7 默认给从节点设置为只读，所以可以认为只有主节点有读写权限，其余只有读权限。如果情况不一致，就手动给每一个redis-server的配置文件都加上这一行。 language-txt1replica-read-only yes 4. 简单的controller写一个简单的controller，等会用于测试。 language-java1234567891011121314151617181920@RestControllerpublic class HelloController { @Autowired private StringRedisTemplate redisTemplate; @GetMapping(&quot;/get/{key}&quot;) public String hi(@PathVariable String key) { return redisTemplate.opsForValue().get(key); } @GetMapping(&quot;/set/{key}/{value}&quot;) public String hi(@PathVariable String key, @PathVariable String value) { redisTemplate.opsForValue().set(key, value); return &quot;success&quot;; }} 三、运行首先，因为所有redis节点都在一个docker bridge网络中，所以基于Idea编写的项目在宿主机(Windows)中运行spirngboot程序，不好去和redis集群做完整的交互。 虽然说无论是sentinel还是redis-server都暴露了端口到宿主机，我们可以通过映射的端口分别访问它们，但是我们的程序只访问sentinel，sentinel管理redis-server，sentinel会返回redis-server的ip来让我们的程序来访问redis-server，这里的ip是docker bridge网络里的ip，所以即使我们的程序拿到ip也访问不了redis-server。 这个时候就需要将我们的项目放到一个docker容器中运行，然后把这个容器放到和redis同一网络下，就像下图。 具体如何快捷让Idea结合Docker去运行SpringBoot程序，可以参考下面这篇文章。 Idea连接Docker在本地(Windows)开发SpringBoot 记得要暴露你的程序端口到宿主机，这样才方便测试。 四、测试1. 写浏览器访问localhost:8080/set/num/7799 查看SpringBoot容器日志，可以看到向主节点172.30.1.2:6379发送写请求。 language-txt123456789101101-06 07:23:59:848 DEBUG 1 --- [nio-8080-exec-6] io.lettuce.core.RedisChannelHandler : dispatching command AsyncCommand [type=SET, output=StatusOutput [output=null, error='null'], commandType=io.lettuce.core.protocol.Command]01-06 07:23:59:848 DEBUG 1 --- [nio-8080-exec-6] i.l.c.m.MasterReplicaConnectionProvider : getConnectionAsync(WRITE)01-06 07:23:59:848 DEBUG 1 --- [nio-8080-exec-6] io.lettuce.core.RedisChannelHandler : dispatching command AsyncCommand [type=SET, output=StatusOutput [output=null, error='null'], commandType=io.lettuce.core.protocol.Command]01-06 07:23:59:848 DEBUG 1 --- [nio-8080-exec-6] i.lettuce.core.protocol.DefaultEndpoint : [channel=0x9b4ebc85, /172.30.1.5:46700 -&gt; /172.30.1.2:6379, epid=0xf] write() writeAndFlush command AsyncCommand [type=SET, output=StatusOutput [output=null, error='null'], commandType=io.lettuce.core.protocol.Command]01-06 07:23:59:848 DEBUG 1 --- [nio-8080-exec-6] i.lettuce.core.protocol.DefaultEndpoint : [channel=0x9b4ebc85, /172.30.1.5:46700 -&gt; /172.30.1.2:6379, epid=0xf] write() done01-06 07:23:59:848 DEBUG 1 --- [oEventLoop-4-10] io.lettuce.core.protocol.CommandHandler : [channel=0x9b4ebc85, /172.30.1.5:46700 -&gt; /172.30.1.2:6379, epid=0xf, chid=0x16] write(ctx, AsyncCommand [type=SET, output=StatusOutput [output=null, error='null'], commandType=io.lettuce.core.protocol.Command], promise)01-06 07:23:59:849 DEBUG 1 --- [oEventLoop-4-10] io.lettuce.core.protocol.CommandEncoder : [channel=0x9b4ebc85, /172.30.1.5:46700 -&gt; /172.30.1.2:6379] writing command AsyncCommand [type=SET, output=StatusOutput [output=null, error='null'], commandType=io.lettuce.core.protocol.Command]01-06 07:23:59:851 DEBUG 1 --- [oEventLoop-4-10] io.lettuce.core.protocol.CommandHandler : [channel=0x9b4ebc85, /172.30.1.5:46700 -&gt; /172.30.1.2:6379, epid=0xf, chid=0x16] Received: 5 bytes, 1 commands in the stack01-06 07:23:59:851 DEBUG 1 --- [oEventLoop-4-10] io.lettuce.core.protocol.CommandHandler : [channel=0x9b4ebc85, /172.30.1.5:46700 -&gt; /172.30.1.2:6379, epid=0xf, chid=0x16] Stack contains: 1 commands01-06 07:23:59:851 DEBUG 1 --- [oEventLoop-4-10] i.l.core.protocol.RedisStateMachine : Decode done, empty stack: true01-06 07:23:59:852 DEBUG 1 --- [oEventLoop-4-10] io.lettuce.core.protocol.CommandHandler : [channel=0x9b4ebc85, /172.30.1.5:46700 -&gt; /172.30.1.2:6379, epid=0xf, chid=0x16] Completing command AsyncCommand [type=SET, output=StatusOutput [output=OK, error='null'], commandType=io.lettuce.core.protocol.Command] 2. 读浏览器访问localhost:8080/get/num 查看SpringBoot容器日志，会向两个从节点之一发送读请求。 language-txt123456789101101-06 07:25:45:342 DEBUG 1 --- [io-8080-exec-10] io.lettuce.core.RedisChannelHandler : dispatching command AsyncCommand [type=GET, output=ValueOutput [output=null, error='null'], commandType=io.lettuce.core.protocol.Command]01-06 07:25:45:342 DEBUG 1 --- [io-8080-exec-10] i.l.c.m.MasterReplicaConnectionProvider : getConnectionAsync(READ)01-06 07:25:45:342 DEBUG 1 --- [io-8080-exec-10] io.lettuce.core.RedisChannelHandler : dispatching command AsyncCommand [type=GET, output=ValueOutput [output=null, error='null'], commandType=io.lettuce.core.protocol.Command]01-06 07:25:45:342 DEBUG 1 --- [io-8080-exec-10] i.lettuce.core.protocol.DefaultEndpoint : [channel=0x96ae68cf, /172.30.1.5:38102 -&gt; /172.30.1.4:6379, epid=0x1c] write() writeAndFlush command AsyncCommand [type=GET, output=ValueOutput [output=null, error='null'], commandType=io.lettuce.core.protocol.Command]01-06 07:25:45:342 DEBUG 1 --- [io-8080-exec-10] i.lettuce.core.protocol.DefaultEndpoint : [channel=0x96ae68cf, /172.30.1.5:38102 -&gt; /172.30.1.4:6379, epid=0x1c] write() done01-06 07:25:45:342 DEBUG 1 --- [oEventLoop-4-11] io.lettuce.core.protocol.CommandHandler : [channel=0x96ae68cf, /172.30.1.5:38102 -&gt; /172.30.1.4:6379, epid=0x1c, chid=0x23] write(ctx, AsyncCommand [type=GET, output=ValueOutput [output=null, error='null'], commandType=io.lettuce.core.protocol.Command], promise)01-06 07:25:45:343 DEBUG 1 --- [oEventLoop-4-11] io.lettuce.core.protocol.CommandEncoder : [channel=0x96ae68cf, /172.30.1.5:38102 -&gt; /172.30.1.4:6379] writing command AsyncCommand [type=GET, output=ValueOutput [output=null, error='null'], commandType=io.lettuce.core.protocol.Command]01-06 07:25:45:346 DEBUG 1 --- [oEventLoop-4-11] io.lettuce.core.protocol.CommandHandler : [channel=0x96ae68cf, /172.30.1.5:38102 -&gt; /172.30.1.4:6379, epid=0x1c, chid=0x23] Received: 10 bytes, 1 commands in the stack01-06 07:25:45:346 DEBUG 1 --- [oEventLoop-4-11] io.lettuce.core.protocol.CommandHandler : [channel=0x96ae68cf, /172.30.1.5:38102 -&gt; /172.30.1.4:6379, epid=0x1c, chid=0x23] Stack contains: 1 commands01-06 07:25:45:346 DEBUG 1 --- [oEventLoop-4-11] i.l.core.protocol.RedisStateMachine : Decode done, empty stack: true01-06 07:25:45:346 DEBUG 1 --- [oEventLoop-4-11] io.lettuce.core.protocol.CommandHandler : [channel=0x96ae68cf, /172.30.1.5:38102 -&gt; /172.30.1.4:6379, epid=0x1c, chid=0x23] Completing command AsyncCommand [type=GET, output=ValueOutput [output=[B@7427ef47, error='null'], commandType=io.lettuce.core.protocol.Command] 3. 额外测试以及还有一些额外的测试，可以自行去尝试，检验，这里列举一些，但具体不再赘述。 关闭两个从节点容器，等待sentinel完成维护和通知后，测试读数据和写数据会请求谁？ 再次开启两个从节点，等待sentinel完成操作后，再关闭主节点，等待sentinel完成操作后，测试读数据和写数据会请求谁？ 再次开启主节点，等待sentinel完成操作后，测试读数据和写数据会请求谁？","link":"/Hexo/2024/01/06/2024-H1/2024-01-06-15-31-49/"},{"title":"Docker-Compose部署Redis(v7.2)分片集群(含主从)","text":"环境 docker desktop for windows 4.23.0 redis 7.2 目标 搭建如下图分片+主从集群。 一、前提准备1. 文件夹结构因为Redis 7.2 docker镜像里面没有配置文件，所以需要去redis官网下载一个复制里面的redis.conf博主这里用的是7.2.3版本的redis.conf，这个文件就在解压后第一层文件夹里。 然后构建如下文件夹结构。 language-txt123456789101112131415161718192021sharding/├── docker-compose.yaml├── master1│ └── conf│ └── redis.conf├── master2│ └── conf│ └── redis.conf├── master3│ └── conf│ └── redis.conf├── replica1│ └── conf│ └── redis.conf├── replica2│ └── conf│ └── redis.conf└── replica3 └── conf └── redis.conf 二、配置文件1. redis.conf对每个redis.conf都做以下修改。分片集群的redis主从的redis.conf目前都是一样的。 language-bash12345678910111213141516171819port 6379# 开启集群功能cluster-enabled yes# 集群的配置文件名称，不需要我们创建，由redis自己维护cluster-config-file /data/nodes.conf# 节点心跳失败的超时时间cluster-node-timeout 5000# 持久化文件存放目录dir /data# 绑定地址bind 0.0.0.0# 让redis后台运行daemonize no# 保护模式protected-mode no# 数据库数量databases 1# 日志logfile /data/run.log 2. docker-compose文件language-yaml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384version: '3.8'networks: redis-sharding: driver: bridge ipam: driver: default config: - subnet: 172.30.2.0/24services: master1: container_name: master1 image: redis:7.2 volumes: - ./master1/conf:/usr/local/etc/redis ports: - &quot;7001:6379&quot; command: [&quot;redis-server&quot;, &quot;/usr/local/etc/redis/redis.conf&quot;] networks: redis-sharding: ipv4_address: 172.30.2.11 master2: container_name: master2 image: redis:7.2 volumes: - ./master2/conf:/usr/local/etc/redis ports: - &quot;7002:6379&quot; command: [ &quot;redis-server&quot;, &quot;/usr/local/etc/redis/redis.conf&quot; ] networks: redis-sharding: ipv4_address: 172.30.2.12 master3: container_name: master3 image: redis:7.2 volumes: - ./master3/conf:/usr/local/etc/redis ports: - &quot;7003:6379&quot; command: [ &quot;redis-server&quot;, &quot;/usr/local/etc/redis/redis.conf&quot; ] networks: redis-sharding: ipv4_address: 172.30.2.13 replica1: container_name: replica1 image: redis:7.2 volumes: - ./replica1/conf:/usr/local/etc/redis ports: - &quot;8001:6379&quot; command: [ &quot;redis-server&quot;, &quot;/usr/local/etc/redis/redis.conf&quot; ] networks: redis-sharding: ipv4_address: 172.30.2.21 replica2: container_name: replica2 image: redis:7.2 volumes: - ./replica2/conf:/usr/local/etc/redis ports: - &quot;8002:6379&quot; command: [ &quot;redis-server&quot;, &quot;/usr/local/etc/redis/redis.conf&quot; ] networks: redis-sharding: ipv4_address: 172.30.2.22 replica3: container_name: replica3 image: redis:7.2 volumes: - ./replica3/conf:/usr/local/etc/redis ports: - &quot;8003:6379&quot; command: [ &quot;redis-server&quot;, &quot;/usr/local/etc/redis/redis.conf&quot; ] networks: redis-sharding: ipv4_address: 172.30.2.23 需要注意以下几点 这里自定义了bridge子网并限定了范围，如果该范围已经被使用，请更换。 这里没有对data进行-v挂载，如果要挂载，请注意宿主机对应文件夹权限问题。 随后运行 language-bash1docker-compose -p redis-sharding up -d 三、构建集群接下来所有命令都在master1容器的命令行执行 1. 自动分配主从关系这个命令会创建了一个集群，包括三个主节点和三个从节点，每个主节点分配一个从节点作为副本，前3个ip为主节点，后3个为从节点，主节点的从节点随机分配。 language-bash1redis-cli --cluster create 172.30.2.11:6379 172.30.2.12:6379 172.30.2.13:6379 172.30.2.21:6379 172.30.2.22:6379 172.30.2.23:6379 --cluster-replicas 1 如果希望手动指定主从关系，看下面，否则你可以跳过这一章节了。 2.1 构建3 master集群language-bash1redis-cli --cluster create 172.30.2.11:6379 172.30.2.12:6379 172.30.2.13:6379 --cluster-replicas 0 2.2 手动配置从节点查看3个主节点的ID language-bash1redis-cli -h 172.30.2.11 -p 6379 cluster nodes 下面3个命令会将3个从节点加入集群中，其中172.30.2.11可以是三个主节点的任意一个。 language-bash123redis-cli -h 172.30.2.21 -p 6379 cluster meet 172.30.2.11 6379redis-cli -h 172.30.2.22 -p 6379 cluster meet 172.30.2.11 6379redis-cli -h 172.30.2.23 -p 6379 cluster meet 172.30.2.11 6379 然后为每个从节点指定主节点。 language-bash123redis-cli -h 172.30.2.21 -p 6379 cluster replicate &lt;master-ID&gt;redis-cli -h 172.30.2.22 -p 6379 cluster replicate &lt;master-ID&gt;redis-cli -h 172.30.2.23 -p 6379 cluster replicate &lt;master-ID&gt; 四、测试1. 集群结构可以通过以下命令查看集群中每个节点的id、角色、ip、port、插槽范围等信息 language-bash1redis-cli -h 172.30.2.11 -p 6379 cluster nodes 2. 分片测试往集群存入4个键值 language-bash1234redis-cli -c -h 172.30.2.11 -p 6379 set key1 value1redis-cli -c -h 172.30.2.11 -p 6379 set key2 value2redis-cli -c -h 172.30.2.11 -p 6379 set key3 value3redis-cli -c -h 172.30.2.11 -p 6379 set key4 value4 查看每个主节点现有的键值，会发现每个节点只有一部分键值。 language-bash123redis-cli -h 172.30.2.11 -p 6379 --scanredis-cli -h 172.30.2.12 -p 6379 --scanredis-cli -h 172.30.2.13 -p 6379 --scan","link":"/Hexo/2024/01/06/2024-H1/2024-01-06-17-47-08/"},{"title":"SpringBoot基于Redis(7.2)分片集群实现读写分离","text":"一、前置提要SpringBoot访问Redis分片集群和Redis哨兵模式，使用上没有什么区别。唯一的区别在于application.yml配置上不一样。 二、集群搭建首先，无论如何，得先有一个Redis分片集群，具体可以参考下面这篇文章 Docker-Compose部署Redis(v7.2)分片集群(含主从) 搭建完成后大致得到如下图描述的一个集群。 三、SpringBoot访问分片集群其次，具体如何结合Idea和Docker让本地开发的SpringBoot项目访问Redis分片集群，可以参考下面这篇文章 SpringBoot基于哨兵模式的Redis(7.2)集群实现读写分离 要注意的是，yaml文件要从 language-yaml12345678910spring: redis: sentinel: master: mymaster nodes: - 172.30.1.11:26379 - 172.30.1.12:26379 - 172.30.1.13:26379 password: 1009 password: 1009 变成 language-yaml12345678910spring: redis: cluster: nodes: - 172.30.2.11:6379 - 172.30.2.12:6379 - 172.30.2.13:6379 - 172.30.2.21:6379 - 172.30.2.22:6379 - 172.30.2.23:6379 其余基本一致。","link":"/Hexo/2024/01/06/2024-H1/2024-01-06-20-13-15/"},{"title":"云服务器Docker部署SpringBoot+Vue前后端(Ubuntu)","text":"本文创作环境华为云Ubuntu22.04需要对以下知识具备一定了解和经验 Linux和Docker使用基础 Vue基本使用 SpringBoot基本使用 一、起手式-环境配置1.远程服务器免密在远程服务器执行ssh-keygen -t rsa,得到如下三个文件 language-bash12345root@hecs-295176:~# ls -lh .ssh/total 12K-rw------- 1 root root 570 Oct 21 15:14 authorized_keys-rw------- 1 root root 2.6K Oct 21 15:09 id_rsa-rw-r--r-- 1 root root 570 Oct 21 15:09 id_rsa.pub 将id_rsa.pub内容复制到authorized_keys，然后将id_rsa下载到本地。在VsCode使用Remote-SSH配置远程免密登录，例如 language-bash12345Host huaweiYun HostName xxx.xxx.xxx.xxx User root Port 22 IdentityFile &quot;C:\\Users\\mumu\\.ssh\\id_rsa&quot; 2.安装Docker执行以下命令安装Docker并检查docker命令是否可以使用 language-bash12345apt updateapt upgradeapt install docker.iodocker ps -adocker images -a 二、Vue前端部署1.参考文件夹结构文件先不用创建，按照下面结构先把文件夹创建出来然后将你的Vue打包后的dist文件夹替换下面的dist文件夹（如果没有Vue的打包文件夹本人建议先在index.html随便写点东西等会看能不能访问） language-html12345678910111213/root├── conf│ └── nginx│ ├── default.conf│ └── nginx.conf└── Vue ├── MyTest01 │ ├── dist │ │ └── index.html │ └── logs │ ├── access.log │ └── error.log └── nginxDocker.sh 2.nginx拉取nginx镜像并创建nginx容器 language-bash12docker pull nginxdocker run -itd nginx 把里面的两个配置文件复制到主机 language-bash12docker cp containerName:/etc/nginx/nginx.conf ~/conf/nginx/nginx.confdocker cp containerName:/etc/nginx/conf.d/default.conf ~/conf/nginx/default.conf 编辑default.conf 文件，修改以下内容： 将 listen 80; 改为 listen 8080;，表示 nginx 容器监听 8080 端口。 将 root /usr/share/nginx/html; 改为 root /usr/share/nginx/dist;，表示 nginx容器的根目录为 /usr/share/nginx/dist。 将 index index.html index.htm; 改为 index index.html;，表示 nginx 容器的默认首页为 index.html。 参考第一小步文件夹结构，把以下内容写入nginxDocker.sh language-bash123456789101112131415#!/bin/bashcontainerName=&quot;Test01&quot;nginxConf=&quot;/root/conf/nginx/nginx.conf&quot;defaultConf=&quot;/root/conf/nginx/default.conf&quot;logsPath=&quot;/root/Vue/MyTest01/logs&quot;vuePath=&quot;/root/Vue/MyTest01/dist&quot;docker run -d --name &quot;$containerName&quot; \\ -v &quot;$nginxConf&quot;:/etc/nginx/nginx.conf \\ -v &quot;$defaultConf&quot;:/etc/nginx/conf.d/default.conf \\ -v &quot;$logsPath&quot;:/var/log/nginx \\ -v &quot;$vuePath&quot;:/usr/share/nginx/dist \\ -p 8080:8080 \\ nginx 命令行运行这个sh脚本并查看当前容器列表确认容器已经在运行中 language-bash12bash Vue/nginxDocker.shdocker ps -a 3.开放8080端口如果你使用的VsCode远程连接的服务器，那么可以先通过端口转发，在本地访问前端服务。如果想要别人通过公网访问，需要去购买云服务器的平台，修改服务器的安全组配置，添加入站规则，开放8080端口。之后使用IP+8080即可访问这个docker容器里的前端服务。 4.复盘首先是更新便捷性，使用-v挂载文件到容器，我们可以直接修改主机的dist文件夹内容而不必对容器做任何操作，前端服务就可以自动update，其它-v挂载的文件都可以在主机直接修改而不必连入容器中修改，同时重启容器即可一定保证所有服务重启。其次是多开便捷性，以上流程就是一个包裹了前端服务的docker占一个端口，如果有多个Vue前端，使用不同端口即可。总而言之，都是选择Docker容器化的优势所在。 三、SpringBoot后端部署1.参考文件夹结构将maven打包好的jar包如下图放入对应位置 language-bash1234SpringBoot ├── javaDocker.sh └── MyTest01 └── demo-0.0.1-SNAPSHOT.jar 2.openjdk17以java17举例，拉取对应docker镜像（java8对应的镜像是java:8 ） language-bash1docker pull openjdk:17 如下编写javaDocker.sh脚本 language-bash123456789#!/bin/bashcontainerName=&quot;JavaTest01&quot;SpringBootPath=&quot;/root/SpringBoot/MyTest01/demo-0.0.1-SNAPSHOT.jar&quot;docker run -d --name &quot;$containerName&quot; \\ -p 8081:8081 \\ -v &quot;$SpringBootPath&quot;:/app/your-app.jar \\ openjdk:17 java -jar /app/your-app.jar 命令行运行这个sh脚本并查看当前容器列表确认容器已经在运行中 language-bash12bash SpringBoot/javaDocker.shdocker ps -a 3.开放8081端口需要去购买云服务器的平台，修改服务器的安全组配置，添加入站规则，开放8081端口。打开浏览器，输入IP:8081然后跟上一些你在程序中写的api路径，验证是否有返回。 四、Vue-&gt;Axios-&gt;SpringBoot前后端通信简单实现vue这里使用ts + setup +组合式 语法举例，前端代码如下意思是向IP为xxx.xxx.xxx.xxx的云服务器的8081端口服务发送路径为/Home/Kmo的请求 language-html12345678910111213141516171819202122&lt;template&gt; &lt;div&gt; Your Remote JavaDocker State : { { line }} &lt;/div&gt;&lt;/template&gt;&lt;script setup lang=&quot;ts&quot;&gt;import { ref } from &quot;vue&quot;;import axios from &quot;axios&quot;;const line = ref(&quot;fail&quot;);axios.get(&quot;http://xxx.xxx.xxx.xxx:8081/Home/Kmo&quot;).then(rp=&gt;{ line.value = rp.data})&lt;/script&gt;&lt;style scoped&gt;&lt;/style&gt; SpringBoot后端写一个简单Controller类，代码如下 language-java123456789101112131415161718192021package com.kmo.demo.controller;import org.springframework.web.bind.annotation.CrossOrigin;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;@CrossOrigin(originPatterns = &quot;*&quot;, allowCredentials = &quot;true&quot;)@RestController@RequestMapping(&quot;Home&quot;)public class TestController { @GetMapping(&quot;/Kmo&quot;) public String test(){ return &quot;Success!&quot;; }} 分别打包放到云服务指定文件夹，然后restart重启两个docker容器即可，在本地浏览器访问IP:8080看看效果吧。 (完)","link":"/Hexo/2024/01/06/2024-H1/2024-01-06-20-49-56/"},{"title":"多级缓存架构(一)项目初始化","text":"一、项目克隆克隆此项目到本地https://github.com/Xiamu-ssr/MultiCache来到start目录下，分别有以下文件夹 docker：docker相关文件 item-service：springboot项目 二、数据库准备在docker/docker-compose.yml中已经定义好如下mysql块 language-yaml1234567891011121314mysql: container_name: mysql image: mysql:8 volumes: - ./mysql/conf/my.cnf:/etc/mysql/conf.d/my.cnf - ./mysql/data:/var/lib/mysql - ./mysql/logs:/logs ports: - &quot;3306:3306&quot; environment: - MYSQL_ROOT_PASSWORD=1009 networks: multi-cache: ipv4_address: 172.30.3.2 my.cnf如下 language-bash12345[mysqld]bind-address=0.0.0.0skip-name-resolvecharacter_set_server=utf8datadir=/var/lib/mysql 运行以下命令启动docker-compose language-bash1docker-compose -p multi-cache up -d 之后使用数据库连接工具连接mysql容器，创建heima数据库，并对其执行docker/mysql/item.sql脚本。 三、项目工程准备用idea打开item-service文件夹，等待idea加载本springboot项目。 如果在docker-compose中服务ip改动，请注意一些可能关联的地方也需要做同样改动，比如item-service的application.yml language-yaml12345678spring: application: name: itemservice datasource: url: jdbc:mysql://172.30.3.2:3306/heima?useSSL=false&amp;allowPublicKeyRetrieval=true username: root password: 1009 driver-class-name: com.mysql.cj.jdbc.Driver 观察controller language-java12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879808182838485package com.heima.item.web;import com.baomidou.mybatisplus.extension.plugins.pagination.Page;import com.heima.item.pojo.Item;import com.heima.item.pojo.ItemStock;import com.heima.item.pojo.PageDTO;import com.heima.item.service.IItemService;import com.heima.item.service.IItemStockService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.*;import java.util.List;import java.util.stream.Collectors;@RestController@RequestMapping(&quot;item&quot;)public class ItemController { @Autowired private IItemService itemService; @Autowired private IItemStockService stockService; @GetMapping(&quot;list&quot;) public PageDTO queryItemPage( @RequestParam(value = &quot;page&quot;, defaultValue = &quot;1&quot;) Integer page, @RequestParam(value = &quot;size&quot;, defaultValue = &quot;5&quot;) Integer size){ // 分页查询商品 Page&lt;Item&gt; result = itemService.query() .ne(&quot;status&quot;, 3) .page(new Page&lt;&gt;(page, size)); // 查询库存 List&lt;Item&gt; list = result.getRecords().stream().peek(item -&gt; { ItemStock stock = stockService.getById(item.getId()); item.setStock(stock.getStock()); item.setSold(stock.getSold()); }).collect(Collectors.toList()); // 封装返回 return new PageDTO(result.getTotal(), list); } @PostMapping public void saveItem(@RequestBody Item item){ itemService.saveItem(item); } @PutMapping public void updateItem(@RequestBody Item item) { itemService.updateById(item); } @PutMapping(&quot;stock&quot;) public void updateStock(@RequestBody ItemStock itemStock){ stockService.updateById(itemStock); } @DeleteMapping(&quot;/{id}&quot;) public void deleteById(@PathVariable(&quot;id&quot;) Long id){ itemService.update().set(&quot;status&quot;, 3).eq(&quot;id&quot;, id).update(); } @GetMapping(&quot;/{id}&quot;) public Item findById(@PathVariable(&quot;id&quot;) Long id){ return itemService.query() .ne(&quot;status&quot;, 3).eq(&quot;id&quot;, id) .one(); } @GetMapping(&quot;/stock/{id}&quot;) public ItemStock findStockById(@PathVariable(&quot;id&quot;) Long id){ return stockService.getById(id); }}","link":"/Hexo/2024/01/12/2024-H1/2024-01-12-17-40-42/"},{"title":"多级缓存架构(四)Redis缓存","text":"通过本文章，可以完成多级缓存架构中的Redis缓存。 一、Redis服务在docker/docker-compose.yml中，添加redis服务块 language-yml1234567891011redis: container_name: redis image: redis:7.2 volumes: - ./redis/redis.conf:/usr/local/etc/redis/redis.conf ports: - &quot;6379:6379&quot; command: [&quot;redis-server&quot;, &quot;/usr/local/etc/redis/redis.conf&quot;] networks: multi-cache: ipv4_address: 172.30.3.21 二、Redis缓存预热在spirngboot项目启动时，将固定的热点数据提前加载到redis中。 1. 引入依赖pom.xml添加如下依赖 language-xml123456789101112131415&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;io.lettuce&lt;/groupId&gt; &lt;artifactId&gt;lettuce-core&lt;/artifactId&gt; &lt;version&gt;6.1.4.RELEASE&lt;/version&gt; &lt;!-- 或更高版本 --&gt; &lt;/dependency&gt; &lt;!-- https://mvnrepository.com/artifact/com.alibaba.fastjson2/fastjson2 --&gt; &lt;dependency&gt; &lt;groupId&gt;com.alibaba.fastjson2&lt;/groupId&gt; &lt;artifactId&gt;fastjson2&lt;/artifactId&gt; &lt;version&gt;2.0.41&lt;/version&gt; &lt;/dependency&gt; application.yml添加如下配置 language-yml123spring: redis: host: 172.30.3.21 2. handler类实现新建config.RedisHandler类，内容如下，主要是重写afterPropertiesSet，完成缓存预热逻辑，saveItem和deleteItemById函数给之后的章节使用。 language-java12345678910111213141516171819202122232425262728293031323334353637@Componentpublic class RedisHandler implements InitializingBean { @Autowired private StringRedisTemplate redisTemplate; @Autowired private IItemService itemService; @Autowired private IItemStockService stockService; @Override public void afterPropertiesSet() throws Exception { List&lt;Item&gt; itemList = itemService.list(); for (Item item : itemList) { String json = JSON.toJSONString(item); redisTemplate.opsForValue().set(&quot;item:id:&quot;+item.getId(), json); } List&lt;ItemStock&gt; stockList = stockService.list(); for (ItemStock stock : stockList) { String json = JSON.toJSONString(stock); redisTemplate.opsForValue().set(&quot;item:stock:id:&quot;+stock.getId(), json); } } public void saveItem(Item item){ String json = JSON.toJSONString(item); redisTemplate.opsForValue().set(&quot;item:id:&quot;+item.getId(), json); } public void deleteItemById(Long id){ redisTemplate.delete(&quot;item:id:&quot;+id); }} 三、整合Redis缓存 改进openresty的docker/openresty1/lualib/common.lua，如下 language-lua12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576777879local redis = require('resty.redis')local red = redis:new()red:set_timeouts(1000, 1000, 1000)-- 创建一个本地缓存对象item_cachelocal item_cache = ngx.shared.item_cache;-- 关闭redis连接的工具方法，其实是放入连接池local function close_redis(red) local pool_max_idle_time = 10000 -- 连接的空闲时间，单位是毫秒 local pool_size = 100 --连接池大小 local ok, err = red:set_keepalive(pool_max_idle_time, pool_size) if not ok then ngx.log(ngx.ERR, &quot;放入redis连接池失败: &quot;, err) endend-- 查询redis的方法 ip和port是redis地址，key是查询的keylocal function read_redis(ip, port, key) -- 获取一个连接 local ok, err = red:connect(ip, port) if not ok then ngx.log(ngx.ERR, &quot;连接redis失败 : &quot;, err) return nil end -- 查询redis local resp, err = red:get(key) -- 查询失败处理 if not resp then ngx.log(ngx.ERR, &quot;查询Redis失败: &quot;, err, &quot;, key = &quot; , key) end --得到的数据为空处理 if resp == ngx.null then resp = nil ngx.log(ngx.ERR, &quot;查询Redis数据为空, key = &quot;, key) end close_redis(red) return respend-- 函数，向openresty本身发送类似/path/item/10001请求，根据conf配置，将被删除/path前缀并代理至tomcat程序local function read_get(path, params) local rsp = ngx.location.capture('/path'..path,{ method = ngx.HTTP_GET, args = params, }) if not rsp then ngx.log(ngx.ERR, &quot;http not found, path: &quot;, path, &quot;, args: &quot;, params); ngx.exit(404) end return rsp.bodyend-- 函数，如果本地有缓存，使用缓存，如果没有代理到tomcat然后将数据存入缓存local function read_data(key, expire, path, params) -- query local cache local rsp = item_cache:get(key) -- query redis if not rsp then ngx.log(ngx.ERR, &quot;local cache miss, try redis, key: &quot;, key) rsp = read_redis(&quot;172.30.3.21&quot;, 6379, key) if not rsp then ngx.log(ngx.ERR, &quot;redis cache miss, try tomcat, key: &quot;, key) rsp = read_get(path, params) end end -- write into local cache item_cache:set(key, rsp, expire) return rspendlocal _M = { read_get = read_get, read_redis = read_redis, read_data = read_data}return _M item.lua不需要用改动。 四、运行到此为止，docker-compose.yml内容应该如下 language-yml1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162version: '3.8'networks: multi-cache: driver: bridge ipam: driver: default config: - subnet: 172.30.3.0/24services: mysql: container_name: mysql image: mysql:8 volumes: - ./mysql/conf/my.cnf:/etc/mysql/conf.d/my.cnf - ./mysql/data:/var/lib/mysql - ./mysql/logs:/logs ports: - &quot;3306:3306&quot; environment: - MYSQL_ROOT_PASSWORD=1009 networks: multi-cache: ipv4_address: 172.30.3.2 nginx: container_name: nginx image: nginx:stable volumes: - ./nginx/conf/nginx.conf:/etc/nginx/nginx.conf - ./nginx/conf/conf.d/default.conf:/etc/nginx/conf.d/default.conf - ./nginx/dist:/usr/share/nginx/dist ports: - &quot;8080:8080&quot; networks: multi-cache: ipv4_address: 172.30.3.3 openresty1: container_name: openresty1 image: openresty/openresty:1.21.4.3-3-jammy-amd64 volumes: - ./openresty1/conf/nginx.conf:/usr/local/openresty/nginx/conf/nginx.conf - ./openresty1/conf/conf.d/default.conf:/etc/nginx/conf.d/default.conf - ./openresty1/lua:/usr/local/openresty/nginx/lua - ./openresty1/lualib/common.lua:/usr/local/openresty/lualib/common.lua networks: multi-cache: ipv4_address: 172.30.3.11 redis: container_name: redis image: redis:7.2 volumes: - ./redis/redis.conf:/usr/local/etc/redis/redis.conf ports: - &quot;6379:6379&quot; command: [ &quot;redis-server&quot;, &quot;/usr/local/etc/redis/redis.conf&quot; ] networks: multi-cache: ipv4_address: 172.30.3.21 删除原来的multiCache，重新启动各项服务。 language-bash1docker-compose -p multi-cache up -d 启动springboot程序。 五、测试1. redis缓存预热springboot程序启动后，出现查询日志，查看redis数据库发现自动存入了数据。 2. redis缓存命中清空openresty容器日志，访问http://localhost:8080/item.html?id=10001，查看日志，发现两次commonUtils.read_data都只触发到查询redis，没到查询tomcat。 language-txt1232024-01-12 16:06:18 2024/01/12 08:06:18 [error] 7#7: *1 [lua] common.lua:59: read_data(): local cache miss, try redis, key: item:id:10001, client: 172.30.3.3, server: localhost, request: &quot;GET /api/item/10001 HTTP/1.0&quot;, host: &quot;nginx-cluster&quot;, referrer: &quot;http://localhost:8080/item.html?id=10001&quot;2024-01-12 16:06:18 2024/01/12 08:06:18 [error] 7#7: *1 [lua] common.lua:59: read_data(): local cache miss, try redis, key: item:stock:id:10001, client: 172.30.3.3, server: localhost, request: &quot;GET /api/item/10001 HTTP/1.0&quot;, host: &quot;nginx-cluster&quot;, referrer: &quot;http://localhost:8080/item.html?id=10001&quot;2024-01-12 16:06:18 172.30.3.3 - - [12/Jan/2024:08:06:18 +0000] &quot;GET /api/item/10001 HTTP/1.0&quot; 200 466 &quot;http://localhost:8080/item.html?id=10001&quot; &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0&quot; 查看springboot程序日志，也没有查询记录，说明redis缓存命中成功。 六、高可用集群 对于redis高可用集群，可以参考以下专栏文章。https://blog.csdn.net/m0_51390969/category_12546314.html?spm=1001.2014.3001.5482","link":"/Hexo/2024/01/12/2024-H1/2024-01-12-17-43-18/"},{"title":"基于Docker Compose单机实现多级缓存架构2024","text":"一、环境参考 Name Version Docker Desktop for Windows 4.23.0 Openjdk 8 MySQL 8.2.0 Redis 7.2 Canal 1.1.7 OpenResty 1.21.4.3-3-jammy-amd64 Lua - Caffeine - 二、专栏简介多级缓存实现过程比较长，将拆分为多个文章分步讲述。如果一切顺利，大致会得到如下一个多级缓存架构： 本专栏主要对Lua缓存、Redis缓存、Caffeine缓存进行实践，以及缓存同步实践。依次为以下几篇： 多级缓存架构(一)项目初始化 多级缓存架构(二)Caffeine进程缓存 多级缓存架构(三)OpenResty Lua缓存 多级缓存架构(四)Redis缓存 多级缓存架构(五)缓存同步 三、扩展对于高可用，集群等扩展，例如下图的构造，本专栏只包含部分展开但并不提供实践指导。","link":"/Hexo/2024/01/12/2024-H1/2024-01-12-18-03-24/"},{"title":"多级缓存架构(二)Caffeine进程缓存","text":"通过本文章，可以完成多级缓存架构中的进程缓存。 一、引入依赖在item-service中引入caffeine依赖 language-xml1234&lt;dependency&gt; &lt;groupId&gt;com.github.ben-manes.caffeine&lt;/groupId&gt; &lt;artifactId&gt;caffeine&lt;/artifactId&gt; &lt;/dependency&gt; 二、实现进程缓存这是Caffeine官方文档地址 1. 配置Config类创建config.CaffeineConfig类 language-java123456789101112131415161718192021@Configurationpublic class CaffeineConfig { @Bean public Cache&lt;Long, Item&gt; itemCache(){ return Caffeine.newBuilder() .initialCapacity(100) .maximumSize(10_000) .build(); } @Bean public Cache&lt;Long, ItemStock&gt; stockCache(){ return Caffeine.newBuilder() .initialCapacity(100) .maximumSize(10_000) .build(); }} 2. 修改controller在ItemController中注入两个Cache对象，并修改业务逻辑 language-java12345678910111213141516171819202122232425262728293031323334353637@RestController@RequestMapping(&quot;item&quot;)public class ItemController { @Autowired private IItemService itemService; @Autowired private IItemStockService stockService; @Autowired private Cache&lt;Long, Item&gt; itemCache; @Autowired private Cache&lt;Long, ItemStock&gt; stockCache; @GetMapping(&quot;/{id}&quot;) public Item findById(@PathVariable(&quot;id&quot;) Long id){ return itemCache.get(id, key-&gt; itemService.query() .ne(&quot;status&quot;, 3).eq(&quot;id&quot;, id) .one() );// return itemService.query()// .ne(&quot;status&quot;, 3).eq(&quot;id&quot;, id)// .one(); } @GetMapping(&quot;/stock/{id}&quot;) public ItemStock findStockById(@PathVariable(&quot;id&quot;) Long id){ return stockCache.get(id, key-&gt; stockService.getById(id) );// return stockService.getById(id); }} 三、运行Idea结合Docker将springboot放入docker容器中运行，并指定使用multi-cache_multi-cache网络，以及固定172.30.3.4地址。详细参考如下文章 Idea连接Docker在本地(Windows)开发SpringBoot 启动好后，可以看到springboot容器和mysql容器处于同一网络下。（Docker Desktop for Windows插件PortNavigator） 四、测试访问http://localhost:8081/item/10001可以看到springboot日志输出如下 language-txt12302:45:58:841 DEBUG 1 --- [nio-8081-exec-1] c.h.item.mapper.ItemMapper.selectOne : ==&gt; Preparing: SELECT id,name,title,price,image,category,brand,spec,status,create_time,update_time FROM tb_item WHERE (status &lt;&gt; ? AND id = ?)02:45:58:889 DEBUG 1 --- [nio-8081-exec-1] c.h.item.mapper.ItemMapper.selectOne : ==&gt; Parameters: 3(Integer), 10001(Long)02:45:58:951 DEBUG 1 --- [nio-8081-exec-1] c.h.item.mapper.ItemMapper.selectOne : &lt;== Total: 1 当我们二次访问此网址，强制刷新+禁用浏览器缓存+更换浏览器，springboot日志都没有新的查询记录，说明使用了Caffeine缓存。","link":"/Hexo/2024/01/12/2024-H1/2024-01-12-19-51-35/"},{"title":"多级缓存架构(三)OpenResty Lua缓存","text":"通过本文章，可以完成多级缓存架构中的Lua缓存。 一、nginx服务在docker/docker-compose.yml中添加nginx服务块。 language-yaml123456789101112nginx: container_name: nginx image: nginx:stable volumes: - ./nginx/conf/nginx.conf:/etc/nginx/nginx.conf - ./nginx/conf/conf.d/default.conf:/etc/nginx/conf.d/default.conf - ./nginx/dist:/usr/share/nginx/dist ports: - &quot;8080:8080&quot; networks: multi-cache: ipv4_address: 172.30.3.3 删除原来docker里的multiCache项目并停止springboot应用。 nginx部分配置如下，监听端口为8080，并且将请求反向代理至172.30.3.11，下一小节，将openresty固定在172.30.3.11。 language-txt12345678910111213upstream nginx-cluster { server 172.30.3.11;}server { listen 8080; listen [::]:8080; server_name localhost; location /api { proxy_pass http://nginx-cluster; }} 重新启动multiCache看看nginx前端网页效果。 language-css1docker-compose -p multi-cache up -d 访问http://localhost:8080/item.html?id=10001查询id=10001商品页 这里是假数据，前端页面会向/api/item/10001发送数据请求。 二、OpenResty服务1. 服务块定义在docker/docker-compose.yml中添加openresty1服务块。 language-yaml1234567891011openresty1: container_name: openresty1 image: openresty/openresty:1.21.4.3-3-jammy-amd64 volumes: - ./openresty1/conf/nginx.conf:/usr/local/openresty/nginx/conf/nginx.conf - ./openresty1/conf/conf.d/default.conf:/etc/nginx/conf.d/default.conf - ./openresty1/lua:/usr/local/openresty/nginx/lua - ./openresty1/lualib/common.lua:/usr/local/openresty/lualib/common.lua networks: multi-cache: ipv4_address: 172.30.3.11 2. 配置修改前端向后端发送/api/item/10001请求关于id=10001商品信息。 根据nginx的配置内容，这个请求首先被nginx拦截，反向代理到172.30.3.11 （即openresty1）。 language-txt123456789upstream nginx-cluster { server 172.30.3.11;}server { location /api { proxy_pass http://nginx-cluster; }} openresty1收到的也是/api/item/10001，同时，openresty将/api/item/(\\d+)请求代理到指定lua程序，在lua程序中完成数据缓存。 因此，openresty的conf/conf.d/default.conf如下 language-txt12345678910111213141516171819202122232425262728upstream tomcat-cluster { hash $request_uri; server 172.30.3.4:8081;# server 172.30.3.5:8081;}server { listen 80; listen [::]:80; server_name localhost; # intercept /item and join lua location ~ /api/item/(\\d+) { default_type application/json; content_by_lua_file lua/item.lua; } # intercept lua and redirect to back-end location /path/ { rewrite ^/path/(.*)$ /$1 break; proxy_pass http://tomcat-cluster; } error_page 500 502 503 504 /50x.html; location = /50x.html { root /usr/share/nginx/dist; }} conf/nginx.conf在http块最后添加3行，引入依赖。 language-txt123456#lua 模块lua_package_path &quot;/usr/local/openresty/lualib/?.lua;;&quot;;#c模块lua_package_cpath &quot;/usr/local/openresty/lualib/?.so;;&quot;;#本地缓存lua_shared_dict item_cache 150m; 3. Lua程序编写common.lua被挂载到lualib，表示可以被其他lua当做库使用，内容如下 language-lua12345678910111213141516171819202122232425262728293031323334353637-- 创建一个本地缓存对象item_cachelocal item_cache = ngx.shared.item_cache;-- 函数，向openresty本身发送类似/path/item/10001请求，根据conf配置，将被删除/path前缀并代理至tomcat程序local function read_get(path, params) local rsp = ngx.location.capture('/path'..path,{ method = ngx.HTTP_GET, args = params, }) if not rsp then ngx.log(ngx.ERR, &quot;http not found, path: &quot;, path, &quot;, args: &quot;, params); ngx.exit(404) end return rsp.bodyend-- 函数，如果本地有缓存，使用缓存，如果没有代理到tomcat然后将数据存入缓存local function read_data(key, expire, path, params) -- query local cache local rsp = item_cache:get(key) -- query tomcat if not rsp then ngx.log(ngx.ERR, &quot;redis cache miss, try tomcat, key: &quot;, key) rsp = read_get(path, params) end -- write into local cache item_cache:set(key, rsp, expire) return rspendlocal _M = { read_data = read_data}return _M item.lua是处理来自形如/api/item/10001请求的程序，内容如下 language-lua123456789101112131415161718-- includelocal commonUtils = require('common')local cjson = require(&quot;cjson&quot;)-- get url params 10001local id = ngx.var[1]-- redirect item, 缓存过期时间1800s, 适合长时间不改变的数据local itemJson = commonUtils.read_data(&quot;item:id:&quot;..id, 1800,&quot;/item/&quot;..id,nil)-- redirect item/stock, 缓存过期时间4s, 适合经常改变的数据local stockJson = commonUtils.read_data(&quot;item:stock:id:&quot;..id, 4 ,&quot;/item/stock/&quot;..id, nil)-- json2tablelocal item = cjson.decode(itemJson)local stock = cjson.decode(stockJson)-- combine item and stockitem.stock = stock.stockitem.sold = stock.sold-- return resultngx.say(cjson.encode(item)) 4. 总结 这里lua对item(tb_item表)和stock(tb_stock表)两个信息都有缓存，并使用cjson库将两者合并后返回到前端。 关于expire时效性的问题，如果后台改变了数据，但是openresty关于此数据的缓存未过期，前端得到的是旧数据。 大致来说openresty = nginx + lua，不仅具有nginx反向代理的能力，还能介入lua程序进行扩展。 三、运行到此为止，docker-compose.yml应该如下 language-yml1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950version: '3.8'networks: multi-cache: driver: bridge ipam: driver: default config: - subnet: 172.30.3.0/24services: mysql: container_name: mysql image: mysql:8 volumes: - ./mysql/conf/my.cnf:/etc/mysql/conf.d/my.cnf - ./mysql/data:/var/lib/mysql - ./mysql/logs:/logs ports: - &quot;3306:3306&quot; environment: - MYSQL_ROOT_PASSWORD=1009 networks: multi-cache: ipv4_address: 172.30.3.2 nginx: container_name: nginx image: nginx:stable volumes: - ./nginx/conf/nginx.conf:/etc/nginx/nginx.conf - ./nginx/conf/conf.d/default.conf:/etc/nginx/conf.d/default.conf - ./nginx/dist:/usr/share/nginx/dist ports: - &quot;8080:8080&quot; networks: multi-cache: ipv4_address: 172.30.3.3 openresty1: container_name: openresty1 image: openresty/openresty:1.21.4.3-3-jammy-amd64 volumes: - ./openresty1/conf/nginx.conf:/usr/local/openresty/nginx/conf/nginx.conf - ./openresty1/conf/conf.d/default.conf:/etc/nginx/conf.d/default.conf - ./openresty1/lua:/usr/local/openresty/nginx/lua - ./openresty1/lualib/common.lua:/usr/local/openresty/lualib/common.lua networks: multi-cache: ipv4_address: 172.30.3.11 启动各项服务 language-bash1docker-compose -p multi-cache up -d 启动springboot程序。 四、测试清空openresty容器日志。访问http://localhost:8080/item.html?id=10001查看openresty容器日志，可以看到两次commonUtils.read_data都没有缓存，于是代理到tomcat，可以看到springboot日志出现查询相关记录。 language-txt1232024-01-12 11:45:53 2024/01/12 03:45:53 [error] 7#7: *1 [lua] common.lua:99: read_data(): redis cache miss, try tomcat, key: item:id:10001, client: 172.30.3.3, server: localhost, request: &quot;GET /api/item/10001 HTTP/1.0&quot;, host: &quot;nginx-cluster&quot;, referrer: &quot;http://localhost:8080/item.html?id=10001&quot;2024-01-12 11:45:53 2024/01/12 03:45:53 [error] 7#7: *1 [lua] common.lua:99: read_data(): redis cache miss, try tomcat, key: item:stock:id:10001 while sending to client, client: 172.30.3.3, server: localhost, request: &quot;GET /api/item/10001 HTTP/1.0&quot;, host: &quot;nginx-cluster&quot;, referrer: &quot;http://localhost:8080/item.html?id=10001&quot;2024-01-12 11:45:53 172.30.3.3 - - [12/Jan/2024:03:45:53 +0000] &quot;GET /api/item/10001 HTTP/1.0&quot; 200 486 &quot;http://localhost:8080/item.html?id=10001&quot; &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0&quot; 再次访问此网址，强制刷新+禁用浏览器缓存+更换浏览器间隔超过4s但小于1800s时，日志如下，只出现一次miss。 language-txt122024-01-12 11:48:04 2024/01/12 03:48:04 [error] 7#7: *4 [lua] common.lua:99: read_data(): redis cache miss, try tomcat, key: item:stock:id:10001, client: 172.30.3.3, server: localhost, request: &quot;GET /api/item/10001 HTTP/1.0&quot;, host: &quot;nginx-cluster&quot;, referrer: &quot;http://localhost:8080/item.html?id=10001&quot;2024-01-12 11:48:04 172.30.3.3 - - [12/Jan/2024:03:48:04 +0000] &quot;GET /api/item/10001 HTTP/1.0&quot; 200 486 &quot;http://localhost:8080/item.html?id=10001&quot; &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0&quot; 再次访问此网址，强制刷新+禁用浏览器缓存+更换浏览器间隔小于4s，日志如下，未出现miss。 language-txt12024-01-12 11:49:16 172.30.3.3 - - [12/Jan/2024:03:49:16 +0000] &quot;GET /api/item/10001 HTTP/1.0&quot; 200 486 &quot;http://localhost:8080/item.html?id=10001&quot; &quot;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36 Edg/121.0.0.0&quot; 五、高可用集群1. openresty 对于openresty高可用，可以部署多个openresty docker实例，并在nginx的docker/nginx/conf/conf.d/default.conf的upstream nginx-cluster将多个openresty地址添加进去即可。比如 language-txt1234567upstream nginx-cluster { hash $request_uri; # hash $request_uri consistent; server 172.30.3.11; server 172.30.3.12; server 172.30.3.13;} 多个openresty 无论是conf还是lua都保持一致即可。并且使用hash $request_uri负载均衡作为反向代理策略，防止同一请求被多个实例缓存数据。 2. tomcat 对于springboot程序高可用，也是类似。可以部署多个springboot docker实例，并在openresty 的docker/openresty1/conf/conf.d/default.conf的upstream nginx-cluster将多个springboot地址添加进去即可。比如 language-txt12345upstream tomcat-cluster { hash $request_uri; server 172.30.3.4:8081; server 172.30.3.5:8081;}","link":"/Hexo/2024/01/12/2024-H1/2024-01-12-19-57-30/"},{"title":"多级缓存架构(五)缓存同步","text":"通过本文章，可以完成多级缓存架构中的缓存同步。 一、Canal服务 1. mysql添加canal用户连接在上一次multiCache项目中运行的mysql容器，创建canal用户。 language-sql1234CREATE USER canal IDENTIFIED BY 'canal'; GRANT SELECT, REPLICATION SLAVE, REPLICATION CLIENT ON *.* TO 'canal'@'%';-- GRANT ALL PRIVILEGES ON *.* TO 'canal'@'%' ;FLUSH PRIVILEGES; 2. mysql配置文件在docker/mysql/conf/my.cnf添加如下配置 language-txt1234server-id=1000log-bin=/var/lib/mysql/mysql-binbinlog-do-db=heimabinlog_format=row 3. canal配置文件添加canal服务块到docker-compose.yml，如下 language-yml12345678910111213canal: container_name: canal image: canal/canal-server:v1.1.7 volumes: - ./canal/logs:/home/admin/canal-server/logs - ./canal/conf:/home/admin/canal-server/conf ports: - &quot;11111:11111&quot; depends_on: - mysql networks: multi-cache: ipv4_address: 172.30.3.7 language-bash1docker pull canal/canal-server:v1.1.7 任意启动一个canal-server容器，将里面的/home/admin/canal-server/conf文件夹复制到宿主机，对应docker/canal/conf文件夹。删除此临时容器。 修改docker/canal/conf/canal.properties如下条目 language-dart12canal.destinations=examplecanal.instance.tsdb.enable=true 修改docker/canal/conf/example/instance.properties如下条目 language-dart1234567canal.instance.master.address=172.30.3.2:3306canal.instance.dbUsername=canalcanal.instance.dbPassword=canalcanal.instance.connectionCharset = UTF-8canal.instance.tsdb.enable=truecanal.instance.gtidon=falsecanal.instance.filter.regex=heima\\\\..* 二、引入依赖pom.xml language-xml12345&lt;dependency&gt; &lt;groupId&gt;top.javatool&lt;/groupId&gt; &lt;artifactId&gt;canal-spring-boot-starter&lt;/artifactId&gt; &lt;version&gt;1.2.1-RELEASE&lt;/version&gt; &lt;/dependency&gt; application.yml language-yml123canal: destination: example server: 172.30.3.7:11111 三、监听Canal消息这是canal-spring-boot-starter官方仓库，含使用文档 新建canal.ItemHandler类，内容如下 language-java1234567891011121314151617181920212223242526272829303132333435363738394041package com.heima.item.canal;import com.github.benmanes.caffeine.cache.Cache;import com.heima.item.config.RedisHandler;import com.heima.item.pojo.Item;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.stereotype.Component;import top.javatool.canal.client.annotation.CanalTable;import top.javatool.canal.client.handler.EntryHandler;@CanalTable(value = &quot;tb_item&quot;)@Componentpublic class ItemHandler implements EntryHandler&lt;Item&gt; { @Autowired private RedisHandler redisHandler; @Autowired private Cache&lt;Long, Item&gt; itemCache; @Override public void insert(Item item) { itemCache.put(item.getId(), item); redisHandler.saveItem(item); } @Override public void update(Item before, Item after) { itemCache.put(after.getId(), after); redisHandler.saveItem(after); } @Override public void delete(Item item) { itemCache.invalidate(item.getId()); redisHandler.deleteItemById(item.getId()); }} 修改pojo.Item类，如下 language-java123456789101112131415161718192021222324252627282930313233343536package com.heima.item.pojo;import com.baomidou.mybatisplus.annotation.IdType;import com.baomidou.mybatisplus.annotation.TableField;import com.baomidou.mybatisplus.annotation.TableId;import com.baomidou.mybatisplus.annotation.TableName;import lombok.Data;import org.springframework.data.annotation.Id;import org.springframework.data.annotation.Transient;import java.util.Date;@Data@TableName(&quot;tb_item&quot;)public class Item { @TableId(type = IdType.AUTO) @Id private Long id;//商品id private String name;//商品名称 private String title;//商品标题 private Long price;//价格（分） private String image;//商品图片 private String category;//分类名称 private String brand;//品牌名称 private String spec;//规格 private Integer status;//商品状态 1-正常，2-下架 private Date createTime;//创建时间 private Date updateTime;//更新时间 @TableField(exist = false) @Transient private Integer stock; @TableField(exist = false) @Transient private Integer sold;} 四、运行到此为止，docker-compose.yml内容应该如下 language-yml12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576version: '3.8'networks: multi-cache: driver: bridge ipam: driver: default config: - subnet: 172.30.3.0/24services: mysql: container_name: mysql image: mysql:8 volumes: - ./mysql/conf/my.cnf:/etc/mysql/conf.d/my.cnf - ./mysql/data:/var/lib/mysql - ./mysql/logs:/logs ports: - &quot;3306:3306&quot; environment: - MYSQL_ROOT_PASSWORD=1009 networks: multi-cache: ipv4_address: 172.30.3.2 nginx: container_name: nginx image: nginx:stable volumes: - ./nginx/conf/nginx.conf:/etc/nginx/nginx.conf - ./nginx/conf/conf.d/default.conf:/etc/nginx/conf.d/default.conf - ./nginx/dist:/usr/share/nginx/dist ports: - &quot;8080:8080&quot; networks: multi-cache: ipv4_address: 172.30.3.3 canal: container_name: canal image: canal/canal-server:v1.1.7 volumes: - ./canal/logs:/home/admin/canal-server/logs - ./canal/conf:/home/admin/canal-server/conf ports: - &quot;11111:11111&quot; depends_on: - mysql networks: multi-cache: ipv4_address: 172.30.3.7 openresty1: container_name: openresty1 image: openresty/openresty:1.21.4.3-3-jammy-amd64 volumes: - ./openresty1/conf/nginx.conf:/usr/local/openresty/nginx/conf/nginx.conf - ./openresty1/conf/conf.d/default.conf:/etc/nginx/conf.d/default.conf - ./openresty1/lua:/usr/local/openresty/nginx/lua - ./openresty1/lualib/common.lua:/usr/local/openresty/lualib/common.lua networks: multi-cache: ipv4_address: 172.30.3.11 redis: container_name: redis image: redis:7.2 volumes: - ./redis/redis.conf:/usr/local/etc/redis/redis.conf ports: - &quot;6379:6379&quot; command: [ &quot;redis-server&quot;, &quot;/usr/local/etc/redis/redis.conf&quot; ] networks: multi-cache: ipv4_address: 172.30.3.21 删除原来的multiCache，重新启动各项服务。 language-bash1docker-compose -p multi-cache up -d 启动springboot程序。 五、测试springboot不断输入类似如下日志，属于正常监听canal消息中。 language-txt12309:27:17:175 INFO 1 --- [l-client-thread] t.j.c.client.client.AbstractCanalClient : 获取消息 Message[id=-1,entries=[],raw=false,rawEntries=[]]09:27:18:177 INFO 1 --- [l-client-thread] t.j.c.client.client.AbstractCanalClient : 获取消息 Message[id=-1,entries=[],raw=false,rawEntries=[]]09:27:19:178 INFO 1 --- [l-client-thread] t.j.c.client.client.AbstractCanalClient : 获取消息 Message[id=-1,entries=[],raw=false,rawEntries=[]] 访问http://localhost:8081/item/10001，此时信息为tomcat查询数据库所得数据，而后存入Caffeine缓存。访问http://localhost:8080/item.html?id=10001，此时信息为Redis缓存数据。 然后，访问http://localhost:8081/来到商品管理页面。 修改id=10001的数据的商品分类 确认后springboot日志出现类似如下日志 language-txt1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484909:31:29:234 INFO 1 --- [l-client-thread] t.j.c.client.client.AbstractCanalClient : 获取消息 Message[id=1,entries=[header { version: 1 logfileName: &quot;binlog.000007&quot; logfileOffset: 236 serverId: 1 serverenCode: &quot;UTF-8&quot; executeTime: 1705051889000 sourceType: MYSQL schemaName: &quot;&quot; tableName: &quot;&quot; eventLength: 93}entryType: TRANSACTIONBEGINstoreValue: &quot; \\r&quot;, header { version: 1 logfileName: &quot;binlog.000007&quot; logfileOffset: 411 serverId: 1 serverenCode: &quot;UTF-8&quot; executeTime: 1705051889000 sourceType: MYSQL schemaName: &quot;heima&quot; tableName: &quot;tb_item&quot; eventLength: 626 eventType: UPDATE props { key: &quot;rowsCount&quot; value: &quot;1&quot; }}entryType: ROWDATAstoreValue: &quot;\\bV\\020\\002P\\000b\\332\\n\\n&amp;\\b\\000\\020\\373\\377\\377\\377\\377\\377\\377\\377\\377\\001\\032\\002id \\001(\\0000\\000B\\00510001R\\006bigint\\nd\\b\\001\\020\\f\\032\\005title \\000(\\0000\\000BCRIMOWA 21\\345\\257\\270\\346\\211\\230\\350\\277\\220\\347\\256\\261\\346\\213\\211\\346\\235\\206\\347\\256\\261 SALSA AIR\\347\\263\\273\\345\\210\\227\\346\\236\\234\\347\\273\\277\\350\\211\\262 820.70.36.4R\\fvarchar(264)\\n)\\b\\002\\020\\f\\032\\004name \\000(\\0000\\000B\\tSALSA AIRR\\fvarchar(128)\\n)\\b\\003\\020\\373\\377\\377\\377\\377\\377\\377\\377\\377\\001\\032\\005price \\000(\\0000\\000B\\00516900R\\006bigint\\n\\226\\001\\b\\004\\020\\f\\032\\005image \\000(\\0000\\000Buhttps://m.360buyimg.com/mobilecms/s720x720_jfs/t6934/364/1195375010/84676/e9f2c55f/597ece38N0ddcbc77.jpg!q70.jpg.webpR\\fvarchar(200)\\n0\\b\\005\\020\\f\\032\\bcategory \\000(\\0000\\000B\\f\\346\\213\\211\\346\\235\\206\\347\\256\\261777R\\fvarchar(200)\\n\\'\\b\\006\\020\\f\\032\\005brand \\000(\\0000\\000B\\006RIMOWAR\\fvarchar(100)\\nG\\b\\a\\020\\f\\032\\004spec \\000(\\0000\\000B\\'{\\&quot;\\351\\242\\234\\350\\211\\262\\&quot;: \\&quot;\\347\\272\\242\\350\\211\\262\\&quot;, \\&quot;\\345\\260\\272\\347\\240\\201\\&quot;: \\&quot;26\\345\\257\\270\\&quot;}R\\fvarchar(200)\\n\\032\\b\\b\\020\\004\\032\\006status \\000(\\0000\\000B\\0011R\\003int\\n6\\b\\t\\020]\\032\\vcreate_time \\000(\\0000\\000B\\0232019-05-01 00:00:00R\\bdatetime\\n6\\b\\n\\020]\\032\\vupdate_time \\000(\\0000\\000B\\0232019-05-01 00:00:00R\\bdatetime\\022&amp;\\b\\000\\020\\373\\377\\377\\377\\377\\377\\377\\377\\377\\001\\032\\002id \\001(\\0000\\000B\\00510001R\\006bigint\\022d\\b\\001\\020\\f\\032\\005title \\000(\\0000\\000BCRIMOWA 21\\345\\257\\270\\346\\211\\230\\350\\277\\220\\347\\256\\261\\346\\213\\211\\346\\235\\206\\347\\256\\261 SALSA AIR\\347\\263\\273\\345\\210\\227\\346\\236\\234\\347\\273\\277\\350\\211\\262 820.70.36.4R\\fvarchar(264)\\022)\\b\\002\\020\\f\\032\\004name \\000(\\0000\\000B\\tSALSA AIRR\\fvarchar(128)\\022)\\b\\003\\020\\373\\377\\377\\377\\377\\377\\377\\377\\377\\001\\032\\005price \\000(\\0000\\000B\\00516900R\\006bigint\\022\\226\\001\\b\\004\\020\\f\\032\\005image \\000(\\0000\\000Buhttps://m.360buyimg.com/mobilecms/s720x720_jfs/t6934/364/1195375010/84676/e9f2c55f/597ece38N0ddcbc77.jpg!q70.jpg.webpR\\fvarchar(200)\\0220\\b\\005\\020\\f\\032\\bcategory \\000(\\0010\\000B\\f\\346\\213\\211\\346\\235\\206\\347\\256\\261888R\\fvarchar(200)\\022\\'\\b\\006\\020\\f\\032\\005brand \\000(\\0000\\000B\\006RIMOWAR\\fvarchar(100)\\022G\\b\\a\\020\\f\\032\\004spec \\000(\\0000\\000B\\'{\\&quot;\\351\\242\\234\\350\\211\\262\\&quot;: \\&quot;\\347\\272\\242\\350\\211\\262\\&quot;, \\&quot;\\345\\260\\272\\347\\240\\201\\&quot;: \\&quot;26\\345\\257\\270\\&quot;}R\\fvarchar(200)\\022\\032\\b\\b\\020\\004\\032\\006status \\000(\\0000\\000B\\0011R\\003int\\0226\\b\\t\\020]\\032\\vcreate_time \\000(\\0000\\000B\\0232019-05-01 00:00:00R\\bdatetime\\0226\\b\\n\\020]\\032\\vupdate_time \\000(\\0000\\000B\\0232019-05-01 00:00:00R\\bdatetime&quot;],raw=false,rawEntries=[]]09:31:30:572 INFO 1 --- [l-client-thread] t.j.c.client.client.AbstractCanalClient : 获取消息 Message[id=2,entries=[header { version: 1 logfileName: &quot;binlog.000007&quot; logfileOffset: 1037 serverId: 1 serverenCode: &quot;UTF-8&quot; executeTime: 1705051889000 sourceType: MYSQL schemaName: &quot;&quot; tableName: &quot;&quot; eventLength: 31}entryType: TRANSACTIONENDstoreValue: &quot;\\022\\00287&quot;],raw=false,rawEntries=[]] 这里可以先用redis连接工具查询数据，发现rediis已被更新。 再次访问http://localhost:8081/item/10001直接向springboot的controller发送请求，发现caffeine数据更新，并且springboot日志没有出现查询记录，说明走的是caffeine。","link":"/Hexo/2024/01/12/2024-H1/2024-01-12-20-12-42/"},{"title":"Docker运行RabbitMQ并使用SpringAMQP操作","text":"一、RabbitMQ运行拉取docker镜像 language-bash1docker pull rabbitmq:3-management 基础运行命令 language-bash12345678docker run \\ -e RABBITMQ_DEFAULT_USER=rabbitmq \\ -e RABBITMQ_DEFAULT_PASS=rabbitmq \\ --name rabbitmq \\ -p 15672:15672 \\ -p 5672:5672 \\ -d \\ rabbitmq:3-management 15672是网页后台管理系统，5672是给服务用的。 官方入门教程可以看这里RabbitMQ Tutorials — RabbitMQ 二、整合SpringAMQP1. 引入依赖language-xml1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt; &lt;/dependency&gt; language-yml123456spring: rabbitmq: host: localhost # rabbitMQ的ip地址 port: 5672 # rabbitMQ服务端口 username: rabbitmq password: rabbitmq 三、测试这边采用常用的消费者-生产者模型，使用默认的Direct类型exchange。不懂的可以先继续学习rabbitmq再来实践。 1. 消费者在消费者服务随便新建一个listener language-java123456789101112131415@Slf4j@Componentpublic class SpringRabbitListener { @RabbitListener(bindings = @QueueBinding( value = @Queue(name = &quot;simple.queue&quot;), exchange = @Exchange(name = &quot;simple.exchange&quot;), key = &quot;simple&quot; )) public void listenSimpleQueue(String msg) { log.info(&quot;消费者接收到simple.queue的消息：【&quot; + msg + &quot;】&quot;); }} 2. 生产者在生产者服务的Test模块新建一个测试 language-java123456789101112131415@Slf4j@RunWith(SpringRunner.class)@SpringBootTestpublic class SpringAmqpTest { @Autowired private RabbitTemplate rabbitTemplate; @Test public void testSendMessage2SimpleQueue() throws InterruptedException { String message = &quot;hello, spring amqp!&quot;; rabbitTemplate.convertAndSend(&quot;simple.exchange&quot;, &quot;simple&quot;, message); }} 3. 运行先启动消费者。登录http://localhost:15672/，可以看到simple.exchange和simple.queue已被创建。 然后启动测试testSendMessage2SimpleQueue，出现类似以下日志，消息发送成功。 language-txt1212:17:43:771 INFO 21064 --- [ main] o.s.a.r.c.CachingConnectionFactory : Attempting to connect to: [localhost:5672]12:17:43:808 INFO 21064 --- [ main] o.s.a.r.c.CachingConnectionFactory : Created new connection: rabbitConnectionFactory#50f40653:0/SimpleConnection@536d97f8 [delegate=amqp://rabbitmq@127.0.0.1:5672/, localPort= 59641] 消费者出现类似以下日志，收到消息。 language-txt12312:17:31:074 INFO 8924 --- [ main] o.s.a.r.c.CachingConnectionFactory : Created new connection: rabbitConnectionFactory#2a27cb34:0/SimpleConnection@671facee [delegate=amqp://rabbitmq@127.0.0.1:5672/, localPort= 59634]12:17:31:141 INFO 8924 --- [ main] cn.itcast.mq.ConsumerApplication : Started ConsumerApplication in 1.011 seconds (JVM running for 1.462)12:17:43:848 INFO 8924 --- [ntContainer#0-1] c.i.mq.listener.SpringRabbitListener : 消费者接收到simple.queue的消息：【hello, spring amqp!】","link":"/Hexo/2024/01/14/2024-H1/2024-01-14-12-19-21/"},{"title":"RabbitMQ常见问题之消息可靠性","text":"一、介绍MQ的消息可靠性，将从以下四个方面展开并实践： 生产者消息确认 消息持久化 消费者消息确认 消费失败重试机制 二、生产者消息确认对于publisher，如果message到达exchange与否，rabbitmq提供publiser-comfirm机制，如果message达到exchange但是是否到达queue，rabbitmq提供publisher-return机制。这两种机制在代码中都可以通过配置来自定义实现。 以下操作都在publisher服务方完成。 1. 引入依赖language-xml1234&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-amqp&lt;/artifactId&gt; &lt;/dependency&gt; language-yaml123456spring: rabbitmq: publisher-confirm-type: correlated publisher-returns: true template: mandatory: true 配置说明：publish-confirm-type:开启publisher-confirm，这里支持两种类型： simple：同步等待confirm结果，直到超时 correlated：异步回调，定义ConfirmCallback，MQ返回结果时会回调这个ConfirmCallback publish-returns：开启publish-return功能，同样是基于callback机制，不过是定义ReturnCallbacktemplate.mandatory：定义消息路由失败时的策略。true，则调用ReturnCallback; false，则直接丢弃消息 2. 配置ReturnCallBack每个RabbitTemplate只能配置一个ReturnCallBack，所以直接给IoC里面的RabbitTemplate配上，所有人都统一用。新建配置类，实现ApplicationContextAware 接口，在接口中setReturnCallback。 language-java12345678910111213141516171819202122@Slf4j@Configurationpublic class CommonConfig implements ApplicationContextAware { @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException { RabbitTemplate rabbitTemplate = applicationContext.getBean(RabbitTemplate.class); rabbitTemplate.setReturnCallback((message, replyCode, replyText, exchange, routingKey)-&gt;{ //check if is delay message if (message.getMessageProperties().getReceivedDelay() != null &amp;&amp; message.getMessageProperties().getReceivedDelay() &gt; 0) { return; } log.error(&quot;消息发送到queue失败，replyCode={}, reason={}, exchange={}, routeKey={}, message={}&quot;, replyCode, replyText, exchange, routingKey, message.toString()); }); }} 3. 配置ConfirmCallBackConfirmCallBack在message发送时配置，每个message都可以有自己的ConfirmCallBack。 language-java12345678910111213141516171819202122232425@Test public void testSendMessage2SimpleQueue() throws InterruptedException { String message = &quot;hello, spring amqp!&quot;; // confirm callback CorrelationData correlationData = new CorrelationData(UUID.randomUUID().toString()); correlationData.getFuture().addCallback( result -&gt; { if (result.isAck()){ log.debug(&quot;消息到exchange成功, id={}&quot;, correlationData.getId()); }else { log.error(&quot;消息到exchange失败, id={}&quot;, correlationData.getId()); } }, throwable -&gt; { log.error(&quot;消息发送失败&quot;, throwable); } ); rabbitTemplate.convertAndSend(&quot;amq.topic&quot;, &quot;simple.test&quot;, message, correlationData); } 4. 测试将消息发送到一个不存在的exchange，模拟消息达到exchange失败，触发ConfirmCallBack，日志如下。 language-txt1218:22:03:913 ERROR 23232 --- [ 127.0.0.1:5672] o.s.a.r.c.CachingConnectionFactory : Channel shutdown: channel error; protocol method: #method&lt;channel.close&gt;(reply-code=404, reply-text=NOT_FOUND - no exchange 'aamq.topic' in vhost '/', class-id=60, method-id=40)18:22:03:915 ERROR 23232 --- [nectionFactory1] cn.itcast.mq.spring.SpringAmqpTest : 消息到exchange失败, id=0c0910a3-7937-43ea-9606-e5bbcdda0b5c 将消息发送到一个存在的exchange，但routekey异常，模拟消息到达exchange但没有到达queue，触发ConfirmCallBack和ReturnCallBack，日志如下。 language-txt12318:27:22:757 INFO 20184 --- [ main] o.s.a.r.c.CachingConnectionFactory : Created new connection: rabbitConnectionFactory#7428de63:0/SimpleConnection@6d60899e [delegate=amqp://rabbitmq@127.0.0.1:5672/, localPort= 53662]18:27:22:797 DEBUG 20184 --- [ 127.0.0.1:5672] cn.itcast.mq.spring.SpringAmqpTest : 消息到exchange成功, id=5fbdaaa1-5f20-4683-bdfa-bd71cd6afd1118:27:22:796 ERROR 20184 --- [nectionFactory1] cn.itcast.mq.config.CommonConfig : 消息发送到queue失败，replyCode=312, reason=NO_ROUTE, exchange=amq.topic, routeKey=simplee.test, message=(Body:'hello, spring amqp!' MessageProperties [headers={spring_returned_message_correlation=5fbdaaa1-5f20-4683-bdfa-bd71cd6afd11}, contentType=text/plain, contentEncoding=UTF-8, contentLength=0, receivedDeliveryMode=PERSISTENT, priority=0, deliveryTag=0]) 三、消息持久化 新版本的SpringAMQP默认开启持久化。RabbitMQ本身并不默认开启持久化。 队列持久化，通过QueueBuilder构建持久化队列，比如 language-java1234567@Bean public Queue simpleQueue(){ return QueueBuilder .durable(&quot;simple.queue&quot;) .build(); } 消息持久化，在发送时可以设置，比如 language-java12345678@Testpublic void testDurableMessage(){ Message message = MessageBuilder.withBody(&quot;hello springcloud&quot;.getBytes(StandardCharsets.UTF_8)) .setDeliveryMode(MessageDeliveryMode.PERSISTENT) .build(); rabbitTemplate.convertAndSend(&quot;simple.queue&quot;, message);} 四、消费者消息确认消费者消息确认是指，consumer收到消息后会给rabbitmq发送回执来确认消息接收状况。 SpringAMQP允许配置三种确认模式: manual：手动ack，需要在业务代码结束后，调用api发送ack。 auto：自动ack，由spring监测listener代码是否出现异常，没有异常则返回ack；抛出异常则返回nack none:关闭ack, MQ假定消费者获取消息后会成功处理,因此消息投递后立即被删除 language-yaml123456spring: rabbitmq: listener: simple: prefetch: 1 acknowledge-mode: auto # manual auto none 但是auto有个很大的缺陷，因为rabbitmq会自动不断给有问题的listen反复投递消息，导致不断报错，所以建议使用下一章的操作。 五、消费失败重试机制当消费者出现异常后,消息会不断requeue (重新入队)到队列,再重新发送给消费者,然后再次异常,再次requeue，无限循环，导致mq的消息处理飙升，带来不必要的压力。 我们可以利用Spring的retry机制,在消费者出现异常时利用本地重试,而不是无限制的requeue到mq队列。 1. 引入依赖language-yml1234567891011spring: rabbitmq: listener: simple: prefetch: 1 retry: enabled: true # 开启消费者失败重试 initial-interval: 1000 #初识的失败等待时长为1秒 multiplier: 2 # 下次失败的等待时长倍数，下次等待时长 = multiplier * last-interval max-attempts: 3 # 最大重试次数 stateless: true # true无状态；false有状态。如果业务中包含事务，这里改为false 2. 配置重试次数耗尽策略 我们采用RepublishMessageRecoverer。定义用于接收失败消息的exchange，queue以及它们之间的bindings。 然后定义MessageRecoverer，比如 language-java123456789@Componentpublic class ErrorMessageConfig { @Bean public MessageRecoverer republishMessageRecover(RabbitTemplate rabbitTemplate){ return new RepublishMessageRecoverer(rabbitTemplate, &quot;error.exchange&quot;, &quot;error&quot;); }} 3. 测试定义处理异常消息的exchange和queue，比如 language-java123456789@RabbitListener(bindings = @QueueBinding( value = @Queue(name = &quot;error.queue&quot;), exchange = @Exchange(name = &quot;error.exchange&quot;), key = &quot;error&quot;))public void listenErrorQueue(String msg){ log.info(&quot;消费者接收到error.queue的消息：【&quot; + msg + &quot;】&quot;);} 定义如下一个listener，来模拟consumer处理消息失败触发消息重试。 language-java1234567891011@RabbitListener(bindings = @QueueBinding( value = @Queue(name = &quot;simple.queue&quot;), exchange = @Exchange(name = &quot;simple.exchange&quot;), key = &quot;simple&quot;))public void listenSimpleQueue(String msg) { log.info(&quot;消费者接收到simple.queue的消息：【&quot; + msg + &quot;】&quot;); System.out.println(1/0); log.info(&quot;consumer handle message success&quot;);} 写一个简单的测试，往simple.exchange发送消息，比如 language-java123456@Testpublic void testSendMessageSimpleQueue() throws InterruptedException { String message = &quot;hello, spring amqp!&quot;; rabbitTemplate.convertAndSend(&quot;simple.exchange&quot;, &quot;simple&quot;, message);} 运行测试，consumer得到以下日志 language-txt1234518:51:10:164 INFO 24072 --- [ntContainer#0-1] c.i.mq.listener.SpringRabbitListener : 消费者接收到simple.queue的消息：【hello, spring amqp!】18:51:11:167 INFO 24072 --- [ntContainer#0-1] c.i.mq.listener.SpringRabbitListener : 消费者接收到simple.queue的消息：【hello, spring amqp!】18:51:13:168 INFO 24072 --- [ntContainer#0-1] c.i.mq.listener.SpringRabbitListener : 消费者接收到simple.queue的消息：【hello, spring amqp!】18:51:13:176 WARN 24072 --- [ntContainer#0-1] o.s.a.r.retry.RepublishMessageRecoverer : Republishing failed message to exchange 'error.exchange' with routing key error18:51:13:181 INFO 24072 --- [ntContainer#1-1] c.i.mq.listener.SpringRabbitListener : 消费者接收到error.queue的消息：【hello, spring amqp!】 可以看到spring尝试2次重发，一共3次，第一次间隔1秒，第二次间隔2秒，重试次数耗尽，消息被consumer传入error.exchange，注意，是consumer传的，不是simple.queue。","link":"/Hexo/2024/01/17/2024-H1/2024-01-17-18-55-26/"},{"title":"RabbitMQ常见问题之延迟消息","text":"一、死信交换机当一个队列中的消息满足下列情况之一时，可以成为死信（dead letter）： 消费者使用basic.reject或 basic.nack声明消费失败，并且消息的requeue参数设置为false 消息是一个过期消息，超时无人消费 要投递的队列消息堆积满了，最早的消息可能成为死信 如果该队列配置了dead-letter-exchange属性，指定了一个交换机，那么队列中的死信就会投递到这个交换机中，而这个交换机称为死信交换机(Dead Letter Exchange,简称DLX)。 二、TTL 如果message和queue都有ttl，采用更小的一方。 1. Queue指定死信交换机并设置TTLlanguage-java1234567891011121314151617181920212223242526@Configurationpublic class CommonConfig { @Bean public DirectExchange ttlExchange(){ return new DirectExchange(&quot;ttl.direct&quot;); } @Bean public Queue ttlQueue(){ return QueueBuilder .durable(&quot;ttl.queue&quot;) .ttl(10000) .deadLetterExchange(&quot;dl.direct&quot;) .deadLetterRoutingKey(&quot;dl&quot;) .build(); } @Bean public Binding ttlBinding(){ return BindingBuilder.bind(ttlQueue()).to(ttlExchange()).with(&quot;ttl&quot;); }} 2. 消息设置TTLlanguage-java12345678910@Testpublic void testTTLMessage(){ Message message = MessageBuilder.withBody(&quot;hello ttl&quot;.getBytes(StandardCharsets.UTF_8)) .setDeliveryMode(MessageDeliveryMode.PERSISTENT) .setExpiration(&quot;5000&quot;) .build(); rabbitTemplate.convertAndSend(&quot;ttl.direct&quot;, &quot;ttl&quot;, message); log.info(&quot;ttl消息已发送&quot;);} 借助TTL机制可以用死信交换机模拟延迟队列，但是设计上比较牵强，性能不好。 三、延迟队列这是官方提供的一些额外插件https://www.rabbitmq.com/community-plugins.html 下载其中的DelayExchange插件，把.ez文件挂载到RabbitMQ容器的/plugins目录下，然后进入容器，执行 language-bash1rabbitmq-plugins enable rabbitmq_delayed_message_exchange language-txt123456789101112131415root@7c4ba266e5bc:/# rabbitmq-plugins enable rabbitmq_delayed_message_exchangeEnabling plugins on node rabbit@7c4ba266e5bc:rabbitmq_delayed_message_exchangeThe following plugins have been configured: rabbitmq_delayed_message_exchange rabbitmq_management rabbitmq_management_agent rabbitmq_prometheus rabbitmq_web_dispatchApplying plugin configuration to rabbit@7c4ba266e5bc...The following plugins have been enabled: rabbitmq_delayed_message_exchangestarted 1 plugins. 1. SpringAMQP创建延迟队列基于@RabbitListener或者基于@Bean都可以。 language-java123456789@RabbitListener(bindings = @QueueBinding( value = @Queue(name = &quot;delay.queue&quot;), exchange = @Exchange(name = &quot;delay.direct&quot;, delayed = &quot;true&quot;), key = &quot;delay&quot;))public void listenDelayExchange(String msg){ log.info(&quot;消费者接收到delay.queue的延迟消息：【&quot; + msg + &quot;】&quot;);} 2. 设置消息延迟这个插件只能在消息上设置延迟时间，没有队列设置延迟时间的概念，不过都是一样的。message要在Header上添加一个x-delay。 language-java123456789101112@Testpublic void testDelayMessage(){ Message message = MessageBuilder.withBody(&quot;hello delay&quot;.getBytes(StandardCharsets.UTF_8)) .setDeliveryMode(MessageDeliveryMode.PERSISTENT) .setHeader(&quot;x-delay&quot;, 5000) .build(); // confirm callback CorrelationData correlationData = new CorrelationData(UUID.randomUUID().toString()); rabbitTemplate.convertAndSend(&quot;delay.direct&quot;, &quot;delay&quot;, message, correlationData); log.info(&quot;发送消息成功&quot;);} 3. 测试直接运行测试，可能会报错，因为rabbitmq意识到消息到了exchange却没有立即到queue，被认为错误，回调returnback，所以我们在ReturnCallBack中绕过这个限制。 language-java123456789101112131415161718192021@Slf4j@Configurationpublic class CommonConfig implements ApplicationContextAware { @Override public void setApplicationContext(ApplicationContext applicationContext) throws BeansException { RabbitTemplate rabbitTemplate = applicationContext.getBean(RabbitTemplate.class); rabbitTemplate.setReturnCallback((message, replyCode, replyText, exchange, routingKey)-&gt;{ //check if is delay message if (message.getMessageProperties().getReceivedDelay() != null &amp;&amp; message.getMessageProperties().getReceivedDelay() &gt; 0) { return; } log.error(&quot;消息发送到queue失败，replyCode={}, reason={}, exchange={}, routeKey={}, message={}&quot;, replyCode, replyText, exchange, routingKey, message.toString()); }); }} 运行Test测试，可以看到Test方面，消息发送的时间为21:09:13 language-txt1221:09:13:516 INFO 25468 --- [ main] o.s.a.r.c.CachingConnectionFactory : Created new connection: rabbitConnectionFactory#2063c53e:0/SimpleConnection@6415f61e [delegate=amqp://rabbitmq@127.0.0.1:5672/, localPort= 62470]21:09:13:557 INFO 25468 --- [ main] cn.itcast.mq.spring.SpringAmqpTest : 发送消息成功 listener方面消息消费的时间为21:09:18，刚好5s。 language-txt1221:08:31:952 INFO 19532 --- [ main] cn.itcast.mq.ConsumerApplication : Started ConsumerApplication in 1.735 seconds (JVM running for 2.357)21:09:18:583 INFO 19532 --- [ntContainer#0-1] c.i.mq.listener.SpringRabbitListener : 消费者接收到delay.queue的延迟消息：【hello delay】","link":"/Hexo/2024/01/17/2024-H1/2024-01-17-21-11-29/"},{"title":"RabbitMQ常见问题之消息堆积","text":"一、介绍当生产者发送消息的速度超过了消费者处理消息的速度,就会导致队列中的消息堆积,直到队列存储消息达到上限。最早接收到的消息，可能就会成为死信，会被丢弃，这就是消息堆积问题。 解决消息堆积有三种种思路： 增加更多消费者，提高消费速度 在消费者内开启线程池加快消息处理速度 扩大队列容积，提高堆积上限 从RabbitMQ的3.6.0版本开始，就增加了Lazy Queues的概念，也就是惰性队列。惰性队列的特征如下： 接收到消息后直接存入磁盘而非內存 消费者要消费消息时才会从磁盘中读取并加载到内存 支持数百万条的消息存储 二、使用惰性队列1. 基于@Beanlanguage-java12345678@Bean public Queue lazyQueue(){ return QueueBuilder .durable(&quot;lazy.queue&quot;) .lazy() .build(); } 2. 基于@RabbitListenerlanguage-java123456789 @RabbitListener(bindings = @QueueBinding( value = @Queue(name = &quot;lazy.queue&quot;, arguments = @Argument(name = &quot;x-queue-mode&quot;, value = &quot;lazy&quot;)), exchange = @Exchange(name = &quot;simple.exchange&quot;), key = &quot;lazy&quot; )) public void listenLazyExchange(String msg){ // log.info(&quot;消费者接收到lazy.queue的消息：【&quot; + msg + &quot;】&quot;); }","link":"/Hexo/2024/01/17/2024-H1/2024-01-17-21-17-45/"},{"title":"RabbitMQ常见问题之高可用","text":"一、集群分类RabbitMQ的是基于Erlang语言编写,而Erlang又是一个面向并发的语言,天然支持集群模式。RabbitMQ的集群有两种模式： 普通集群：是一种分布式集群，将队列分散到集群的各个节点，从而提高整个集群的并发能力。 镜像集群：是一种主从集群，普通集群的基础上，添加了主从备份功能，提高集群的数据可用性。 镜像集群虽然支持主从,但主从同步并不是强一致的,某些情况下可能有数据丢失的风险。因此在RabbitMQ的3.8版本以后,推出了新的功能——仲裁队列来代替镜像集群,底层采用Raft协议确保主从的数据一致性。 二、普通集群搭建 1. 准备建立如下文件夹结构 language-txt1234567891011121314./cluster/├── docker-compose.yml├── mq1│ ├── .erlang.cookie│ └── conf│ └── rabbitmq.conf├── mq2│ ├── .erlang.cookie│ └── conf│ └── rabbitmq.conf└── mq3 ├── .erlang.cookie └── conf └── rabbitmq.conf 2. 配置rabbitmq.conf都写入以下内容 language-shell1234567loopback_users.guest = falselisteners.tcp.default = 5672cluster_formation.peer_discovery_backend = rabbit_peer_discovery_classic_configcluster_formation.classic_config.nodes.1 = rabbit@mq1cluster_formation.classic_config.nodes.2 = rabbit@mq2cluster_formation.classic_config.nodes.3 = rabbit@mq3vm_memory_high_watermark.absolute = 524288000 .erlang.cookie都写入以下内容 language-txt1SUGWXEQPRCPYJAVYPNZY 集群的所有节点的.erlang.cookie需要保持一致才能互相信任，具体内容并不固定，可以随便新建一个rabbitmq容器去查看其.erlang.cookie然后复制使用即可。 docker-compose.yml写入以下内容 language-yml12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061version: &quot;3.8&quot;networks: rabbitmq-normal-cluster: driver: bridge ipam: driver: default config: - subnet: 172.30.3.0/24services: mq1: container_name: mq1 hostname: mq1 image: rabbitmq:3-management environment: - RABBITMQ_DEFAULT_USER=rabbitmq - RABBITMQ_DEFAULT_PASS=rabbitmq volumes: - ./mq1/conf/rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf - ./mq1/.erlang.cookie:/var/lib/rabbitmq/.erlang.cookie:ro ports: - &quot;8071:5672&quot; - &quot;8081:15672&quot; networks: rabbitmq-normal-cluster: ipv4_address: 172.30.3.11 mq2: container_name: mq2 hostname: mq2 image: rabbitmq:3-management environment: - RABBITMQ_DEFAULT_USER=rabbitmq - RABBITMQ_DEFAULT_PASS=rabbitmq volumes: - ./mq2/conf/rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf - ./mq2/.erlang.cookie:/var/lib/rabbitmq/.erlang.cookie:ro ports: - &quot;8072:5672&quot; - &quot;8082:15672&quot; networks: rabbitmq-normal-cluster: ipv4_address: 172.30.3.12 mq3: container_name: mq3 hostname: mq3 image: rabbitmq:3-management environment: - RABBITMQ_DEFAULT_USER=rabbitmq - RABBITMQ_DEFAULT_PASS=rabbitmq volumes: - ./mq3/conf/rabbitmq.conf:/etc/rabbitmq/rabbitmq.conf - ./mq3/.erlang.cookie:/var/lib/rabbitmq/.erlang.cookie:ro ports: - &quot;8073:5672&quot; - &quot;8083:15672&quot; networks: rabbitmq-normal-cluster: ipv4_address: 172.30.3.13 3. 运行language-bash1docker-compose -p rabbitmq-c up -d 三、镜像集群1. 介绍 镜像模式的配置有3种模式： ha-mode ha-params 效果 准确模式exactly 队列的副本量count 集群中队列副本（主服务器和镜像服务器之和）的数量。count如果为1意味着单个副本：即队列主节点。count值为2表示2个副本：1个队列主和1个队列镜像。换句话说：count = 镜像数量 + 1。如果群集中的节点数少于count，则该队列将镜像到所有节点。如果有集群总数大于count+1，并且包含镜像的节点出现故障，则将在另一个节点上创建一个新的镜像。 all (none) 队列在群集中的所有节点之间进行镜像。队列将镜像到任何新加入的节点。镜像到所有节点将对所有群集节点施加额外的压力，包括网络I / O，磁盘I / O和磁盘空间使用情况。推荐使用exactly，设置副本数为（N / 2 +1）。 nodes node names 指定队列创建到哪些节点，如果指定的节点全部不存在，则会出现异常。如果指定的节点在集群中存在，但是暂时不可用，会创建节点到当前客户端连接到的节点。 2. 启用方式三种模式启动方式分别如下，基于普通集群之上，命令均需要在单个容器内部执行。 language-bash1rabbitmqctl set_policy ha-two &quot;^two\\.&quot; '{&quot;ha-mode&quot;:&quot;exactly&quot;,&quot;ha-params&quot;:2,&quot;ha-sync-mode&quot;:&quot;automatic&quot;}' language-bash1rabbitmqctl set_policy ha-all &quot;^all\\.&quot; '{&quot;ha-mode&quot;:&quot;all&quot;}' language-bash1rabbitmqctl set_policy ha-nodes &quot;^nodes\\.&quot; '{&quot;ha-mode&quot;:&quot;nodes&quot;,&quot;ha-params&quot;:[&quot;rabbit@nodeA&quot;, &quot;rabbit@nodeB&quot;]}' 3. 测试这里以exactly为例，在mq1中执行rabbitmqctl set_policy ha-two &quot;^two\\.&quot; '{&quot;ha-mode&quot;:&quot;exactly&quot;,&quot;ha-params&quot;:2,&quot;ha-sync-mode&quot;:&quot;automatic&quot;}'后，所有前缀为two的queue都会有1个主queue和1个副本。 language-txt123root@mq1:/# rabbitmqctl set_policy ha-two &quot;^two\\.&quot; '{&quot;ha-mode&quot;:&quot;exactly&quot;,&quot;ha-params&quot;:2,&quot;ha-sync-mode&quot;:&quot;automatic&quot;}'Setting policy &quot;ha-two&quot; for pattern &quot;^two\\.&quot; to &quot;{&quot;ha-mode&quot;:&quot;exactly&quot;,&quot;ha-params&quot;:2,&quot;ha-sync-mode&quot;:&quot;automatic&quot;}&quot; with priority &quot;0&quot; for vhost &quot;/&quot; ...root@mq1:/# 来到localhost:8081管理页，找到admin-&gt;policies可以看到策略生效。 来新建一个two.test.queue，可以看到这是一个拥有副本的queue。 四、仲裁队列1. 介绍仲裁队列：仲裁队列是3.8版本以后才有的新功能，用来替代镜像队列，具备下列特征： 与镜像队列一样，都是主从模式，支持主从数据同步 使用非常简单，没有复杂的配置 主从同步基于Raft协议，强一致 上一章中想要一个镜像队列还要执行各种命令，遵循规定，现在不用了。 2. 创建 java使用目前只能基于@Bean创建 language-java12345678@Beanpublic Queue quorumQueue(){ return QueueBuilder .durable(&quot;quorum.queue2&quot;) .quorum() .build();} 五、Java连接RabbitMQ集群方式Java使用RabbitMQ集群application.yml中需要修改address language-yml1234spring: rabbitmq: host: localhost # rabbitMQ的ip地址 port: 5672 # 端口 language-yml123spring: rabbitmq: addresses: localhost:8071, localhost:8072, localhost:8073","link":"/Hexo/2024/01/17/2024-H1/2024-01-17-21-47-33/"},{"title":"SpringBoot3整合OpenAPI3(Swagger3)","text":"swagger2更新到3后，再使用方法上发生了很大的变化，名称也变为OpenAPI3。 官方文档 一、引入依赖language-xml12345&lt;dependency&gt; &lt;groupId&gt;org.springdoc&lt;/groupId&gt; &lt;artifactId&gt;springdoc-openapi-starter-webmvc-ui&lt;/artifactId&gt; &lt;version&gt;${springdoc-openapi.version}&lt;/version&gt;&lt;/dependency&gt; language-yml12345678910server: servlet: context-path: /contentspringdoc: api-docs: enabled: true path: /v3/api-docs swagger-ui: enabled: true path: /swagger-ui.html openapi3使用十分方便，做到这里后，你可以直接通过以下网址访问swagger页面。 language-html1http://&lt;ip&gt;:&lt;port&gt;/content/swagger-ui/index.html 二、使用1. @OpenAPIDefinition + @Info用于定义整个 API 的信息，通常放在主应用类上。可以包括 API 的标题、描述、版本等信息。 language-java12345678910@SpringBootApplication@Slf4j@OpenAPIDefinition(info = @Info(title = &quot;内容管理系统&quot;, description = &quot;对课程相关信息进行管理&quot;, version = &quot;1.0.0&quot;))public class ContentApplication { public static void main(String[] args) { SpringApplication.run(ContentApplication.class, args); }} 2. @Tag用于对 API 进行分组。可以在控制器类或方法级别上使用。 language-java123456@Tag(name = &quot;课程信息编辑接口&quot;)@RestController(&quot;content&quot;)public class CourseBaseInfoController { } 3. @Operation描述单个 API 操作（即一个请求映射方法）。可以提供操作的摘要、描述、标签等。 language-java123456789101112@Operation(summary = &quot;课程查询接口&quot;)@PostMapping(&quot;/course/list&quot;)public PageResult&lt;CourseBase&gt; list( PageParams params, @RequestBody(required = false) QueryCourseParamsDto dto){ CourseBase courseBase = new CourseBase(); courseBase.setCreateDate(LocalDateTime.now()); return new PageResult&lt;CourseBase&gt;(new ArrayList&lt;CourseBase&gt;(List.of(courseBase)),20, 2, 10);} 4. @Parameter用于描述方法参数的额外信息，例如参数的描述、是否必需等。 language-java123456789101112@Operation(summary = &quot;课程查询接口&quot;)@PostMapping(&quot;/course/list&quot;)public PageResult&lt;CourseBase&gt; list( @Parameter(description = &quot;分页参数&quot;) PageParams params, @Parameter(description = &quot;请求具体内容&quot;) @RequestBody(required = false) QueryCourseParamsDto dto){ CourseBase courseBase = new CourseBase(); courseBase.setCreateDate(LocalDateTime.now()); return new PageResult&lt;CourseBase&gt;(new ArrayList&lt;CourseBase&gt;(List.of(courseBase)),20, 2, 10);} 5. @Schema描述模型的结构。可以用于类级别（标注在模型类上）或字段级别。 language-java1234567891011121314@Data@AllArgsConstructor@NoArgsConstructorpublic class PageParams { //当前页码 @Schema(description = &quot;页码&quot;) private Long pageNo = 1L; //每页记录数默认值 @Schema(description = &quot;每页条目数量&quot;) private Long pageSize =10L;} 6. @ApiResponse描述 API 响应的预期结果。可以指定状态码、描述以及返回类型。 language-java1234@ApiResponse(responseCode = &quot;200&quot;, description = &quot;Successfully retrieved user&quot;)public User getUserById(@PathVariable Long id) { }","link":"/Hexo/2024/01/23/2024-H1/2024-01-23-17-14-08/"},{"title":"SpringBoot3整合MyBatisPlus","text":"一、起因随着SpringBoot3的发布，mybatisplus也在不断更新以适配spirngboot3 。目前仍然处于维护升级阶段，最初2023.08时，官方宣布对SpringBoot3的原生支持，详情看这里。 但是对于较新版本的SpringBoot3，仍然有很多bug，甚至无法启动，摸爬滚打又游历社区后，实践后得到一套成功的版本搭配，具体如下 Version Java 17 Spring Boot 3.2.1 Spring Cloud 2023.0.0 Mybatis Plus 3.5.5 二、引入依赖language-xml12345&lt;dependency&gt; &lt;groupId&gt;com.baomidou&lt;/groupId&gt; &lt;artifactId&gt;mybatis-plus-spring-boot3-starter&lt;/artifactId&gt; &lt;version&gt;3.5.5&lt;/version&gt; &lt;/dependency&gt; 同时官方也提供了Demo项目，详情看这里，里面使用的版本搭配如下 Version Java 17 Spring Boot 3.2.0 Mybatis Plus 3.5.5-SNAPSHOT","link":"/Hexo/2024/01/23/2024-H1/2024-01-23-17-28-37/"},{"title":"SpringBoot自定义全局异常处理器","text":"一、介绍Springboot框架提供两个注解帮助我们十分方便实现全局异常处理器以及自定义异常。 @ControllerAdvice 或 @RestControllerAdvice（推荐） @ExceptionHandler 二、实现1. 定义全局异常处理器定义GlobalExceptionHandler类，拦截所有异常。@RestControllerAdvice注解使得你可以在GlobalExceptionHandler 中处理异常，@ExceptionHandle注解用于将指定异常绑定到处理的函数上。如下使用@ExceptionHandler(Exception.class)即对所有异常进行捕获处理。 language-java12345678910111213141516@RestControllerAdvice@Slf4jpublic class GlobalExceptionHandler { @ExceptionHandler(Exception.class) @ResponseStatus(HttpStatus.INTERNAL_SERVER_ERROR) public RestErrorResponse exception(Exception e){ //record log log.error(&quot;系统异常{}&quot;, e.getMessage(),e); //decode errorException String errMessage = &quot;系统异常&quot;; return new RestErrorResponse(errMessage); }} language-java123456@Data@AllArgsConstructorpublic class RestErrorResponse implements Serializable { private String errMessage;} 事实上，写到这里已经可以用了，RestErrorResponse 用来承载错误信息到前端，因为@RestControllerAdvice已经包含了@ResponseBody。 2. 自定义异常类继承RuntimeException 异常类写一个自定义的异常类。这么做主要是能够使用自定义的枚举类来更优雅的抛出错误。 language-java123456789101112131415161718192021222324252627@Datapublic class XueChengPlusException extends RuntimeException { private String errMessage; public XueChengPlusException() { super(); } public XueChengPlusException(String errMessage) { super(errMessage); this.errMessage = errMessage; } public static void cast(CommonError commonError){ throw new XueChengPlusException(commonError.getErrMessage()); } public static void cast(String errMessage){ throw new XueChengPlusException(errMessage); }} language-java1234567891011121314151617@Getterpublic enum CommonError { UNKOWN_ERROR(&quot;执行过程异常，请重试。&quot;), PARAMS_ERROR(&quot;非法参数&quot;), OBJECT_NULL(&quot;对象为空&quot;), QUERY_NULL(&quot;查询结果为空&quot;), REQUEST_NULL(&quot;请求参数为空&quot;); private String errMessage; private CommonError( String errMessage) { this.errMessage = errMessage; }} 同时，对于GlobalExceptionHandler 也要做一些修改，一方面处理自定义异常，另一方处理其余异常。 language-java123456789101112131415161718192021222324252627@RestControllerAdvice@Slf4jpublic class GlobalExceptionHandler { @ExceptionHandler(XueChengPlusException.class) @ResponseStatus(HttpStatus.INTERNAL_SERVER_ERROR) public RestErrorResponse customException(XueChengPlusException e){ //record log log.error(&quot;系统异常{}&quot;, e.getErrMessage(),e); //decode errorException String errMessage = e.getErrMessage(); return new RestErrorResponse(errMessage); } @ExceptionHandler(Exception.class) @ResponseStatus(HttpStatus.INTERNAL_SERVER_ERROR) public RestErrorResponse exception(Exception e){ //record log log.error(&quot;系统异常{}&quot;, e.getMessage(),e); //decode errorException String errMessage = CommonError.UNKOWN_ERROR.getErrMessage(); return new RestErrorResponse(errMessage); }} 三、使用在程序中任意地方抛出异常，controller、service、dao层都可以，比如 language-java1throw new RuntimeException(&quot;价格不能为空且必须大于0&quot;); 这时走的就是 language-java12@ExceptionHandler(Exception.class) public RestErrorResponse exception(Exception e) 除此之外，可以这样抛出自定义异常，比如 language-java1XueChengPlusException.cast(CommonError.PARAMS_ERROR); language-java1XueChengPlusException.cast(&quot;其他的消息&quot;); language-java1throw new XueChengPlusException(CommonError.OBJECT_NULL.getErrMessage()); language-java1throw new XueChengPlusException(&quot;其他的消息&quot;); 这时走的就是 language-java12@ExceptionHandler(XueChengPlusException.class) public RestErrorResponse customException(XueChengPlusException e) 四、疑问 Q：疑问，XueChengPlusException异常类继承自RuntimeException ，而RuntimeException 继承自Exception，为什么触发customException而不是exception？ 在这个全局异常处理器中，当抛出一个XueChengPlusException异常时，它会被customException(XueChengPlusException e)方法处理，而不是exception(Exception e)方法。 这是因为Spring框架的异常处理机制会优先匹配最具体的异常类型。在您的代码中，XueChengPlusException是RuntimeException（以及Exception）的子类，因此它更具体。所以，当抛出一个XueChengPlusException异常时，Spring会优先调用处理XueChengPlusException的方法，而不是处理Exception的方法。 这种行为确实表明全局异常处理器有一定的优先级和覆盖逻辑。具体来说，处理器会优先处理更具体的异常类型，如果没有找到匹配的处理器，那么它会寻找处理更一般异常类型的处理器。","link":"/Hexo/2024/01/26/2024-H1/2024-01-26-21-44-24/"},{"title":"SpringBoot注解@GetMapping处理Get请求","text":"一、如何从URL中获取参数当你想从URL中获取名为courseId的参数时，可以使用@GetMapping(&quot;/course/{courseId}&quot;)和@GetMapping(&quot;/course&quot;)两种办法，主要体现在URL模式和如何获取参数上。 使用@GetMapping(&quot;/course/{courseId}&quot;): 这种方式表示你正在定义一个REST风格的API，其中{courseId}是URL的一部分，通常被称为路径变量（path variable）。 你可以通过在方法的参数中加上@PathVariable注解来获取这个路径变量。例如： language-java12345@GetMapping(&quot;/course/{courseId}&quot;)public String getCourse(@PathVariable String courseId) { // 使用courseId} 这种方式适合于当courseId是必需的，并且每个课程的URL都是唯一的情况。 使用@GetMapping(&quot;/course&quot;): 这种方式下，URL不直接包含courseId。相反，courseId可以作为请求参数（query parameter）来传递。 你可以通过在方法的参数中加上@RequestParam注解来获取这个请求参数。例如： language-java12345@GetMapping(&quot;/course&quot;)public String getCourse(@RequestParam String courseId) { // 使用courseId} 这种方式适合于当你想要让courseId作为一个可选参数或者你希望从一组标准的URL中筛选特定课程的情况。 二、获取多个参数当URL中有多个参数时，@GetMapping(&quot;/course/{courseId}&quot;)和@GetMapping(&quot;/course&quot;)的使用方式和它们之间的区别仍然基于路径变量（Path Variable）和请求参数（Request Parameter）的概念。这两种方法可以根据参数的性质和用途灵活组合使用。 使用路径变量（Path Variables）: 当你使用@GetMapping(&quot;/course/{courseId}&quot;)并且URL中有多个参数时，这些参数通常是URL路径的一部分，并且每个参数都是资源定位的关键部分。 例如，如果你有一个URL像这样：/course/{courseId}/module/{moduleId}，你可以这样使用： language-java12345@GetMapping(&quot;/course/{courseId}/module/{moduleId}&quot;)public String getModule(@PathVariable String courseId, @PathVariable String moduleId) { // 使用courseId和moduleId} 在这个例子中，courseId和moduleId都是路径的一部分，用来定位特定的资源。 使用请求参数（Request Parameters）: 当你使用@GetMapping(&quot;/course&quot;)并且URL中有多个参数时，这些参数通常作为URL的查询字符串（query string）。 例如，URL可能是这样的：/course?courseId=123&amp;moduleId=456，你可以这样使用： language-java12345@GetMapping(&quot;/course&quot;)public String getCourse(@RequestParam String courseId, @RequestParam String moduleId) { // 使用courseId和moduleId} 在这个例子中，courseId和moduleId是作为查询字符串的一部分传递的，通常用于过滤、排序或其他非资源定位的操作。 三、用一个类接收多个参数对于URL中包含多个请求参数（如 /course?courseId=123&amp;moduleId=456），你可以使用一个Java类来接收所有这些参数。这种方法可以使代码更加整洁，尤其是当处理具有多个参数的复杂请求时。 这里是如何使用一个类来接收所有请求参数的示例： 定义一个类来表示请求参数 :首先，你需要定义一个类，其属性对应于URL中的请求参数。例如，对于参数courseId和moduleId，你可以定义如下类： language-java12345678910111213141516171819202122232425262728public class CourseQuery { private String courseId; private String moduleId; // 标准的getter和setter方法 public String getCourseId() { return courseId; } public void setCourseId(String courseId) { this.courseId = courseId; } public String getModuleId() { return moduleId; } public void setModuleId(String moduleId) { this.moduleId = moduleId; } // 可以添加构造函数、toString()等} 在控制器方法中使用这个类 :接下来，在你的控制器方法中，你可以将这个类作为参数，并使用@ModelAttribute注解（或者不使用任何注解，因为Spring MVC会自动将请求参数绑定到类的属性上）： language-java12345@GetMapping(&quot;/course&quot;)public String getCourse(@ModelAttribute CourseQuery query) { // 使用query.getCourseId()和query.getModuleId()} 或者，如果你不使用@ModelAttribute注解，Spring MVC默认也会按照相同的方式处理这个参数： language-java12345@GetMapping(&quot;/course&quot;)public String getCourse(CourseQuery query) { // 使用query.getCourseId()和query.getModuleId()} 使用这种方式，你可以轻松地处理包含许多参数的复杂请求，同时保持代码的清晰和可维护性。这也让你能够在需要时对参数进行验证，比如使用Spring的验证框架来确保传入的参数满足特定条件。 四、疑问 Q：定义一个类来表示请求参数时，不需要使用@RequestParam吗？还是说@RequestParam用于简单的类型获取单个参数，比如String？ 在定义一个类来表示请求参数时，通常不需要在类的属性上使用@RequestParam注解。当你使用一个类来接收请求参数，Spring MVC的数据绑定机制会自动将请求中的参数名称映射到类的属性上。这是基于类的属性名和请求参数名的匹配来完成的。 使用类接收参数: 当你有多个请求参数，并且想要将它们组织在一个类中时，你可以定义一个类，其属性与请求参数的名称相对应。 在控制器方法中，你可以使用这个类的实例作为参数，而无需为每个属性单独使用@RequestParam。Spring会自动处理参数到类属性的映射。 例如： language-java12345678910111213public class CourseQuery { private String courseId; private String moduleId; // getter和setter省略}@GetMapping(&quot;/course&quot;)public String getCourse(CourseQuery query) { // 使用query.getCourseId()和query.getModuleId()} 使用@RequestParam: @RequestParam通常用于获取单个请求参数，特别是当这个参数是一个简单类型（如String、int等）时。 当你只需要从请求中获取一个或少数几个参数，而不是一个复杂对象时，@RequestParam是一个很好的选择。 例如： language-java12345@GetMapping(&quot;/course&quot;)public String getCourse(@RequestParam String courseId, @RequestParam String moduleId) { // 直接使用courseId和moduleId} 总结来说，当处理包含多个参数的复杂请求时，使用一个类来封装这些参数可以使代码更加清晰和易于维护。而@RequestParam适用于处理更简单或直接的参数获取需求。在实际的应用中，你可以根据具体情况选择最适合的方法。 Q:假如我已经有一个在/course上的controller了，如下@PostMapping(&quot;/course&quot;) public CourseBaseInfoDto createCourseBase(@RequestBody AddCourseDto dto)我还能继续写@GetMapping(&quot;/course&quot;) public String getCourse(@RequestParam String courseId, @RequestParam String moduleId) 吗？ 是的，你完全可以在同一个控制器（Controller）中同时定义一个@PostMapping和一个@GetMapping方法，即使它们都映射到了相同的路径（如/course）。这是因为HTTP请求的方法类型（GET、POST等）作为映射的一部分，允许区分不同的操作。在你的例子中，一个方法用于处理POST请求，另一个用于处理GET请求。 @PostMapping(&quot;/course&quot;) 用于创建课程（通常是添加新资源），接收一个请求体（RequestBody）。 @GetMapping(&quot;/course&quot;) 用于获取课程信息（通常是读取资源），接收URL中的请求参数（RequestParam）。 你的控制器可能看起来像这样： language-java1234567891011121314151617@RestController@RequestMapping(&quot;/path-to-controller&quot;)public class CourseController { @PostMapping(&quot;/course&quot;) public CourseBaseInfoDto createCourseBase(@RequestBody AddCourseDto dto) { // 创建课程的逻辑 } @GetMapping(&quot;/course&quot;) public String getCourse(@RequestParam String courseId, @RequestParam String moduleId) { // 获取课程信息的逻辑 }} 在这种配置中，当一个POST请求发送到/course时，createCourseBase方法将被调用；而当一个GET请求发送到/course时，带有请求参数的getCourse方法将被调用。 这种方法是RESTful API设计中的常见实践，它允许你在同一路径上对资源进行不同类型的操作，同时保持了代码的清晰和逻辑的分离。","link":"/Hexo/2024/01/27/2024-H1/2024-01-27-11-38-56/"},{"title":"SpringBoot不同的@Mapping使用","text":"一、介绍一般@Mapping类注解在Spring框架中用于将HTTP请求映射到对应的处理器方法。它们各自对应于不同类型的HTTP方法，主要用于RESTful Web服务中。以下是每个注解的作用： @GetMapping: 用于映射HTTP GET请求到处理器方法。通常用于读取操作。 @PostMapping: 用于映射HTTP POST请求到处理器方法。通常用于创建操作。 @PutMapping: 用于映射HTTP PUT请求到处理器方法。通常用于更新操作，其中更新操作是幂等的，意味着多次执行同一个请求会得到相同的结果。 @DeleteMapping: 用于映射HTTP DELETE请求到处理器方法。通常用于删除操作。 @PatchMapping: 用于映射HTTP PATCH请求到处理器方法。PATCH与PUT类似，但通常用于部分更新资源。 @RequestMapping: 是一个通用的注解，可以用于映射任何HTTP方法，通过指定method属性来明确映射类型。如果不指定method，它将映射到所有HTTP方法。这是最早的注解，后来为了方便使用，根据HTTP方法细分出了上述的专用注解。 二、使用在Spring框架中，不同的@Mapping注解通常与不同的数据获取方式结合使用，以适应各种HTTP请求的特点： @GetMapping: 用于获取数据，通常与@RequestParam一起使用来接收查询参数。 示例: 获取URL中查询参数的值。 language-java12345@GetMapping(&quot;/users&quot;)public String getUsers(@RequestParam String name) { // ...} 也可以用@PathVariable来获取URL中的路径变量。 language-java12345@GetMapping(&quot;/users/{id}&quot;)public String getUserById(@PathVariable Long id) { // ...} @PostMapping: 用于创建数据，通常与@RequestBody结合使用来接收请求体中的内容，如JSON或XML。 示例: 从请求体中获取JSON对象。 language-java12345@PostMapping(&quot;/users&quot;)public String addUser(@RequestBody User user) { // ...} 有时也与@RequestParam结合使用来处理表单数据。 @PutMapping: 用于更新数据，通常与@RequestBody结合使用来接收请求体中的内容。 示例: 从请求体中获取JSON对象来更新数据。 language-java12345@PutMapping(&quot;/users/{id}&quot;)public String updateUser(@PathVariable Long id, @RequestBody User user) { // ...} @DeleteMapping: 用于删除数据，通常与@PathVariable结合使用来指定要删除的资源的ID。 示例: 删除指定ID的用户。 language-java12345@DeleteMapping(&quot;/users/{id}&quot;)public String deleteUser(@PathVariable Long id) { // ...} @PatchMapping: 用于部分更新资源，与@RequestBody结合使用来接收部分数据。 示例: 部分更新用户信息。 language-java12345@PatchMapping(&quot;/users/{id}&quot;)public String patchUser(@PathVariable Long id, @RequestBody Map&lt;String, Object&gt; updates) { // ...} @RequestMapping: 这是一个通用注解，可以用来处理任何HTTP方法，其具体方法由method属性指定。 数据获取方式取决于具体的HTTP方法。 每个注解的使用依赖于HTTP请求的语义，以及你如何打算处理请求数据。总体而言，@RequestParam和@PathVariable用于从URL获取数据，而@RequestBody用于处理复杂的请求体内容。","link":"/Hexo/2024/01/27/2024-H1/2024-01-27-16-06-04/"},{"title":"spring-boot-starter-validation常用注解","text":"一、使用要使用这些注解，首先确保在你的 Spring Boot 应用的 pom.xml 文件中添加了 spring-boot-starter-validation 依赖。然后，你可以将这些注解应用于你的模型类字段上。在你的控制器方法中，你可以使用 @Valid 或 @Validated 注解来触发验证，例如： language-java123456@PostMapping(&quot;/users&quot;)public ResponseEntity&lt;?&gt; createUser(@Valid @RequestBody User user) { // 如果存在验证错误，会抛出异常 // 正常业务逻辑} 在这个例子中，如果 User 对象的字段不满足注解定义的验证规则，Spring 将抛出一个异常，你可以通过全局异常处理或控制器层的异常处理来处理这些异常，并向用户返回适当的响应。 二、常用注解spring-boot-starter-validation 依赖包引入了 Java Bean Validation API（通常基于 Hibernate Validator 实现），提供了一系列注解来帮助你对 Java 对象进行验证。以下是一些常用的验证注解及其含义和使用方式： @NotNull : 确保字段不是 null。 language-java123456public class User { @NotNull(message = &quot;用户名不能为空&quot;) private String username; // 其他字段和方法} @NotEmpty : 确保字段既不是 null 也不是空（对于字符串意味着长度大于0，对于集合意味着至少包含一个元素）。 language-java123456public class User { @NotEmpty(message = &quot;密码不能为空&quot;) private String password; // 其他字段和方法} @NotBlank : 确保字符串字段不是 null 且至少包含一个非空白字符。 language-java123456public class User { @NotBlank(message = &quot;邮箱不能为空且不能只包含空格&quot;) private String email; // 其他字段和方法} @Size: 确保字段（字符串、集合、数组）符合指定的大小范围。 language-java123456public class User { @Size(min = 2, max = 30, message = &quot;用户名长度必须在2到30之间&quot;) private String username; // 其他字段和方法} @Min 和 @Max: 对数值类型字段设置最小值和最大值。 language-java1234567public class User { @Min(value = 18, message = &quot;年龄必须大于等于18&quot;) @Max(value = 100, message = &quot;年龄必须小于等于100&quot;) private int age; // 其他字段和方法} @Email: 确保字段是有效的电子邮件地址。 language-java123456public class User { @Email(message = &quot;无效的邮箱格式&quot;) private String email; // 其他字段和方法} @Pattern: 确保字符串字段匹配正则表达式。 language-java123456public class User { @Pattern(regexp = &quot;^[a-zA-Z0-9]+$&quot;, message = &quot;用户名只能包含字母和数字&quot;) private String username; // 其他字段和方法} @Positive 和 @PositiveOrZero: 确保数值字段是正数或者正数和零。 language-java123456public class Product { @Positive(message = &quot;价格必须是正数&quot;) private BigDecimal price; // 其他字段和方法} 三、@Valid or @Validated ？@Valid 和 @Validated 注解都用于数据验证，但它们在使用和功能上有一些差异： @Valid: 来源于 JSR 303/JSR 380 Bean Validation API。 可以用在方法参数上，以触发对传递给该方法的对象的验证。这通常在 Spring MVC 中用于验证带有 @RequestBody 或 @ModelAttribute 注解的参数。 不支持验证组的概念，这意味着不能控制验证的顺序或验证特定的子集。 示例： language-java12345@PostMapping(&quot;/users&quot;)public ResponseEntity&lt;?&gt; createUser(@Valid @RequestBody User user) { // 业务逻辑} @Validated(推荐): 是 Spring 的特有注解，不是 JSR 303/JSR 380 的一部分。 支持验证组，允许您更灵活地指定在特定情况下应用哪些验证约束。例如，可以根据不同的操作（如创建、更新）定义不同的验证规则。 可以用在类型级别（在类上）和方法参数上。在类型级别使用时，它会触发该类中所有带有验证注解的方法的验证。 示例： language-java12345@PostMapping(&quot;/users&quot;)public ResponseEntity&lt;?&gt; createUser(@Validated @RequestBody User user) { // 业务逻辑} 在实际使用中，如果你需要简单的验证功能，@Valid 是一个很好的选择。如果你需要更复杂的验证逻辑，比如验证组，那么 @Validated 更适合。此外，@Validated 可以应用在类级别，从而对一个类的多个方法进行验证，这在使用 Spring 服务层时非常有用。 四、分组校验分组校验（Group Validation）是一种在 Java Bean Validation 中用于在不同上下文中应用不同验证规则的方法。这对于那些在不同情况下（例如，创建 vs 更新）需要不同验证规则的对象特别有用。 1. 分组校验的基本概念在分组校验中，你可以定义多个接口（通常为空）来表示不同的验证组。然后，你可以在验证注解中指定这些接口，以表明该注解仅在验证特定组时应用。 例如，你可能有一个User类，其中某些字段在创建用户时是必需的，但在更新用户时可能是可选的。 2. 定义验证组首先，定义两个空接口作为验证组： language-java1234public interface OnCreate { }public interface OnUpdate { } 3. 应用分组到模型然后，在你的模型类中使用这些接口作为验证注解的参数： language-java12345678910111213141516public class User { @NotNull(groups = OnCreate.class) private Long id; @NotBlank(groups = { OnCreate.class, OnUpdate.class}) private String username; @Email(groups = { OnCreate.class, OnUpdate.class}) private String email; // 其他字段和方法} 在这个例子中，id 字段仅在创建用户时需要验证（OnCreate组），而 username 和 email 字段在创建和更新用户时都需要验证。 4. 在控制器中使用分组最后，在你的控制器方法中，使用 @Validated 注解指定要应用的验证组： language-java1234567891011@PostMapping(&quot;/users&quot;)public ResponseEntity&lt;?&gt; createUser(@Validated(OnCreate.class) @RequestBody User user) { // 创建用户的业务逻辑}@PutMapping(&quot;/users&quot;)public ResponseEntity&lt;?&gt; updateUser(@Validated(OnUpdate.class) @RequestBody User user) { // 更新用户的业务逻辑} 在这个例子中，createUser 方法只会验证属于 OnCreate 组的字段，而 updateUser 方法则只会验证属于 OnUpdate 组的字段。这样，你就可以根据不同的操作自定义验证逻辑了。 5. 默认组如何总是被校验当字段没有指定groups时，属于默认组，当@Validated(OnUpdate.class)指定了特定的组后，属于默认组的字段将不再被校验，一个个都加上groups太麻烦，如何让默认组字段总是被校验呢？如下 language-java12345import jakarta.validation.groups.Default;public interface OnCreate extends Default{ }public interface OnUpdate extends Default{ } 6. 总结通过使用分组校验，你可以为同一个对象的不同操作设置不同的验证规则，这在复杂应用中非常有用。这种方法提高了代码的灵活性和可维护性。","link":"/Hexo/2024/01/27/2024-H1/2024-01-27-16-26-19/"},{"title":"MybatisPlus二级映射和关联对象ResultMap","text":"在我们的教程中，我们设计了一个课程内容的数据结构，包含章节和相关资源。这种结构非常适合在线教育平台或电子学习系统，其中课程内容需要被组织成不同的章节和子章节，每个子章节可能关联特定的学习资源。 这将是一个很好的示例来展示 MyBatis 中如何使用一对多（&lt;collection&gt;）和一对一（&lt;association&gt;）映射。 一、业务背景1. 数据库表结构 章节表 (chapter)这张表包含所有章节的信息，其中包括大章节和小章节。大章节作为容器，可以包含多个小章节。 id (章节ID) parent_id (父章节ID，用于区分大章节和小章节) name (章节名称) courseId (课程ID) language-java1234567public class Chapter { private Long id; private Long parentId; private String name; private Long courseId;} 资源表 (resource)这张表包含与小章节相关联的资源信息。 id (资源ID) section_id (章节ID，关联到章节表) name (资源名称) language-java123456public class Resource { private Long id; private Long sectionId; private String name;} 2. 需求要求根据courseId查询出指定课程的信息，包括大章节、小章节、资源，并以一定结构返回，比如 language-json1234567891011121314151617181920212223242526272829303132333435[ { &quot;id&quot;: 1, &quot;parentId&quot;: null, &quot;name&quot;: &quot;Chapter 1&quot;, &quot;courseId&quot;: 100, &quot;subChapters&quot;: [ { &quot;id&quot;: 11, &quot;parentId&quot;: 1, &quot;name&quot;: &quot;Section 1.1&quot;, &quot;courseId&quot;: 100, &quot;resource&quot;: { &quot;id&quot;: 101, &quot;sectionId&quot;: 11, &quot;name&quot;: &quot;Introduction Video&quot; } }, { &quot;id&quot;: 12, &quot;parentId&quot;: 1, &quot;name&quot;: &quot;Section 1.2&quot;, &quot;courseId&quot;: 100, &quot;resource&quot;: null } ], &quot;resource&quot;: null } // other...] 所以我们定义一个Dto如下 language-java1234567public class ChapterDto extends Chapter { private List&lt;ChapterDto&gt; subChapters; private Resource resource; // 构造器、getter和setter} 二、使用映射直接得到指定结构在 ChapterMapper.xml 文件中，我们定义 SQL 查询以及结果映射。 language-xml123456789101112131415161718192021222324252627282930313233343536&lt;mapper namespace=&quot;com.example.mapper.ChapterMapper&quot;&gt; &lt;resultMap id=&quot;ChapterDtoMap&quot; type=&quot;com.example.dto.ChapterDto&quot;&gt; &lt;id column=&quot;chapter_id&quot; property=&quot;id&quot; /&gt; &lt;result column=&quot;parent_id&quot; property=&quot;parentId&quot; /&gt; &lt;result column=&quot;name&quot; property=&quot;name&quot; /&gt; &lt;result column=&quot;courseId&quot; property=&quot;courseId&quot; /&gt; &lt;collection property=&quot;subChapters&quot; ofType=&quot;com.example.dto.ChapterDto&quot;&gt; &lt;id column=&quot;sub_chapter_id&quot; property=&quot;id&quot; /&gt; &lt;result column=&quot;sub_parent_id&quot; property=&quot;parentId&quot; /&gt; &lt;result column=&quot;sub_name&quot; property=&quot;name&quot; /&gt; &lt;result column=&quot;sub_courseId&quot; property=&quot;courseId&quot; /&gt; &lt;association property=&quot;resource&quot; javaType=&quot;com.example.model.Resource&quot;&gt; &lt;id column=&quot;resource_id&quot; property=&quot;id&quot; /&gt; &lt;result column=&quot;section_id&quot; property=&quot;sectionId&quot; /&gt; &lt;result column=&quot;resource_name&quot; property=&quot;name&quot; /&gt; &lt;/association&gt; &lt;/collection&gt; &lt;/resultMap&gt; &lt;select id=&quot;selectChaptersWithResources&quot; resultMap=&quot;ChapterDtoMap&quot;&gt; SELECT c.id AS chapter_id, c.parent_id, c.name, c.courseId, sc.id AS sub_chapter_id, sc.parent_id AS sub_parent_id, sc.name AS sub_name, sc.courseId AS sub_courseId, r.id AS resource_id, r.section_id, r.name AS resource_name FROM chapter c LEFT JOIN chapter sc ON c.id = sc.parent_id LEFT JOIN resource r ON sc.id = r.section_id WHERE c.courseId = #{courseId} AND c.parent_id IS NULL &lt;/select&gt;&lt;/mapper&gt; 三、其他文件1. Mapperlanguage-java1234public interface ChapterMapper { List&lt;ChapterDto&gt; selectChaptersWithResources(Long courseId);} 2. Servicelanguage-java1234567891011@Servicepublic class ChapterService { @Autowired private ChapterMapper chapterMapper; public List&lt;ChapterDto&gt; getChaptersWithResources(Long courseId) { return chapterMapper.selectChaptersWithResources(courseId); }} 3. Controllerlanguage-java1234567891011121314@RestController@RequestMapping(&quot;/chapters&quot;)public class ChapterController { @Autowired private ChapterService chapterService; @GetMapping(&quot;/{courseId}&quot;) public ResponseEntity&lt;List&lt;ChapterDto&gt;&gt; getChapters(@PathVariable Long courseId) { List&lt;ChapterDto&gt; chapters = chapterService.getChaptersWithResources(courseId); return ResponseEntity.ok(chapters); }} 四、概念理解一级映射在提供的 resultMap 中，一级映射是针对 ChapterDto类的直接属性的映射。这意味着数据库中的列（如 chapter_id, parent_id等）直接映射到 ChapterDto类的相应属性（如 id, parent_id等），这部分映射是非常直接的。 二级映射二级映射用于处理复杂的对象关系，比如当一个对象包含其他对象或对象的集合时。这通常在处理一对多关系时出现，例如，一个章节结构（ChapterDto）可能包含多个子章节。 聚合这种聚合是根据您在 &lt;collection&gt; 标签中定义的规则进行的。MyBatis 会识别哪些行应该被映射为独立的实例，哪些行应该作为子元素聚合到其他实例中。 五、标签使用1. 标签用途：用于映射一对多关系。在这个例子中，ChapterDto类包含一个 Chapter 类型的列表，这代表了大章节和小章节之间的一对多关系。 常用属性： property：指定要映射到的目标属性名称。 ofType：指定集合中元素的类型。 2. 标签用途：用于映射一对一关系。在您的例子中，ChapterDto包含一个 Resource 类型的属性，这代表了小章节和资源之间的一对一关系。常用属性： property：指定要映射到的目标属性名称。 javaType：指定关联对象的类型。","link":"/Hexo/2024/01/27/2024-H1/2024-01-27-22-43-32/"},{"title":"SpringCloud + Nacos配置文件加载顺序和优先级详解","text":"在微服务架构中，合理地管理和理解配置文件的加载顺序与优先级对于确保应用的稳定性和灵活性至关重要。特别是在使用 Spring Cloud Alibaba Nacos 作为配置中心的场景下，这一点显得尤为重要。本文将基于一个具体的 bootstrap.yml 配置示例，深入探讨这些概念，并介绍如何通过 Nacos 配置实现本地配置的优先级设置。 一、加载顺序与优先级1. 示例配置首先，我们看一下示例的 bootstrap.yml 配置： language-yaml123456789101112131415161718192021222324252627282930spring: application: name: content-api cloud: nacos: server-addr: 192.168.101.65:8848 discovery: namespace: dev group: xuecheng-plus-project config: namespace: dev group: xuecheng-plus-project file-extension: yaml refresh-enabled: true extension-configs: - data-id: content-service-${ spring.profiles.active}.yaml group: xuecheng-plus-project refresh: true shared-configs: - data-id: swagger-${ spring.profiles.active}.yaml group: xuecheng-plus-common refresh: true - data-id: logging-${ spring.profiles.active}.yaml group: xuecheng-plus-common refresh: true profiles: active: dev 2. 配置文件分类在 Spring Cloud Alibaba Nacos 环境中，我们主要遇到以下类型的配置文件： 本地配置文件： bootstrap.yml / bootstrap.yaml application.yml / application.yaml Nacos 配置中心的配置文件： 共享配置文件 (shared-configs) 扩展配置文件 (extension-configs) 项目应用名配置文件 (${spring.application.name}.yaml / .properties) 3. 加载顺序 **bootstrap.yml / bootstrap.yaml**：首先加载，用于配置应用的启动环境。 Nacos 配置中心的配置文件 ： 先加载 共享配置文件 (shared-configs) 然后是 扩展配置文件 (extension-configs) 最后是 项目应用名配置文件 (${spring.application.name}.yaml / .properties) **application.yml / application.yaml**：在 Nacos 配置加载之后。 4. 优先级 项目应用名配置文件：具有最高优先级。 扩展配置文件：次之，覆盖共享配置。 共享配置文件：优先级低于扩展配置。 **本地 application.yml / application.yaml**：优先级低于所有从 Nacos 加载的配置。 **本地 bootstrap.yml / bootstrap.yaml**：优先级最低。 二、本地配置优先的设置在 Nacos 中，可以通过特定的配置来设置本地配置优先。这可以在 bootstrap.yml 或 application.yml 文件中设置： language-yaml1234spring: cloud: config: override-none: true 当 override-none 设置为 true 时，本地配置文件 (application.yml / application.yaml) 将具有最高的优先级，即使这些配置在 Nacos 中也有定义。这种设置适用于需要在不同环境中覆盖远程配置中心配置的场景。 结论了解和正确应用 Spring Cloud Alibaba Nacos 中配置文件的加载顺序和优先级，对于确保微服务的正确运行至关重要。此外，通过配置 override-none 为 true，可以灵活地实现本地配置优先的需求，进一步增强了配置管理的灵活性。这些特性使得 Spring Cloud Alibaba Nacos 成为管理微服务配置的强大工具。","link":"/Hexo/2024/01/31/2024-H1/2024-01-31-10-39-02/"},{"title":"SpringCloud Gateway(4.1.0) 返回503：原因分析与解决方案","text":"一、环境版本 Version spring-cloud-dependencies 2023.0.0 spring-cloud-starter-gateway 4.1.0 Nacos v2.3.0 二、原因分析在 Spring Cloud Gateway 的早期版本中，Ribbon 被用作默认的负载均衡器。随着Spring Cloud的发展，Ribbon 被 Spring Cloud LoadBalancer 替代。在过渡期间，为了兼容，Spring Cloud 同时支持了 Ribbon 和 Spring Cloud LoadBalancer。然而，从 Spring Cloud 2020.0.0 版本开始，Ribbon 被废弃，Spring Cloud LoadBalancer 成为了推荐的负载均衡方案。 在这个版本变动中，为了提供更大的灵活性，spring-cloud-starter-loadbalancer 被标记为了可选依赖，不再默认包含在 Spring Cloud Gateway 中。因此，在使用 4.1.0 版本的 Spring Cloud Gateway 并需要服务发现和负载均衡功能时，如果没有显式包含这个依赖，就会导致无法处理 lb://URI，从而返回503错误。 三、解决方案要解决这个问题，您需要在您的项目的 POM 文件中显式添加 spring-cloud-starter-loadbalancer 依赖： language-xml12345&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-loadbalancer&lt;/artifactId&gt; &lt;version&gt;4.1.0&lt;/version&gt;&lt;/dependency&gt; 添加后，确保重启应用程序以使配置生效。这样，Spring Cloud Gateway 就能够正确处理基于服务发现的负载均衡，从而避免503错误。 通过理解 Spring Cloud 的历史演变和适应其依赖管理的变化，我们可以更好地维护和优化我们的微服务架构。","link":"/Hexo/2024/01/31/2024-H1/2024-01-31-13-21-00/"},{"title":"Docker多节点部署Minio分布式文件系统并测试","text":"一、前提准备准备如下文件夹和文件 language-txt123456789101112131415161718./├── docker-compose-minio.yml├── .env├── env│ ├── minio.env├── minio│ ├── minio1│ │ ├── data1│ │ └── data2│ ├── minio2│ │ ├── data1│ │ └── data2│ ├── minio3│ │ ├── data1│ │ └── data2│ └── minio4│ ├── data1│ └── data2 二、文件配置1. .envlanguage-env1MINIO_VERSION=RELEASE.2024-01-29T03-56-32Z 2. env/minio.envlanguage-env12MINIO_ROOT_USER=minioMINIO_ROOT_PASSWORD=minio123 3. docker-compose-minio.ymllanguage-yml123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384version: &quot;3.8&quot;networks: docker_xuecheng: ipam: config: - subnet: 172.20.0.0/16services: minio1: container_name: minio1 image: minio/minio:${ MINIO_VERSION} volumes: - ./minio/minio1/data1:/data1 - ./minio/minio1/data2:/data2 ports: - &quot;9001:9000&quot; - &quot;9011:9001&quot; env_file: - ./env/minio.env command: server --address &quot;:9000&quot; --console-address &quot;:9001&quot; http://172.20.2.{ 1...4}/data{ 1...2} networks: docker_xuecheng: ipv4_address: 172.20.2.1 minio2: container_name: minio2 image: minio/minio:${ MINIO_VERSION} volumes: - ./minio/minio2/data1:/data1 - ./minio/minio2/data2:/data2 ports: - &quot;9002:9000&quot; - &quot;9012:9001&quot; env_file: - ./env/minio.env command: server --address &quot;:9000&quot; --console-address &quot;:9001&quot; http://172.20.2.{ 1...4}/data{ 1...2} networks: docker_xuecheng: ipv4_address: 172.20.2.2 minio3: container_name: minio3 image: minio/minio:${ MINIO_VERSION} volumes: - ./minio/minio3/data1:/data1 - ./minio/minio3/data2:/data2 ports: - &quot;9003:9000&quot; - &quot;9013:9001&quot; env_file: - ./env/minio.env command: server --address &quot;:9000&quot; --console-address &quot;:9001&quot; http://172.20.2.{ 1...4}/data{ 1...2} networks: docker_xuecheng: ipv4_address: 172.20.2.3 minio4: container_name: minio4 image: minio/minio:${ MINIO_VERSION} volumes: - ./minio/minio4/data1:/data1 - ./minio/minio4/data2:/data2 ports: - &quot;9004:9000&quot; - &quot;9014:9001&quot; env_file: - ./env/minio.env command: server --address &quot;:9000&quot; --console-address &quot;:9001&quot; http://172.20.2.{ 1...4}/data{ 1...2} networks: docker_xuecheng: ipv4_address: 172.20.2.4 三、测试访问宿主机ip:9011，输入账号密码。 language-txt12MINIO_ROOT_USER=minioMINIO_ROOT_PASSWORD=minio123 点到Monitoring -&gt; Metrics 四、Java测试1. 引入依赖language-xml123456789&lt;dependency&gt; &lt;groupId&gt;io.minio&lt;/groupId&gt; &lt;artifactId&gt;minio&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-test&lt;/artifactId&gt; &lt;scope&gt;test&lt;/scope&gt;&lt;/dependency&gt; 2. 增删改在这之前先去网页端，创建一个Bucket language-java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657package com.xuecheng.media;import io.minio.*;import io.minio.errors.*;import org.apache.commons.codec.digest.DigestUtils;import org.apache.commons.compress.utils.IOUtils;import org.junit.jupiter.api.Test;import java.io.*;import java.security.InvalidKeyException;import java.security.NoSuchAlgorithmException;public class MinioTest { private MinioClient minioClient = MinioClient.builder() .endpoint(&quot;http://192.168.101.65:9001&quot;) //改成你的宿主机ip .credentials(&quot;minio&quot;, &quot;minio123&quot;) .build(); @Test public void testCreate() throws IOException, ServerException, InsufficientDataException, ErrorResponseException, NoSuchAlgorithmException, InvalidKeyException, InvalidResponseException, XmlParserException, InternalException { ObjectWriteResponse file = minioClient.uploadObject( UploadObjectArgs.builder() .bucket(&quot;test&quot;) .filename(&quot;C:\\\\Users\\\\mumu\\\\Desktop\\\\1C6091EF9671978A9F1B6C6F8A3666FD.png&quot;) .object(&quot;1.png&quot;) .build() ); } @Test public void testDelete() throws ServerException, InsufficientDataException, ErrorResponseException, IOException, NoSuchAlgorithmException, InvalidKeyException, InvalidResponseException, XmlParserException, InternalException { minioClient.removeObject( RemoveObjectArgs.builder() .bucket(&quot;test&quot;) .object(&quot;12.msi&quot;) .build() ); } @Test public void testGet() throws ServerException, InsufficientDataException, ErrorResponseException, IOException, NoSuchAlgorithmException, InvalidKeyException, InvalidResponseException, XmlParserException, InternalException { InputStream inputStream = minioClient.getObject( GetObjectArgs.builder() .bucket(&quot;test&quot;) .object(&quot;1.png&quot;) .build() ); FileOutputStream outputStream = new FileOutputStream(new File(&quot;C:\\\\Users\\\\mumu\\\\Desktop\\\\2.png&quot;)); IOUtils.copy(inputStream, outputStream); }}","link":"/Hexo/2024/01/31/2024-H1/2024-01-31-20-11-55/"},{"title":"AutoHotKey(V2)控制Windows扩展屏视频并开机自启","text":"起因是因为买了一块扩展屏幕，经常用来播放教学视频，而主屏幕用于实战操作，但是每次对视频进行控制时都要把鼠标移动过去，点击，再回来找到原来的代码位置，很难受。所以用AutoHotKey写了一个快捷键脚本。 一、参考资料官方AutoHotKey V2 Docs Windows设置开机自启 二、脚本功能介绍language-python1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556CoordMode &quot;Mouse&quot;, &quot;Screen&quot; ; 将鼠标坐标模式设置为整个屏幕SendMode &quot;Event&quot; ; 设置发送模式为事件模式ExtendBilibili(key, count){ xpos := 0 ypos := 0 originalWinHwnd := WinExist(&quot;A&quot;) ; 获取当前活动窗口的HWND MouseGetPos &amp;xpos, &amp;ypos ; MsgBox Format(&quot;1- {1} {2}&quot;, xpos, ypos) MouseMove 2300, 1050, 0 ; 移动到视频范围 MouseClick &quot;left&quot;, , , , 5 ; 点击一处无关紧要的地方，使视频应用聚焦 Loop count ; 根据提供的次数重复发送键 { Send key } ; MsgBox Format(&quot;2- {1} {2}&quot;, xpos, ypos) Sleep 50 MouseMove xpos, ypos, 0 ; 鼠标移回原处 WinActivate(&quot;ahk_id &quot; . originalWinHwnd) ; 激活原始窗口}#!Space:: ; Win + Alt + Space{ ExtendBilibili(&quot;{Space}&quot;, 1)}#!Left:: ; Win + Alt + Left{ ExtendBilibili(&quot;{Left}&quot;, 3)}#!Right:: ; Win + Alt + Right{ ExtendBilibili(&quot;{Right}&quot;, 2)}#!Up:: ; Win + Alt + Up{ xpos := 0 ypos := 0 originalWinHwnd := WinExist(&quot;A&quot;) ; 获取当前活动窗口的HWND MouseGetPos &amp;xpos, &amp;ypos MouseMove 2300, 1050, 1 MouseClick &quot;left&quot;, , , , 0 Sleep 2000 MouseMove xpos, ypos, 0 WinActivate(&quot;ahk_id &quot; . originalWinHwnd) ; 激活原始窗口}","link":"/Hexo/2024/01/31/2024-H1/2024-01-31-21-06-14/"},{"title":"SpringBoot使用当前类代理类(内部事务)解决方案","text":"在 Spring Boot 开发中，我们时常遇到需要在一个类的内部调用自己的其他方法，并且这些方法可能需要事务支持。这种场景通常发生在业务逻辑较为复杂的服务类中，其中一些操作需要确保数据的一致性和完整性。本文将以 MediaFileServiceImpl 类为例，探讨如何在 Spring Boot 中有效地使用当前类的代理类来处理内部事务。 一、场景描述考虑一个典型的例子：在 MediaFileServiceImpl 服务类中，upload 方法需要调用 upload2Mysql 方法。这里，upload2Mysql 方法是事务性的，意味着它涉及到数据库操作，这些操作需要在一个事务中被处理。如果直接在 upload 方法中调用 upload2Mysql，由于 Spring 的代理方式，事务管理可能不会被正确应用，因为实际上是在同一个实例内部进行方法调用，绕过了 Spring 的代理。 language-java123456789101112131415161718192021222324@Service@Slf4jpublic class MediaFileServiceImpl implements MediaFileService { @Lazy @Autowired private MediaFileService mediaFileService; @Override public UploadFileResultDto upload() { // ... 一些业务逻辑 ... mediaFileService.upload2Mysql(); // ... 其他业务逻辑 ... } @Transactional @Override public MediaFiles upload2Mysql() { // ... 事务性操作 ... }} 二、解决方案1. 使用 @Lazy（推荐）在 MediaFileServiceImpl 类中使用 @Lazy 注解解决循环依赖问题。 language-java123456789101112131415161718192021222324@Service@Slf4jpublic class MediaFileServiceImpl implements MediaFileService { @Lazy @Autowired private MediaFileService mediaFileService; @Override public UploadFileResultDto upload() { // ... 一些业务逻辑 ... mediaFileService.upload2Mysql(); // ... 其他业务逻辑 ... } @Transactional @Override public MediaFiles upload2Mysql() { // ... 事务性操作 ... }} 2. 使用方法注入方法注入是一种允许在运行时动态注入方法实现的技术。这里，我们通过一个简单的例子来说明如何应用方法注入。 language-java1234567891011121314151617181920212223@Service@Slf4jpublic abstract class MediaFileServiceImpl implements MediaFileService { @Override public UploadFileResultDto upload() { // ... 一些业务逻辑 ... getMediaFileService().upload2Mysql(); // ... 其他业务逻辑 ... } @Transactional @Override public MediaFiles upload2Mysql() { // ... 事务性操作 ... } @Lookup protected abstract MediaFileService getMediaFileService();} 3. 使用 ApplicationContext这种方法通过 ApplicationContext 获取当前类的代理。 language-java12345678910111213141516171819202122232425262728@Service@Slf4jpublic class MediaFileServiceImpl implements MediaFileService { @Autowired private ApplicationContext context; private MediaFileService getMediaFileService() { return context.getBean(MediaFileService.class); } @Override public UploadFileResultDto upload() { // ... 一些业务逻辑 ... getMediaFileService().upload2Mysql(); // ... 其他业务逻辑 ... } @Transactional @Override public MediaFiles upload2Mysql() { // ... 事务性操作 ... }} 4. 分离服务层将事务性方法移至另一个服务类中。 language-java123456789101112131415161718192021222324252627@Service@Slf4jpublic class MediaFileServiceImpl implements MediaFileService { @Autowired private MediaFileTransactionalService transactionalService; @Override public UploadFileResultDto upload() { // ... 一些业务逻辑 ... transactionalService.upload2Mysql(); // ... 其他业务逻辑 ... }}@Service@Transactionalclass MediaFileTransactionalService { public MediaFiles upload2Mysql() { // ... 事务性操作 ... }} 5. AspectJ 代理模式使用 AspectJ 代理模式而不是默认的 JDK 动态代理。 language-java123456@EnableAspectJAutoProxy(proxyTargetClass = true)@Configurationpublic class AppConfig { // ... 其他配置 ...} 然后，您的 MediaFileServiceImpl 类保持不变。","link":"/Hexo/2024/02/01/2024-H1/2024-02-01-11-15-35/"},{"title":"Docker部署xxl-job调度器并结合SpringBoot测试","text":"一、Docker部署1. 创建数据库去Github下载最新发布的源码，https://github.com/xuxueli/xxl-job/releases，找到/xxl-job/doc/db/tables_xxl_job.sql文件，对数据库进行执行即可，脚本里面包含数据库的创建。 2. 启动容器参考官方中文文档，写出如下docker-compose示例。使用-e PARAMS: &quot;&quot;来指定一些变量，包括数据库信息，一般需要根据自身情况修改。 language-yml1234567891011121314151617181920212223version: &quot;3.8&quot;networks: docker_xuecheng: ipam: config: - subnet: 172.20.0.0/16services: xxl-job: container_name: xxl-job image: xuxueli/xxl-job-admin:2.4.0 volumes: - ./xxl_job/logs:/data/applogs ports: - &quot;8088:8080&quot; environment: PARAMS: ' --spring.datasource.url=jdbc:mysql://172.20.0.2:3306/xxl_job?useUnicode=true&amp;characterEncoding=UTF-8&amp;autoReconnect=true&amp;serverTimezone=Asia/Shanghai --spring.datasource.username=root --spring.datasource.password=1009' networks: docker_xuecheng: ipv4_address: 172.20.3.1 3. 访问访问http://192.168.101.65:8088/xxl-job-admin/即可。 4. 新建执行器新增一个简单的testHandler执行器。 二、SpringBoot整合1. 模块注册到执行器在对应模块引入依赖 language-xml1234&lt;dependency&gt; &lt;groupId&gt;com.xuxueli&lt;/groupId&gt; &lt;artifactId&gt;xxl-job-core&lt;/artifactId&gt;&lt;/dependency&gt; 并指定执行器的appname language-yml123456789101112xxl: job: admin: addresses: http://192.168.101.65:8088/xxl-job-admin executor: appname: testHandler address: ip: port: 9999 logpath: /data/applogs/xxl-job/jobhandler logretentiondays: 30 accessToken: default_token 2. 创建配置类在源码中找到src/main/java/com/xxl/job/executor/core/config/XxlJobConfig.java，复制到模块代码中。如下 language-java1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980package com.xuecheng.media.config;import com.xxl.job.core.executor.impl.XxlJobSpringExecutor;import org.slf4j.Logger;import org.slf4j.LoggerFactory;import org.springframework.beans.factory.annotation.Value;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;/** * xxl-job config * * @author xuxueli 2017-04-28 */@Configurationpublic class XxlJobConfig { private Logger logger = LoggerFactory.getLogger(XxlJobConfig.class); @Value(&quot;${xxl.job.admin.addresses}&quot;) private String adminAddresses; @Value(&quot;${xxl.job.accessToken}&quot;) private String accessToken; @Value(&quot;${xxl.job.executor.appname}&quot;) private String appname; @Value(&quot;${xxl.job.executor.address}&quot;) private String address; @Value(&quot;${xxl.job.executor.ip}&quot;) private String ip; @Value(&quot;${xxl.job.executor.port}&quot;) private int port; @Value(&quot;${xxl.job.executor.logpath}&quot;) private String logPath; @Value(&quot;${xxl.job.executor.logretentiondays}&quot;) private int logRetentionDays; @Bean public XxlJobSpringExecutor xxlJobExecutor() { logger.info(&quot;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt;&gt; xxl-job config init.&quot;); XxlJobSpringExecutor xxlJobSpringExecutor = new XxlJobSpringExecutor(); xxlJobSpringExecutor.setAdminAddresses(adminAddresses); xxlJobSpringExecutor.setAppname(appname); xxlJobSpringExecutor.setAddress(address); xxlJobSpringExecutor.setIp(ip); xxlJobSpringExecutor.setPort(port); xxlJobSpringExecutor.setAccessToken(accessToken); xxlJobSpringExecutor.setLogPath(logPath); xxlJobSpringExecutor.setLogRetentionDays(logRetentionDays); return xxlJobSpringExecutor; } /** * 针对多网卡、容器内部署等情况，可借助 &quot;spring-cloud-commons&quot; 提供的 &quot;InetUtils&quot; 组件灵活定制注册IP； * * 1、引入依赖： * &lt;dependency&gt; * &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; * &lt;artifactId&gt;spring-cloud-commons&lt;/artifactId&gt; * &lt;version&gt;${version}&lt;/version&gt; * &lt;/dependency&gt; * * 2、配置文件，或者容器启动变量 * spring.cloud.inetutils.preferred-networks: 'xxx.xxx.xxx.' * * 3、获取IP * String ip_ = inetUtils.findFirstNonLoopbackHostInfo().getIpAddress(); */} 3. 启动测试重启模块，访问XXL-JOB网页端，查看情况。如果执行器的OnLine 机器地址有一个信息，表示模块绑定成功。 三、任务发布-普通任务1. 编写任务代码源代码中有任务代码示例，路径为src/main/java/com/xxl/job/executor/service/jobhandler/SampleXxlJob.java，仿照写一个简单的任务，如下。 language-java123456789101112@Componentpublic class SampleXxlJob { /** * 1、简单任务示例（Bean模式） */ @XxlJob(&quot;demoJobHandler&quot;) public void demoJobHandler() throws Exception { System.out.println(&quot;处理视频&quot;); }} 2. 创建任务选择执行器，并指定JobHandler。 3. 启动任务启动刚才创建的任务 对应模块的日志可以看到每10秒打印一次输出。 在XXL-JOB网页管理也可以看到相关任务执行记录。 四、任务发布-分片任务1. 编写任务代码language-java12345678910@XxlJob(&quot;shardingJobHandler&quot;)public void shardingJobHandler() throws Exception { // 分片参数 int shardIndex = XxlJobHelper.getShardIndex(); int shardTotal = XxlJobHelper.getShardTotal(); System.out.println(&quot;分片参数：当前分片序号 = &quot; + shardIndex + &quot;, 总分片数 = &quot; + shardTotal);} 2. 启动多个实例添加虚拟机参数-Dserver.port=63051 -Dxxl.job.executor.port=9998，前者区分程序端口，后者区分执行器端口。 3. 创建任务创建任务之前，检查一下两个模块是否注册到指定执行器。 随后创建任务，指定执行器、JobHandler，同时路由策略选择分片广播。 4. 启动任务启动任务后，观察两个模块的日志。 同时任务记录也在XXL-JOB管理网页中可以查询到。 五、动态扩容当运行分片任务时，又添加一个新的模块示例，此时分片任务会自动扩容再分配。如图，我们再复制一个运行配置。 然后将其运行，等待一会，执行器可以看到有3个绑定的机器。 新增的运行实例日志如下， 同时，先前两个运行实例的日志发送了变化，如下 参考资料 《分布式任务调度平台XXL-JOB》中文文档","link":"/Hexo/2024/02/02/2024-H1/2024-02-02-14-25-49/"},{"title":"SpringCloud + Nacos环境下抽取Feign独立模块并支持MultipartFile","text":"一、前提条件和背景1. 前提已经部署好Nacos，本文以192.168.101.65:8848为例。 2. 背景有两个微服务media和content，都已经注册到Nacos。后者通过引用Feign实现远程调用前者。两个微服务都被分为3个子模块：api、service、model，对应三层架构。 请根据自身情况出发阅读本文。 二、Feign模块1. 依赖引入首先需要Feign依赖和扩展。 language-xml12345678910111213141516171819202122232425&lt;!-- openfeign --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-openfeign&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.cloud&lt;/groupId&gt; &lt;artifactId&gt;spring-cloud-starter-loadbalancer&lt;/artifactId&gt; &lt;version&gt;4.1.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.github.openfeign&lt;/groupId&gt; &lt;artifactId&gt;feign-httpclient&lt;/artifactId&gt;&lt;/dependency&gt;&lt;!--feign支持Multipart格式传参--&gt;&lt;dependency&gt; &lt;groupId&gt;io.github.openfeign.form&lt;/groupId&gt; &lt;artifactId&gt;feign-form&lt;/artifactId&gt; &lt;version&gt;3.8.0&lt;/version&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;io.github.openfeign.form&lt;/groupId&gt; &lt;artifactId&gt;feign-form-spring&lt;/artifactId&gt; &lt;version&gt;3.8.0&lt;/version&gt;&lt;/dependency&gt; 需要测试依赖（可选），为了MockMultipartFile类才引入的，非必需功能。 language-xml1234567&lt;!-- 测试 --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework&lt;/groupId&gt; &lt;artifactId&gt;spring-test&lt;/artifactId&gt; &lt;version&gt;6.1.2&lt;/version&gt; &lt;scope&gt;compile&lt;/scope&gt;&lt;/dependency&gt; 其次需要涉及到的微服务的数据模型，根据个人情况而定。 如果只想要它们的数据模型，而不引入不必要的依赖，可以使用通配符*全部过滤掉。 language-xml1234567891011121314151617181920212223&lt;!-- 数据模型pojo --&gt;&lt;dependency&gt; &lt;groupId&gt;com.xuecheng&lt;/groupId&gt; &lt;artifactId&gt;xuecheng-plus-media-model&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;*&lt;/groupId&gt; &lt;artifactId&gt;*&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;com.xuecheng&lt;/groupId&gt; &lt;artifactId&gt;xuecheng-plus-content-model&lt;/artifactId&gt; &lt;version&gt;0.0.1-SNAPSHOT&lt;/version&gt; &lt;exclusions&gt; &lt;exclusion&gt; &lt;groupId&gt;*&lt;/groupId&gt; &lt;artifactId&gt;*&lt;/artifactId&gt; &lt;/exclusion&gt; &lt;/exclusions&gt;&lt;/dependency&gt; 2. application.yaml配置填入以下内容，大抵为超时熔断处理。（可选），甚至可以留空。 language-yml1234567891011121314151617feign: hystrix: enabled: true circuitbreaker: enabled: truehystrix: command: default: execution: isolation: thread: timeoutInMilliseconds: 30000ribbon: ConnectTimeout: 60000 ReadTimeout: 60000 MaxAutoRetries: 0 MaxAutoRetriesNextServer: 1 3. 扩展支持MultipartFile新建一个配置类，如下，主要是Encoder feignEncoder()使得Feign支持MultipartFile类型传输。MultipartFile getMultipartFile(File file)是一个工具方法，和配置无关。 language-java1234567891011121314151617181920212223242526272829303132@Configurationpublic class MultipartSupportConfig { @Autowired private ObjectFactory&lt;HttpMessageConverters&gt; messageConverters; @Bean @Primary//注入相同类型的bean时优先使用 @Scope(&quot;prototype&quot;) public Encoder feignEncoder() { return new SpringFormEncoder(new SpringEncoder(messageConverters)); } //将file转为Multipart public static MultipartFile getMultipartFile(File file) { try { byte[] content = Files.readAllBytes(file.toPath()); MultipartFile multipartFile = new MockMultipartFile(file.getName(), file.getName(), Files.probeContentType(file.toPath()), content); return multipartFile; } catch (IOException e) { e.printStackTrace(); XueChengPlusException.cast(&quot;File-&gt;MultipartFile转化失败&quot;); return null; } }} 4. 将media-api注册到feign新建一个类，如下。@FeignClient(value)要和服务名称对上，即media模块spring.application.name=media-api。@FeignClient(path)要和服务前缀路径对上，即media模块server.servlet.context-path=/media。然后MediaClient中的方法定义尽量和media模块对应的controller函数保持一致。 language-java1234567891011@FeignClient(value = &quot;media-api&quot;, path = &quot;/media&quot;)public interface MediaClient { @RequestMapping(value = &quot;/upload/coursefile&quot;, consumes = MediaType.MULTIPART_FORM_DATA_VALUE) public UploadFileResultDto upload( @RequestPart(&quot;filedata&quot;) MultipartFile file, @RequestParam(value = &quot;objectName&quot;, required = false) String objectName );} 三、Media模块被调用方media模块无需做什么修改。 四、Content模块测试在content-api上操作。 1. 引入依赖content模块需要引入刚才feign模块的依赖。 language-xml123&lt;dependency&gt; &lt;!-- 根据自身情况引入 --&gt;&lt;/dependency&gt; 2. 启用FeignClient在启动类上加上@EnableFeignClients注解。 3. 测试新建测试类，如下 language-java1234567891011121314151617181920212223242526272829package com.xuecheng.content.service.jobhandler;import com.xuecheng.feign.client.MediaClient;import com.xuecheng.media.model.dto.UploadFileResultDto;import org.junit.jupiter.api.Test;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.boot.test.context.SpringBootTest;import org.springframework.mock.web.MockMultipartFile;import org.springframework.web.multipart.MultipartFile;@SpringBootTestclass CoursePublishTaskTest { @Autowired MediaClient mediaClient; @Test void generateCourseHtml() { MultipartFile file = new MockMultipartFile( &quot;filedata&quot;, &quot;filename.txt&quot;, &quot;text/plain&quot;, &quot;Some dataset...&quot;.getBytes() ); UploadFileResultDto upload = mediaClient.upload(file, &quot;/static-test/t-1&quot;); System.out.println(upload); }} 启动Media模块，启动测试方法，具体的Debug和检验，可以通过Media模块对应的controller函数打印日志，检查是否通过MediaClient 被触发。 五、需要澄清的几点 Feign模块不需要注册到Nacos且不需要服务发现 ：正确。feign-client模块只是一个包含Feign客户端接口的库，它自身并不是一个独立的微服务。因此，它不需要注册到Nacos，也不需要服务发现功能。这个模块只是被其他微服务模块（如content模块）作为依赖引入。这样做的主要目的是为了代码的重用和解耦，允许任何微服务通过引入这个依赖来调用其他服务。 只有调用者（如content模块）需要使用@EnableFeignClients注解，被调用者（如media模块）不需要 ：正确。@EnableFeignClients注解是用来启用Feign客户端的，它告诉Spring Cloud这个服务将会使用Feign来进行远程服务调用。因此，只有需要使用Feign客户端的服务（在这个例子中是content模块）需要添加这个注解。而被调用的服务（如media模块），只需作为普通的Spring Boot应用运行，提供REST API即可，无需使用@EnableFeignClients。 如何在服务间共享数据模型（如DTOs）而不引入不必要的依赖。解决这个问题的一种方法是创建一个共享的库或模块，这个库包含所有服务共享的数据模型。另一种使用依赖剥离，使用通配符（*）可以排除pom.xml中特定依赖的所有传递性依赖。","link":"/Hexo/2024/02/04/2024-H1/2024-02-04-21-58-27/"},{"title":"从RSA角度出发解析JWT原理","text":"在今天的数字化世界中，安全地传递信息变得越来越重要。JSON Web Token（JWT）作为一种流行的开放标准，为简化服务器与客户端之间的安全交流提供了一种高效的方式。本文旨在深入解析JWT的工作原理，并通过示例演示如何使用JWT进行安全通信。我们将从JWT的基本组成部分讲起，探讨公密钥加密的原理，解释为什么JWT是安全的，以及如何验证JWT的有效性。 一、JWT介绍1. JWT组成部分JWT由三个部分组成，它们分别是头部（Header）、载荷（Payload）、和签名（Signature）。通过将这三部分用点（.）连接起来，形成了一个完整的JWT字符串。例如：xxxxx.yyyyy.zzzzz。 2. 头部（Header）头部通常由两部分组成：令牌类型（typ）和签名算法（alg）。例如： language-json12345{ &quot;kid&quot;: &quot;33bd1cad-62a6-4415-89a6-c2c816f3d3b1&quot;, &quot;alg&quot;: &quot;RS256&quot;} kid (Key ID)：密钥标识符，用于指明验证JWT签名时使用的密钥。在含有多个密钥的系统中，这可以帮助接收者选择正确的密钥进行验证。这里的值33bd1cad-62a6-4415-89a6-c2c816f3d3b1是一个UUID，唯一标识了用于签名的密钥。 alg (Algorithm)：指明用于签名的算法，这里是RS256，表示使用RSA签名算法和SHA-256散列算法。这种算法属于公钥/私钥算法，意味着使用私钥进行签名，而用公钥进行验证。 3. 载荷（Payload）载荷包含了所要传递的信息，这些信息以声明（claims）的形式存在。声明可以是用户的身份标识，也可以是其他任何必要的信息。载荷示例： language-json12345678910{ &quot;sub&quot;: &quot;XcWebApp&quot;, &quot;aud&quot;: &quot;XcWebApp&quot;, &quot;nbf&quot;: 1707373072, &quot;iss&quot;: &quot;http://localhost:63070/auth&quot;, &quot;exp&quot;: 1707380272, &quot;iat&quot;: 1707373072, &quot;jti&quot;: &quot;62e885c5-6b3f-49a2-aa10-b2e872a52b33&quot;} sub (Subject)：主题，标识了这个JWT的主体，通常是指用户的唯一标识。这里XcWebApp可能是一个应用或用户标识。 aud (Audience)：受众，标识了这个JWT的预期接收者。这里同样是XcWebApp，意味着这个JWT是为XcWebApp这个应用或服务生成的。 nbf (Not Before)：生效时间，这个时间之前，JWT不应被接受处理。这里的时间是Unix时间戳格式，表示JWT生效的具体时间。 iss (Issuer)：发行者，标识了这个JWT的发行方。这里是http://localhost:63070/auth，表明JWT由本地的某个认证服务器发行。 exp (Expiration Time)：过期时间，这个时间之后，JWT不再有效。同样是Unix时间戳格式，表示JWT过期的具体时间。 iat (Issued At)：发行时间，JWT创建的时间。这提供了JWT的时间信息，也是Unix时间戳格式。 jti (JWT ID)：JWT的唯一标识符，用于防止JWT被重放（即两次使用同一个JWT）。这里的值是一个UUID，确保了JWT的唯一性。 4. 签名（Signature）签名是对头部和载荷的加密保护，确保它们在传输过程中未被篡改。根据头部中指定的算法（例如HS256），使用私钥对头部和载荷进行签名。 二、深入理解JWT签名验证1. 签名生成 哈希处理 ：首先对JWT的头部和载荷部分（经过Base64编码并用.连接的字符串）进行哈希处理，生成一个哈希值。这个步骤是为了确保数据的完整性，即使是微小的改动也会导致哈希值有很大的不同。 私钥加密哈希值 ：然后使用发行者的私钥对这个哈希值进行加密，生成的结果就是JWT的签名部分。这个加密的哈希值（签名）附加在JWT的后面。 2. 签名验证 哈希处理 ：接收方收到JWT后，会独立地对其头部和载荷部分进行同样的哈希处理，生成一个哈希值。 公钥解密签名 ：接收方使用发行者的公钥对签名（加密的哈希值）进行解密，得到另一个哈希值。 哈希值比较 ：比较这两个哈希值。如果它们相同，就证明了JWT在传输过程中未被篡改，因为只有相应的私钥能够生成一个对应的、能够通过公钥解密并得到原始哈希值的签名。 3. 为什么JWT是安全的由于破解RSA算法的难度极高，没有私钥就无法生成有效的签名，因此无法伪造签名。这就是为什么使用公钥进行签名验证是安全的原因。 三、如何验证JWT是否有效对于一个JWT，我们可以使用Base64解码，获取前两部分信息，可以进行token是否过期等验证，具体取决于前两部分具体内容，这是可以人为设置的。对于签名部分，可以用公钥去验证其有效性（即是否被纂改）。 四、 Why JWT？为什么是JWT？首先是不可伪造的安全性，其次，因为你会发现，只要有公钥就可以验证JWT这种token，这也就意味着对于微服务来说，任意微服务都有能力自行验证JWT，而不需要额外的验证模块。这种自校验没有用到网络通信，性能十分好。同时，JWT有时间限制，一定程度上也提高了最坏情况的安全性。","link":"/Hexo/2024/02/08/2024-H1/2024-02-08-17-35-27/"},{"title":"Spring Authorization Server Spring Security密码加密","text":"一、修改密码编码器以BCryptPasswordEncoder举例。直接将其注册成PasswordEncoder 的Bean即可。 language-java12345678 @Bean public PasswordEncoder passwordEncoder() { // 密码为明文方式// return NoOpPasswordEncoder.getInstance(); // 或使用 BCryptPasswordEncoder return new BCryptPasswordEncoder(); } 二、效果使用了加密算法后，无论是RegisteredClient的密码还是UserDetailsService的密码，都会以密文的方式存储在服务器上。 但是前端输入的密码仍然是以明文的方式出现并传到服务器，之后服务器会对明文进行相同的手段（指对同样的明文，密文相同）加密，比较两个密文是否一致。 三、注意点1. RegisteredClientlanguage-java123456789 @Bean public RegisteredClientRepository registeredClientRepository() { RegisteredClient registeredClient = RegisteredClient.withId(UUID.randomUUID().toString()) .clientId(&quot;XcWebApp&quot;) .clientSecret(passwordEncoder().encode(&quot;XcWebApp&quot;)) .build(); return new InMemoryRegisteredClientRepository(registeredClient);} RegisteredClient中clientSecret仍然需要提供密文。 是因为，加密这个行为，只在服务器校验前端发送的明文时使用，至于对照物，则是代码中提供好的密文，所以这个需要提供密文。 2. UserDetailsService对于UserDetailsService也是，密码也需要提供现成的密文形式。下面的代码中数据库保存的是password密文。 language-java1234567891011121314151617181920212223242526@Component@Slf4jpublic class UserServiceImpl implements UserDetailsService { @Autowired XcUserMapper xcUserMapper; @Override public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException { //根据username查询数据库 XcUser xcUser = xcUserMapper.selectOne(new LambdaQueryWrapper&lt;XcUser&gt;() .eq(XcUser::getUsername, username)); //用户不存在，返回null if (xcUser == null){ return null; } //用户存在，拿到密码，封装成UserDetails,密码对比由框架进行 String password = xcUser.getPassword(); UserDetails userDetails = User.withUsername(username).password(password).authorities(&quot;read&quot;).build(); return userDetails; }}","link":"/Hexo/2024/02/08/2024-H1/2024-02-08-21-25-55/"},{"title":"微服务OAuth 2.1扩展额外信息到JWT并解析(Spring Security 6)","text":"一、简介 Version Java 17 SpringCloud 2023.0.0 SpringBoot 3.2.1 Spring Authorization Server 1.2.1 Spring Security 6.2.1 mysql 8.2.0 Spring Authorization Server 使用JWT时，前两部分默认格式如下 language-json123456789101112131415{ &quot;kid&quot;: &quot;33bd1cad-62a6-4415-89a6-c2c816f3d3b1&quot;, &quot;alg&quot;: &quot;RS256&quot;}{ &quot;sub&quot;: &quot;XcWebApp&quot;, &quot;aud&quot;: &quot;XcWebApp&quot;, &quot;nbf&quot;: 1707373072, &quot;iss&quot;: &quot;http://localhost:63070/auth&quot;, &quot;exp&quot;: 1707380272, &quot;iat&quot;: 1707373072, &quot;jti&quot;: &quot;62e885c5-6b3f-49a2-aa10-b2e872a52b33&quot;} 现在我们要把用户信息也扩展到JWT，最简便的方法就是将用户信息写成JSON字符串替换sub字段。其中用户信息由xc_user数据库表存储。 二、重写UserDetailsService注释掉原来的UserDetailsService实例。新建一个实现类，如下 language-java123456789101112131415161718192021222324252627@Component@Slf4jpublic class UserServiceImpl implements UserDetailsService { @Autowired XcUserMapper xcUserMapper; @Override public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException { //根据username查询数据库 XcUser xcUser = xcUserMapper.selectOne(new LambdaQueryWrapper&lt;XcUser&gt;() .eq(XcUser::getUsername, username)); //用户不存在，返回null if (xcUser == null){ return null; } //用户存在，拿到密码，封装成UserDetails,密码对比由框架进行 String password = xcUser.getPassword(); //扩展用户信息 xcUser.setPassword(null); String userInfo = JSON.toJSONString(xcUser); UserDetails userDetails = User.withUsername(userInfo).password(password).authorities(&quot;read&quot;).build(); return userDetails; }} 如果XcUser为null，返回null，这里处理了用户不存在的情况。 如果用户存在，则获取密码，放到UserDetails 中，密码比对过程我们不关心，由框架完成。如果使用了加密算法，这里的password应该是密文。 我们可以把用户信息转成JSON字符串放入withUsername。这样框架生成JWT时就会把用户信息也放进去。 是的，你没有猜错，UserDetails 只要返回密码框架就能比对成功，不需要再返回username。 三、Controller解析JWT获取用户信息写一个工具类，通过Security ContextHolder.getContext()上下文获取Authentication然后解析JWT。 language-java123456789101112131415161718192021@Slf4jpublic class SecurityUtil { public static XcUser getUser(){ Authentication authentication = SecurityContextHolder.getContext().getAuthentication(); if (authentication instanceof JwtAuthenticationToken) { JwtAuthenticationToken jwtAuth = (JwtAuthenticationToken) authentication; Map&lt;String, Object&gt; tokenAttributes = jwtAuth.getTokenAttributes(); Object sub = tokenAttributes.get(&quot;sub&quot;); return JSON.parseObject(sub.toString(), XcUser.class); } return null; } @Data public static class XcUser implements Serializable { //... }} JwtAuthenticationToken是Spring Authorization Server的一个类，可以帮助我们解析JWT。 四、后记从SecurityContextHolder.getContext().getAuthentication()解析我们放进去的XcUser的方法不止一种，将其打印出来就可以看出，有多个地方包含了XcUser，例如。 language-json123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105{ &quot;authenticated&quot;: true, &quot;authorities&quot;: [{ &quot;authority&quot;: &quot;SCOPE_all&quot; }], &quot;credentials&quot;: { &quot;audience&quot;: [&quot;XcWebApp&quot;], &quot;claims&quot;: { &quot;sub&quot;: &quot;{\\&quot;createTime\\&quot;:\\&quot;2022-09-28 08:32:03\\&quot;,\\&quot;id\\&quot;:\\&quot;48\\&quot;,\\&quot;name\\&quot;:\\&quot;系统管理员\\&quot;,\\&quot;sex\\&quot;:\\&quot;1\\&quot;,\\&quot;status\\&quot;:\\&quot;1\\&quot;,\\&quot;username\\&quot;:\\&quot;admin\\&quot;,\\&quot;utype\\&quot;:\\&quot;101003\\&quot;}&quot;, &quot;aud&quot;: [&quot;XcWebApp&quot;], &quot;nbf&quot;: &quot;2024-02-08T14:01:16Z&quot;, &quot;scope&quot;: [&quot;all&quot;], &quot;iss&quot;: &quot;http://localhost:63070/auth&quot;, &quot;exp&quot;: &quot;2024-02-08T16:01:16Z&quot;, &quot;iat&quot;: &quot;2024-02-08T14:01:16Z&quot;, &quot;jti&quot;: &quot;91df8f15-2096-4e03-a927-877b51bf5997&quot; }, &quot;expiresAt&quot;: &quot;2024-02-08T16:01:16Z&quot;, &quot;headers&quot;: { &quot;kid&quot;: &quot;e14df18d-1c95-441d-80d6-8457f3ceba9e&quot;, &quot;alg&quot;: &quot;RS256&quot; }, &quot;id&quot;: &quot;91df8f15-2096-4e03-a927-877b51bf5997&quot;, &quot;issuedAt&quot;: &quot;2024-02-08T14:01:16Z&quot;, &quot;issuer&quot;: &quot;http://localhost:63070/auth&quot;, &quot;notBefore&quot;: &quot;2024-02-08T14:01:16Z&quot;, &quot;subject&quot;: &quot;{\\&quot;createTime\\&quot;:\\&quot;2022-09-28 08:32:03\\&quot;,\\&quot;id\\&quot;:\\&quot;48\\&quot;,\\&quot;name\\&quot;:\\&quot;系统管理员\\&quot;,\\&quot;sex\\&quot;:\\&quot;1\\&quot;,\\&quot;status\\&quot;:\\&quot;1\\&quot;,\\&quot;username\\&quot;:\\&quot;admin\\&quot;,\\&quot;utype\\&quot;:\\&quot;101003\\&quot;}&quot;, &quot;tokenValue&quot;: &quot;eyJraWQiOiJlMTRkZjE4ZC0xYzk1LTQ0MWQtODBkNi04NDU3ZjNjZWJhOWUiLCJhbGciOiJSUzI1NiJ9.eyJzdWIiOiJ7XCJjcmVhdGVUaW1lXCI6XCIyMDIyLTA5LTI4IDA4OjMyOjAzXCIsXCJpZFwiOlwiNDhcIixcIm5hbWVcIjpcIuezu-e7n-euoeeQhuWRmFwiLFwic2V4XCI6XCIxXCIsXCJzdGF0dXNcIjpcIjFcIixcInVzZXJuYW1lXCI6XCJhZG1pblwiLFwidXR5cGVcIjpcIjEwMTAwM1wifSIsImF1ZCI6IlhjV2ViQXBwIiwibmJmIjoxNzA3NDAwODc2LCJzY29wZSI6WyJhbGwiXSwiaXNzIjoiaHR0cDovL2xvY2FsaG9zdDo2MzA3MC9hdXRoIiwiZXhwIjoxNzA3NDA4MDc2LCJpYXQiOjE3MDc0MDA4NzYsImp0aSI6IjkxZGY4ZjE1LTIwOTYtNGUwMy1hOTI3LTg3N2I1MWJmNTk5NyJ9.NZ3f_Pkh871L1c8XkV2PxHfn17pWjaRvBd9HQQTRJhfFvNBN7zoh2riumpfVUj_xVmnCadVX3YE4ARxc0CuiV1QyVDpFnmKiuvWdsRVV9NF5Kkb67CGtF2zw1l2gFdSDFWAwOq1SemtogHX5a4XFF2kG6kx9ZOSL4EoiQMMhUOwfY6mL9Zdcgq_E28kfnrAk__q84rgo9JPvj3jH6cm_oS63-tNXZYdClDG61DHS4Bw7cswUfVf_bcI_a8kXfiM8SzCnROvxe1hU2dM88qxUgkI1GPlrtZhe9z7113XP7ilaPo2UknCFh_OSbfUeUDmP1GpTaspfGmnHhBXLQyG06Q&quot; }, &quot;details&quot;: { &quot;remoteAddress&quot;: &quot;192.168.222.1&quot; }, &quot;name&quot;: &quot;{\\&quot;createTime\\&quot;:\\&quot;2022-09-28 08:32:03\\&quot;,\\&quot;id\\&quot;:\\&quot;48\\&quot;,\\&quot;name\\&quot;:\\&quot;系统管理员\\&quot;,\\&quot;sex\\&quot;:\\&quot;1\\&quot;,\\&quot;status\\&quot;:\\&quot;1\\&quot;,\\&quot;username\\&quot;:\\&quot;admin\\&quot;,\\&quot;utype\\&quot;:\\&quot;101003\\&quot;}&quot;, &quot;principal&quot;: { &quot;audience&quot;: [&quot;XcWebApp&quot;], &quot;claims&quot;: { &quot;sub&quot;: &quot;{\\&quot;createTime\\&quot;:\\&quot;2022-09-28 08:32:03\\&quot;,\\&quot;id\\&quot;:\\&quot;48\\&quot;,\\&quot;name\\&quot;:\\&quot;系统管理员\\&quot;,\\&quot;sex\\&quot;:\\&quot;1\\&quot;,\\&quot;status\\&quot;:\\&quot;1\\&quot;,\\&quot;username\\&quot;:\\&quot;admin\\&quot;,\\&quot;utype\\&quot;:\\&quot;101003\\&quot;}&quot;, &quot;aud&quot;: [&quot;XcWebApp&quot;], &quot;nbf&quot;: &quot;2024-02-08T14:01:16Z&quot;, &quot;scope&quot;: [&quot;all&quot;], &quot;iss&quot;: &quot;http://localhost:63070/auth&quot;, &quot;exp&quot;: &quot;2024-02-08T16:01:16Z&quot;, &quot;iat&quot;: &quot;2024-02-08T14:01:16Z&quot;, &quot;jti&quot;: &quot;91df8f15-2096-4e03-a927-877b51bf5997&quot; }, &quot;expiresAt&quot;: &quot;2024-02-08T16:01:16Z&quot;, &quot;headers&quot;: { &quot;kid&quot;: &quot;e14df18d-1c95-441d-80d6-8457f3ceba9e&quot;, &quot;alg&quot;: &quot;RS256&quot; }, &quot;id&quot;: &quot;91df8f15-2096-4e03-a927-877b51bf5997&quot;, &quot;issuedAt&quot;: &quot;2024-02-08T14:01:16Z&quot;, &quot;issuer&quot;: &quot;http://localhost:63070/auth&quot;, &quot;notBefore&quot;: &quot;2024-02-08T14:01:16Z&quot;, &quot;subject&quot;: &quot;{\\&quot;createTime\\&quot;:\\&quot;2022-09-28 08:32:03\\&quot;,\\&quot;id\\&quot;:\\&quot;48\\&quot;,\\&quot;name\\&quot;:\\&quot;系统管理员\\&quot;,\\&quot;sex\\&quot;:\\&quot;1\\&quot;,\\&quot;status\\&quot;:\\&quot;1\\&quot;,\\&quot;username\\&quot;:\\&quot;admin\\&quot;,\\&quot;utype\\&quot;:\\&quot;101003\\&quot;}&quot;, &quot;tokenValue&quot;: &quot;eyJraWQiOiJlMTRkZjE4ZC0xYzk1LTQ0MWQtODBkNi04NDU3ZjNjZWJhOWUiLCJhbGciOiJSUzI1NiJ9.eyJzdWIiOiJ7XCJjcmVhdGVUaW1lXCI6XCIyMDIyLTA5LTI4IDA4OjMyOjAzXCIsXCJpZFwiOlwiNDhcIixcIm5hbWVcIjpcIuezu-e7n-euoeeQhuWRmFwiLFwic2V4XCI6XCIxXCIsXCJzdGF0dXNcIjpcIjFcIixcInVzZXJuYW1lXCI6XCJhZG1pblwiLFwidXR5cGVcIjpcIjEwMTAwM1wifSIsImF1ZCI6IlhjV2ViQXBwIiwibmJmIjoxNzA3NDAwODc2LCJzY29wZSI6WyJhbGwiXSwiaXNzIjoiaHR0cDovL2xvY2FsaG9zdDo2MzA3MC9hdXRoIiwiZXhwIjoxNzA3NDA4MDc2LCJpYXQiOjE3MDc0MDA4NzYsImp0aSI6IjkxZGY4ZjE1LTIwOTYtNGUwMy1hOTI3LTg3N2I1MWJmNTk5NyJ9.NZ3f_Pkh871L1c8XkV2PxHfn17pWjaRvBd9HQQTRJhfFvNBN7zoh2riumpfVUj_xVmnCadVX3YE4ARxc0CuiV1QyVDpFnmKiuvWdsRVV9NF5Kkb67CGtF2zw1l2gFdSDFWAwOq1SemtogHX5a4XFF2kG6kx9ZOSL4EoiQMMhUOwfY6mL9Zdcgq_E28kfnrAk__q84rgo9JPvj3jH6cm_oS63-tNXZYdClDG61DHS4Bw7cswUfVf_bcI_a8kXfiM8SzCnROvxe1hU2dM88qxUgkI1GPlrtZhe9z7113XP7ilaPo2UknCFh_OSbfUeUDmP1GpTaspfGmnHhBXLQyG06Q&quot; }, &quot;token&quot;: { &quot;audience&quot;: [&quot;XcWebApp&quot;], &quot;claims&quot;: { &quot;sub&quot;: &quot;{\\&quot;createTime\\&quot;:\\&quot;2022-09-28 08:32:03\\&quot;,\\&quot;id\\&quot;:\\&quot;48\\&quot;,\\&quot;name\\&quot;:\\&quot;系统管理员\\&quot;,\\&quot;sex\\&quot;:\\&quot;1\\&quot;,\\&quot;status\\&quot;:\\&quot;1\\&quot;,\\&quot;username\\&quot;:\\&quot;admin\\&quot;,\\&quot;utype\\&quot;:\\&quot;101003\\&quot;}&quot;, &quot;aud&quot;: [&quot;XcWebApp&quot;], &quot;nbf&quot;: &quot;2024-02-08T14:01:16Z&quot;, &quot;scope&quot;: [&quot;all&quot;], &quot;iss&quot;: &quot;http://localhost:63070/auth&quot;, &quot;exp&quot;: &quot;2024-02-08T16:01:16Z&quot;, &quot;iat&quot;: &quot;2024-02-08T14:01:16Z&quot;, &quot;jti&quot;: &quot;91df8f15-2096-4e03-a927-877b51bf5997&quot; }, &quot;expiresAt&quot;: &quot;2024-02-08T16:01:16Z&quot;, &quot;headers&quot;: { &quot;kid&quot;: &quot;e14df18d-1c95-441d-80d6-8457f3ceba9e&quot;, &quot;alg&quot;: &quot;RS256&quot; }, &quot;id&quot;: &quot;91df8f15-2096-4e03-a927-877b51bf5997&quot;, &quot;issuedAt&quot;: &quot;2024-02-08T14:01:16Z&quot;, &quot;issuer&quot;: &quot;http://localhost:63070/auth&quot;, &quot;notBefore&quot;: &quot;2024-02-08T14:01:16Z&quot;, &quot;subject&quot;: &quot;{\\&quot;createTime\\&quot;:\\&quot;2022-09-28 08:32:03\\&quot;,\\&quot;id\\&quot;:\\&quot;48\\&quot;,\\&quot;name\\&quot;:\\&quot;系统管理员\\&quot;,\\&quot;sex\\&quot;:\\&quot;1\\&quot;,\\&quot;status\\&quot;:\\&quot;1\\&quot;,\\&quot;username\\&quot;:\\&quot;admin\\&quot;,\\&quot;utype\\&quot;:\\&quot;101003\\&quot;}&quot;, &quot;tokenValue&quot;: &quot;eyJraWQiOiJlMTRkZjE4ZC0xYzk1LTQ0MWQtODBkNi04NDU3ZjNjZWJhOWUiLCJhbGciOiJSUzI1NiJ9.eyJzdWIiOiJ7XCJjcmVhdGVUaW1lXCI6XCIyMDIyLTA5LTI4IDA4OjMyOjAzXCIsXCJpZFwiOlwiNDhcIixcIm5hbWVcIjpcIuezu-e7n-euoeeQhuWRmFwiLFwic2V4XCI6XCIxXCIsXCJzdGF0dXNcIjpcIjFcIixcInVzZXJuYW1lXCI6XCJhZG1pblwiLFwidXR5cGVcIjpcIjEwMTAwM1wifSIsImF1ZCI6IlhjV2ViQXBwIiwibmJmIjoxNzA3NDAwODc2LCJzY29wZSI6WyJhbGwiXSwiaXNzIjoiaHR0cDovL2xvY2FsaG9zdDo2MzA3MC9hdXRoIiwiZXhwIjoxNzA3NDA4MDc2LCJpYXQiOjE3MDc0MDA4NzYsImp0aSI6IjkxZGY4ZjE1LTIwOTYtNGUwMy1hOTI3LTg3N2I1MWJmNTk5NyJ9.NZ3f_Pkh871L1c8XkV2PxHfn17pWjaRvBd9HQQTRJhfFvNBN7zoh2riumpfVUj_xVmnCadVX3YE4ARxc0CuiV1QyVDpFnmKiuvWdsRVV9NF5Kkb67CGtF2zw1l2gFdSDFWAwOq1SemtogHX5a4XFF2kG6kx9ZOSL4EoiQMMhUOwfY6mL9Zdcgq_E28kfnrAk__q84rgo9JPvj3jH6cm_oS63-tNXZYdClDG61DHS4Bw7cswUfVf_bcI_a8kXfiM8SzCnROvxe1hU2dM88qxUgkI1GPlrtZhe9z7113XP7ilaPo2UknCFh_OSbfUeUDmP1GpTaspfGmnHhBXLQyG06Q&quot; }, &quot;tokenAttributes&quot;: { &quot;sub&quot;: &quot;{\\&quot;createTime\\&quot;:\\&quot;2022-09-28 08:32:03\\&quot;,\\&quot;id\\&quot;:\\&quot;48\\&quot;,\\&quot;name\\&quot;:\\&quot;系统管理员\\&quot;,\\&quot;sex\\&quot;:\\&quot;1\\&quot;,\\&quot;status\\&quot;:\\&quot;1\\&quot;,\\&quot;username\\&quot;:\\&quot;admin\\&quot;,\\&quot;utype\\&quot;:\\&quot;101003\\&quot;}&quot;, &quot;aud&quot;: [&quot;XcWebApp&quot;], &quot;nbf&quot;: &quot;2024-02-08T14:01:16Z&quot;, &quot;scope&quot;: [&quot;all&quot;], &quot;iss&quot;: &quot;http://localhost:63070/auth&quot;, &quot;exp&quot;: &quot;2024-02-08T16:01:16Z&quot;, &quot;iat&quot;: &quot;2024-02-08T14:01:16Z&quot;, &quot;jti&quot;: &quot;91df8f15-2096-4e03-a927-877b51bf5997&quot; }}","link":"/Hexo/2024/02/09/2024-H1/2024-02-09-10-10-37/"},{"title":"Gateway中Spring Security6统一处理CORS","text":"一、起因使用了gateway微服务作为整体的网关，并且整合了Spring Security6；还有一个system微服务，作为被请求的资源，当浏览器向gateway发送请求，请求system资源时，遇到CORS问题。 于是我在system对应的controller上加了@CrossOrigin，无效；配置WebMvcConfigurer，也无效。后来发现，会不会是gateway的spring security6在一开始就拦截了CORS跨域请求，导致根本走不到后面的system配置。 查询了一波，果然如此。这里记录解决方法。 二、解决方法这是依赖 language-xml12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-oauth2-resource-server&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt; 这是配置 language-java12345678910111213141516171819202122232425262728293031323334353637@EnableWebFluxSecurity@Configurationpublic class SecurityConfig { //安全拦截配置 @Bean public SecurityWebFilterChain webFluxSecurityFilterChain(ServerHttpSecurity http) throws Exception { return http .cors(cors -&gt; cors.configurationSource(corsConfigurationSource())) .authorizeExchange(exchanges -&gt; exchanges .pathMatchers(&quot;/**&quot;).permitAll() .anyExchange().authenticated() ) .oauth2ResourceServer(oauth2 -&gt; oauth2.jwt(Customizer.withDefaults())) .csrf(ServerHttpSecurity.CsrfSpec::disable) .build(); } @Bean public CorsConfigurationSource corsConfigurationSource() { CorsConfiguration corsConfig = new CorsConfiguration(); corsConfig.addAllowedOriginPattern(&quot;*&quot;); // 允许任何源 corsConfig.addAllowedMethod(&quot;*&quot;); // 允许任何HTTP方法 corsConfig.addAllowedHeader(&quot;*&quot;); // 允许任何HTTP头 corsConfig.setAllowCredentials(true); // 允许证书（cookies） corsConfig.setMaxAge(3600L); // 预检请求的缓存时间（秒） UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource(); source.registerCorsConfiguration(&quot;/**&quot;, corsConfig); // 对所有路径应用这个配置 return source; }} 需要注意的是，在gateway的spring security中处理了CORS问题后，后续的system什么的，就不需要再二次处理了。因为CORS是一个浏览器的策略，只要处理一次，告诉浏览器我允许跨域，浏览器收到后就不再阻拦请求了。","link":"/Hexo/2024/02/13/2024-H1/2024-02-13-16-22-24/"},{"title":"微服务OAuth 2.1认证授权Demo方案(Spring Security 6)","text":"书接上文微服务OAuth 2.1认证授权可行性方案(Spring Security 6) 一、介绍三个微服务 auth微服务作为认证服务器，用于颁发JWT。 gateway微服务作为网关，用于拦截过滤。 content微服务作为资源服务器，用于校验授权。 以下是授权相关数据库。 user表示用户表 role表示角色表 user_role关联了用户和角色，表示某个用户是是什么角色。一个用户可以有多个角色 menu表示资源权限表。@PreAuthorize(&quot;hasAuthority('xxx')&quot;)时用的就是这里的code。 permission关联了角色和资源权限，表示某个角色用于哪些资源访问权限，一个角色有多个资源访问权限。 当我们知道userId，我们就可以知道这个用户可以访问哪些资源，并把这些权限（也就是menu里的code字段）写成数组，写到JWT的负载部分的authorities字段中。当用户携带此JWT访问具有@PreAuthorize(&quot;hasAuthority('xxx')&quot;)修饰的资源时，我们解析出JWT中的authorities字段，判断是否包含hasAuthority指定的xxx权限，以此来完成所谓的的”授权”。 二、auth微服务代码1. SecurityConfiglanguage-java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280package com.xuecheng.auth.config;import com.nimbusds.jose.jwk.JWKSet;import com.nimbusds.jose.jwk.RSAKey;import com.nimbusds.jose.jwk.source.ImmutableJWKSet;import com.nimbusds.jose.jwk.source.JWKSource;import com.nimbusds.jose.proc.SecurityContext;import org.springframework.context.annotation.Bean;import org.springframework.context.annotation.Configuration;import org.springframework.core.annotation.Order;import org.springframework.http.MediaType;import org.springframework.security.config.Customizer;import org.springframework.security.config.annotation.web.builders.HttpSecurity;import org.springframework.security.config.annotation.web.configuration.EnableWebSecurity;import org.springframework.security.config.annotation.web.configurers.AbstractHttpConfigurer;import org.springframework.security.core.Authentication;import org.springframework.security.core.GrantedAuthority;import org.springframework.security.core.userdetails.UserDetails;import org.springframework.security.crypto.bcrypt.BCryptPasswordEncoder;import org.springframework.security.crypto.password.PasswordEncoder;import org.springframework.security.oauth2.core.AuthorizationGrantType;import org.springframework.security.oauth2.core.ClientAuthenticationMethod;import org.springframework.security.oauth2.core.oidc.OidcScopes;import org.springframework.security.oauth2.jwt.JwtDecoder;import org.springframework.security.oauth2.server.authorization.client.InMemoryRegisteredClientRepository;import org.springframework.security.oauth2.server.authorization.client.RegisteredClient;import org.springframework.security.oauth2.server.authorization.client.RegisteredClientRepository;import org.springframework.security.oauth2.server.authorization.config.annotation.web.configuration.OAuth2AuthorizationServerConfiguration;import org.springframework.security.oauth2.server.authorization.config.annotation.web.configurers.OAuth2AuthorizationServerConfigurer;import org.springframework.security.oauth2.server.authorization.settings.AuthorizationServerSettings;import org.springframework.security.oauth2.server.authorization.settings.ClientSettings;import org.springframework.security.oauth2.server.authorization.settings.TokenSettings;import org.springframework.security.oauth2.server.authorization.token.JwtEncodingContext;import org.springframework.security.oauth2.server.authorization.token.OAuth2TokenCustomizer;import org.springframework.security.oauth2.server.resource.authentication.JwtAuthenticationConverter;import org.springframework.security.web.SecurityFilterChain;import org.springframework.security.web.authentication.LoginUrlAuthenticationEntryPoint;import org.springframework.security.web.authentication.logout.SecurityContextLogoutHandler;import org.springframework.security.web.util.matcher.AntPathRequestMatcher;import org.springframework.security.web.util.matcher.MediaTypeRequestMatcher;import java.security.KeyPair;import java.security.KeyPairGenerator;import java.security.interfaces.RSAPrivateKey;import java.security.interfaces.RSAPublicKey;import java.time.Duration;import java.util.List;import java.util.UUID;import java.util.stream.Collectors;/** * 身份验证服务器安全配置 * * @author mumu * @date 2024/02/13 *///@EnableGlobalMethodSecurity(securedEnabled = true, prePostEnabled = true)@Configuration@EnableWebSecuritypublic class AuthServerSecurityConfig { private static KeyPair generateRsaKey() { KeyPair keyPair; try { KeyPairGenerator keyPairGenerator = KeyPairGenerator.getInstance(&quot;RSA&quot;); keyPairGenerator.initialize(2048); keyPair = keyPairGenerator.generateKeyPair(); } catch (Exception ex) { throw new IllegalStateException(ex); } return keyPair; } /** * 密码编码器 * 用于加密认证服务器client密码和用户密码 * * @return {@link PasswordEncoder} */ @Bean public PasswordEncoder passwordEncoder() { // 密码为明文方式 // return NoOpPasswordEncoder.getInstance(); // 或使用 BCryptPasswordEncoder return new BCryptPasswordEncoder(); } /** * 授权服务器安全筛选器链 * &lt;br/&gt; * 来自Spring Authorization Server示例，用于暴露Oauth2.1端点，一般不影响常规的请求 * * @param http http * @return {@link SecurityFilterChain} * @throws Exception 例外 */ @Bean @Order(1) public SecurityFilterChain authorizationServerSecurityFilterChain(HttpSecurity http) throws Exception { OAuth2AuthorizationServerConfiguration.applyDefaultSecurity(http); http.getConfigurer(OAuth2AuthorizationServerConfigurer.class) .oidc(Customizer.withDefaults()); // Enable OpenID Connect 1.0 http // Redirect to the login page when not authenticated from the // authorization endpoint .exceptionHandling((exceptions) -&gt; exceptions .defaultAuthenticationEntryPointFor( new LoginUrlAuthenticationEntryPoint(&quot;/login&quot;), new MediaTypeRequestMatcher(MediaType.TEXT_HTML) ) ) // Accept access tokens for User Info and/or Client Registration .oauth2ResourceServer((resourceServer) -&gt; resourceServer .jwt(Customizer.withDefaults())); return http.build(); } /** * 默认筛选器链 * &lt;br/&gt; * 这个才是我们需要关心的过滤链，可以指定哪些请求被放行，哪些请求需要JWT验证 * * @param http http * @return {@link SecurityFilterChain} * @throws Exception 例外 */ @Bean @Order(2) public SecurityFilterChain defaultFilterChain(HttpSecurity http) throws Exception { http .authorizeHttpRequests((authorize) -&gt; authorize .requestMatchers(new AntPathRequestMatcher(&quot;/actuator/**&quot;)).permitAll() .requestMatchers(new AntPathRequestMatcher(&quot;/login&quot;)).permitAll() .requestMatchers(new AntPathRequestMatcher(&quot;/logout&quot;)).permitAll() .requestMatchers(new AntPathRequestMatcher(&quot;/wxLogin&quot;)).permitAll() .requestMatchers(new AntPathRequestMatcher(&quot;/register&quot;)).permitAll() .requestMatchers(new AntPathRequestMatcher(&quot;/oauth2/**&quot;)).permitAll() .requestMatchers(new AntPathRequestMatcher(&quot;/**/*.html&quot;)).permitAll() .requestMatchers(new AntPathRequestMatcher(&quot;/**/*.json&quot;)).permitAll() .requestMatchers(new AntPathRequestMatcher(&quot;/auth/**&quot;)).permitAll() .anyRequest().authenticated() ) .csrf(AbstractHttpConfigurer::disable) //指定logout端点，用于退出登陆，不然二次获取授权码时会自动登陆导致短时间内无法切换用户 .logout(logout -&gt; logout .logoutUrl(&quot;/logout&quot;) .addLogoutHandler(new SecurityContextLogoutHandler()) .logoutSuccessUrl(&quot;http://www.51xuecheng.cn&quot;) ) .formLogin(Customizer.withDefaults()) .oauth2ResourceServer(oauth2 -&gt; oauth2.jwt(Customizer.withDefaults())// .jwt(jwt -&gt; jwt// .jwtAuthenticationConverter(jwtAuthenticationConverter())// ) ); return http.build(); } private JwtAuthenticationConverter jwtAuthenticationConverter() { JwtAuthenticationConverter jwtConverter = new JwtAuthenticationConverter(); return jwtConverter; } /** * 客户端管理实例 * &lt;br/&gt; * 来自Spring Authorization Server示例 * * @return {@link RegisteredClientRepository} */ @Bean public RegisteredClientRepository registeredClientRepository() { RegisteredClient registeredClient = RegisteredClient.withId(UUID.randomUUID().toString()) .clientId(&quot;XcWebApp&quot;) .clientSecret(passwordEncoder().encode(&quot;XcWebApp&quot;)) .clientAuthenticationMethod(ClientAuthenticationMethod.CLIENT_SECRET_BASIC) .authorizationGrantType(AuthorizationGrantType.AUTHORIZATION_CODE) .authorizationGrantType(AuthorizationGrantType.REFRESH_TOKEN) .authorizationGrantType(AuthorizationGrantType.CLIENT_CREDENTIALS) .redirectUri(&quot;http://www.51xuecheng.cn&quot;) .redirectUri(&quot;http://localhost:63070/auth/wxLogin&quot;) .redirectUri(&quot;http://www.51xuecheng.cn/sign.html&quot;)// .postLogoutRedirectUri(&quot;http://localhost:63070/login?logout&quot;) .scope(&quot;all&quot;) .scope(OidcScopes.OPENID) .scope(OidcScopes.PROFILE) .scope(&quot;message.read&quot;) .scope(&quot;message.write&quot;) .scope(&quot;read&quot;) .scope(&quot;write&quot;) .clientSettings(ClientSettings.builder().requireAuthorizationConsent(true).build()) .tokenSettings(TokenSettings.builder() .accessTokenTimeToLive(Duration.ofHours(2)) // 设置访问令牌的有效期 .refreshTokenTimeToLive(Duration.ofDays(3)) // 设置刷新令牌的有效期 .reuseRefreshTokens(true) // 是否重用刷新令牌 .build()) .build(); return new InMemoryRegisteredClientRepository(registeredClient); } /** * jwk源 * &lt;br/&gt; * 对访问令牌进行签名的示例，里面包含公私钥信息。 * * @return {@link JWKSource}&lt;{@link SecurityContext}&gt; */ @Bean public JWKSource&lt;SecurityContext&gt; jwkSource() { KeyPair keyPair = generateRsaKey(); RSAPublicKey publicKey = (RSAPublicKey) keyPair.getPublic(); RSAPrivateKey privateKey = (RSAPrivateKey) keyPair.getPrivate(); RSAKey rsaKey = new RSAKey.Builder(publicKey) .privateKey(privateKey) .keyID(UUID.randomUUID().toString()) .build(); JWKSet jwkSet = new JWKSet(rsaKey); return new ImmutableJWKSet&lt;&gt;(jwkSet); } /** * jwt解码器 * &lt;br/&gt; * JWT解码器，主要就是基于公钥信息来解码 * * @param jwkSource jwk源 * @return {@link JwtDecoder} */ @Bean public JwtDecoder jwtDecoder(JWKSource&lt;SecurityContext&gt; jwkSource) { return OAuth2AuthorizationServerConfiguration.jwtDecoder(jwkSource); } @Bean public AuthorizationServerSettings authorizationServerSettings() { return AuthorizationServerSettings.builder().build(); } /** * JWT定制器 * &lt;BR/&gt; * 可以往JWT从加入额外信息，这里是加入authorities字段，是一个权限数组。 * * @return {@link OAuth2TokenCustomizer}&lt;{@link JwtEncodingContext}&gt; */ @Bean public OAuth2TokenCustomizer&lt;JwtEncodingContext&gt; jwtTokenCustomizer() { return context -&gt; { Authentication authentication = context.getPrincipal(); if (authentication.getPrincipal() instanceof UserDetails userDetails) { List&lt;String&gt; authorities = userDetails.getAuthorities().stream() .map(GrantedAuthority::getAuthority) .collect(Collectors.toList()); context.getClaims().claim(&quot;authorities&quot;, authorities); } }; }} 这里需要注意几点 使用BCryptPasswordEncoder密码加密，在设置clientSecret时需要手动使用密码编码器。 jwtTokenCustomizer解析UserDetails然后往JWT中添加authorities字段，为了后面的授权。 2. UserDetailsServicelanguage-java12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273package com.xuecheng.ucenter.service.impl;import com.alibaba.fastjson2.JSON;import com.baomidou.mybatisplus.core.conditions.query.LambdaQueryWrapper;import com.xuecheng.ucenter.mapper.XcMenuMapper;import com.xuecheng.ucenter.mapper.XcUserMapper;import com.xuecheng.ucenter.model.dto.AuthParamsDto;import com.xuecheng.ucenter.model.dto.XcUserExt;import com.xuecheng.ucenter.model.po.XcMenu;import com.xuecheng.ucenter.model.po.XcUser;import com.xuecheng.ucenter.service.AuthService;import lombok.extern.slf4j.Slf4j;import org.apache.commons.lang3.ObjectUtils;import org.apache.commons.lang3.StringUtils;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.beans.factory.annotation.Qualifier;import org.springframework.security.core.userdetails.User;import org.springframework.security.core.userdetails.UserDetails;import org.springframework.security.core.userdetails.UserDetailsService;import org.springframework.security.core.userdetails.UsernameNotFoundException;import org.springframework.stereotype.Component;import java.util.Arrays;import java.util.List;import java.util.stream.Collectors;@Component@Slf4jpublic class UserServiceImpl implements UserDetailsService { @Autowired private MyAuthService myAuthService; @Autowired XcMenuMapper xcMenuMapper; /** * 用户统一认证 * * @param s 用户信息Json字符串 * @return {@link UserDetails} * @throws UsernameNotFoundException 找不到用户名异常 */ @Override public UserDetails loadUserByUsername(String username) throws UsernameNotFoundException { XcUserExt xcUserExt = myAuthService.execute(username); return getUserPrincipal(xcUserExt); } public UserDetails getUserPrincipal(XcUserExt user){ //用户权限,如果不加报Cannot pass a null GrantedAuthority collection List&lt;XcMenu&gt; xcMenus = xcMenuMapper.selectPermissionByUserId(user.getId()); String[] permissions = { &quot;read&quot;}; if (ObjectUtils.isNotEmpty(xcMenus)){ permissions = xcMenus.stream().map(XcMenu::getCode).toList().toArray(String[]::new); log.info(&quot;权限如下:{}&quot;, Arrays.toString(permissions)); } //为了安全在令牌中不放密码 String password = user.getPassword(); user.setPassword(null); //将user对象转json String userString = JSON.toJSONString(user); //创建UserDetails对象 return User.withUsername(userString).password(password).authorities(permissions).build(); }} 这里需要注意几点 username就是前端/auth/login的时候输入的账户名。 myAuthService.execute(username)不抛异常，就默认表示账户存在，此时将password加入UserDetails 并返回，Spring Authorization Server对比校验两个密码。 myAuthService.execute(username)根据username获取用户信息返回，将用户信息存入withUsername中，Spring Authorization Server默认会将其加入到JWT中。 现在Spring Authorization Server默认不会把authorities(permissions)写入JWT，需要配合OAuth2TokenCustomizer手动写入。 3. 总结这样，auth微服务颁发的JWT，现在就会包含authorities字段。示例如下 language-json1234567891011121314151617181920212223{ &quot;active&quot;: true, &quot;sub&quot;: &quot;{\\&quot;cellphone\\&quot;:\\&quot;17266666637\\&quot;,\\&quot;createTime\\&quot;:\\&quot;2024-02-13 10:33:13\\&quot;,\\&quot;email\\&quot;:\\&quot;1138882663@qq.com\\&quot;,\\&quot;id\\&quot;:\\&quot;012f3a90-2bc9-4a2c-82a3-f9777c9ac10a\\&quot;,\\&quot;name\\&quot;:\\&quot;xiamu\\&quot;,\\&quot;nickname\\&quot;:\\&quot;xiamu\\&quot;,\\&quot;permissions\\&quot;:[],\\&quot;status\\&quot;:\\&quot;1\\&quot;,\\&quot;updateTime\\&quot;:\\&quot;2024-02-13 10:33:13\\&quot;,\\&quot;username\\&quot;:\\&quot;xiamu\\&quot;,\\&quot;utype\\&quot;:\\&quot;101001\\&quot;,\\&quot;wxUnionid\\&quot;:\\&quot;test\\&quot;}&quot;, &quot;aud&quot;: [ &quot;XcWebApp&quot; ], &quot;nbf&quot;: 1707830437, &quot;scope&quot;: &quot;all&quot;, &quot;iss&quot;: &quot;http://localhost:63070/auth&quot;, &quot;exp&quot;: 1707837637, &quot;iat&quot;: 1707830437, &quot;jti&quot;: &quot;8a657c60-968f-4d98-8a4c-22a7b4ecd333&quot;, &quot;authorities&quot;: [ &quot;xc_sysmanager&quot;, &quot;xc_sysmanager_company&quot;, &quot;xc_sysmanager_doc&quot;, &quot;xc_sysmanager_log&quot;, &quot;xc_teachmanager_course_list&quot; ], &quot;client_id&quot;: &quot;XcWebApp&quot;, &quot;token_type&quot;: &quot;Bearer&quot;} 三、gateway微服务代码1. 统一处理CORS问题language-java123456789101112131415161718192021222324252627282930313233343536@EnableWebFluxSecurity@Configurationpublic class SecurityConfig { //安全拦截配置 @Bean public SecurityWebFilterChain webFluxSecurityFilterChain(ServerHttpSecurity http) throws Exception { return http .cors(cors -&gt; cors.configurationSource(corsConfigurationSource())) .authorizeExchange(exchanges -&gt; exchanges .pathMatchers(&quot;/**&quot;).permitAll() .anyExchange().authenticated() ) .oauth2ResourceServer(oauth2 -&gt; oauth2.jwt(Customizer.withDefaults())) .csrf(ServerHttpSecurity.CsrfSpec::disable) .build(); } @Bean public CorsConfigurationSource corsConfigurationSource() { CorsConfiguration corsConfig = new CorsConfiguration(); corsConfig.addAllowedOriginPattern(&quot;*&quot;); // 允许任何源 corsConfig.addAllowedMethod(&quot;*&quot;); // 允许任何HTTP方法 corsConfig.addAllowedHeader(&quot;*&quot;); // 允许任何HTTP头 corsConfig.setAllowCredentials(true); // 允许证书（cookies） corsConfig.setMaxAge(3600L); // 预检请求的缓存时间（秒） UrlBasedCorsConfigurationSource source = new UrlBasedCorsConfigurationSource(); source.registerCorsConfiguration(&quot;/**&quot;, corsConfig); // 对所有路径应用这个配置 return source; }} 这里需要注意几点 书接上文，这里虽然用了oauth2.jwt(Customizer.withDefaults())，但实际上基于远程auth微服务开放的jwkSetEndpoint配置的JwtDecoder。 .cors(cors -&gt; cors.configurationSource(corsConfigurationSource()))一次性处理CORS问题。 四、content微服务代码1. controllerlanguage-java12345678910111213141516@PreAuthorize(&quot;hasAuthority('xc_teachmanager_course_list')&quot;) @ApiResponse(responseCode = &quot;200&quot;, description = &quot;Successfully retrieved user&quot;) @Operation(summary = &quot;查询课程信息列表&quot;) @PostMapping(&quot;/course/list&quot;) public PageResult&lt;CourseBase&gt; list( PageParams pageParams, @Parameter(description = &quot;请求具体内容&quot;) @RequestBody(required = false) QueryCourseParamsDto dto){ SecurityUtil.XcUser xcUser = SecurityUtil.getUser(); if (xcUser != null){ System.out.println(xcUser.getUsername()); System.out.println(xcUser.toString()); } return courseBaseInfoService.queryCourseBaseList(pageParams, dto); } 使用了@PreAuthorize(&quot;hasAuthority('xc_teachmanager_course_list')&quot;)修饰的controller资源。 2. SecurityConfiglanguage-java1234567891011121314151617181920212223242526272829303132333435363738@Configuration@EnableWebSecurity@EnableMethodSecuritypublic class SecurityConfig { //安全拦截配置 @Bean public SecurityFilterChain defaultFilterChain(HttpSecurity http) throws Exception { http .authorizeHttpRequests((authorize) -&gt; authorize .requestMatchers(&quot;/**&quot;).permitAll() .anyRequest().authenticated() ) .csrf(AbstractHttpConfigurer::disable) .oauth2ResourceServer(oauth -&gt; oauth.jwt(jwt -&gt; jwt.jwtAuthenticationConverter(jwtAuthenticationConverter()))); return http.build(); } private JwtAuthenticationConverter jwtAuthenticationConverter() { JwtAuthenticationConverter jwtConverter = new JwtAuthenticationConverter(); jwtConverter.setJwtGrantedAuthoritiesConverter(jwt -&gt; { // 从JWT的claims中提取权限信息 List&lt;String&gt; authorities = jwt.getClaimAsStringList(&quot;authorities&quot;); if (authorities == null) { return Collections.emptyList(); } return authorities.stream() .map(SimpleGrantedAuthority::new) .collect(Collectors.toList()); }); return jwtConverter; }} 需要注意几点 使用@EnableMethodSecurity让@PreAuthorize生效 和gateway一样，需要基于远程auth微服务开放的jwkSetEndpoint配置JwtDecoder。 指定JwtAuthenticationConverter ，让anyRequest().authenticated()需要验证的请求，除了完成默认的JWT验证外，还需要完成JwtAuthenticationConverter 指定逻辑。 JwtAuthenticationConverter 中将JWT的authorities部分形成数组后写入GrantedAuthorities，这正是spring security6用于校验@PreAuthorize的字段。 3. 解析JWT Utilslanguage-java12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667@Slf4jpublic class SecurityUtil { public static XcUser getUser(){ Authentication authentication = SecurityContextHolder.getContext().getAuthentication(); if (authentication == null){ return null; } if (authentication instanceof JwtAuthenticationToken) { JwtAuthenticationToken jwtAuth = (JwtAuthenticationToken) authentication; System.out.println(jwtAuth); Map&lt;String, Object&gt; tokenAttributes = jwtAuth.getTokenAttributes(); System.out.println(tokenAttributes); Object sub = tokenAttributes.get(&quot;sub&quot;); return JSON.parseObject(sub.toString(), XcUser.class); } return null; } @Data public static class XcUser implements Serializable { private static final long serialVersionUID = 1L; private String id; private String username; private String password; private String salt; private String name; private String nickname; private String wxUnionid; private String companyId; /** * 头像 */ private String userpic; private String utype; private LocalDateTime birthday; private String sex; private String email; private String cellphone; private String qq; /** * 用户状态 */ private String status; private LocalDateTime createTime; private LocalDateTime updateTime; }} 把JWT的信息解析回XcUser ，相当于用户携带JWT访问后端，后端可以根据JWT获取此用户的信息。当然，你可以尽情的自定义，扩展。 4. 总结当用户携带JWT访问需要权限的资源时，现在可以正常的校验权限了。 五、一些坑 写RegisteredClient时注册那么多redirectUri是因为debug了很久，才发现获取授权码和获取JWT时，redirect_uri参数需要一致。 cors问题，spring secuity6似乎会一开始直接默认拒绝cors，导致跨域请求刚到gateway就寄了，到不了content微服务，即使content微服务配置了CORS的处理方案，也无济于事。","link":"/Hexo/2024/02/13/2024-H1/2024-02-13-23-00-26/"},{"title":"SpringBoot后端Long数据传到前端js精度损失问题","text":"方案一、修改后端在对应的字段上添加注解，将Long转为String后传输。 language-java12@JsonFormat(shape = JsonFormat.Shape.STRING) private Long payNo; 方案二、修改前端在js对应的结果接收上使用BigInt。 language-js123456xxx().then((res) =&gt; { if(res){ this.payNo = String(BigInt(res.payNo)) }","link":"/Hexo/2024/02/16/2024-H1/2024-02-16-10-06-42/"},{"title":"微服务OAuth 2.1认证授权可行性方案(Spring Security 6)","text":"一、背景Oauth2停止维护，基于OAuth 2.1 和 OpenID Connect 1.0的Spring Authorization Server模块独立于SpringCloud。 本文开发环境如下： Version Java 17 SpringCloud 2023.0.0 SpringBoot 3.2.1 Spring Authorization Server 1.2.1 Spring Security 6.2.1 mysql 8.2.0 https://spring.io/projects/spring-security#learnhttps://spring.io/projects/spring-authorization-server#learn 二、微服务架构介绍一个认证服务器（也是一个微服务），专门用于颁发JWT。一个网关（也是一个微服务），用于白名单判断和JWT校验。若干微服务。 本文的关键在于以下几点： 搭建认证服务器 网关白名单判断 网关验证JWT 认证服务器如何共享公钥，让其余微服务有JWT自校验的能力。 三、认证服务器这里是官方文档https://spring.io/projects/spring-authorization-server#learn基本上跟着Getting Started写完就可以。 1. 数据库创建新建一个数据库xc_users。然后执行jar里自带的三个sql。 这一步官方并没有给出，大概因为可以使用内存存储，在简单demo省去了持久化。不建立数据库可能也是可行的，我没试过。 2. 新建模块新建一个auth模块，作为认证服务器。 3. 导入依赖和配置language-xml123456789101112&lt;dependency&gt; &lt;groupId&gt;com.mysql&lt;/groupId&gt; &lt;artifactId&gt;mysql-connector-j&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-oauth2-authorization-server&lt;/artifactId&gt; &lt;/dependency&gt; language-yaml1234567891011121314server: servlet: context-path: /auth port: 63070spring: application: name: auth-service profiles: active: dev datasource: driver-class-name: com.mysql.cj.jdbc.Driver url: jdbc:mysql://192.168.101.65:3306/xc_users?serverTimezone=UTC&amp;userUnicode=true&amp;useSSL=false&amp; username: root password: 1009 4. 安全认证配置类language-java1234@Configuration@EnableWebSecuritypublic class AuthServerSecurityConfig { } 里面包含诸多内容，有来自Spring Security的，也有来自的Spring Authorization Server的。 UserDetailsService 的实例，用于检索用户进行身份验证。 language-java12345678910@Beanpublic UserDetailsService userDetailsService() { UserDetails userDetails = User .withUsername(&quot;lisi&quot;) .password(&quot;456&quot;) .roles(&quot;read&quot;) .build(); return new InMemoryUserDetailsManager(userDetails);} 密码编码器（可选，本文不用） language-java12345678 @Bean public PasswordEncoder passwordEncoder() { // 密码为明文方式 return NoOpPasswordEncoder.getInstance(); // 或使用 BCryptPasswordEncoder// return new BCryptPasswordEncoder(); } 协议端点的 Spring Security 过滤器链 language-java123456789101112131415161718192021222324@Bean @Order(1) public SecurityFilterChain authorizationServerSecurityFilterChain(HttpSecurity http) throws Exception { OAuth2AuthorizationServerConfiguration.applyDefaultSecurity(http); http.getConfigurer(OAuth2AuthorizationServerConfigurer.class) .oidc(Customizer.withDefaults()); // Enable OpenID Connect 1.0 http // Redirect to the login page when not authenticated from the // authorization endpoint .exceptionHandling((exceptions) -&gt; exceptions .defaultAuthenticationEntryPointFor( new LoginUrlAuthenticationEntryPoint(&quot;/login&quot;), new MediaTypeRequestMatcher(MediaType.TEXT_HTML) ) ) // Accept access tokens for User Info and/or Client Registration .oauth2ResourceServer((resourceServer) -&gt; resourceServer .jwt(Customizer.withDefaults())); return http.build(); } 用于身份验证的 Spring Security 过滤器链。至于哪些要校验身份，哪些不用，根据自己需求写。 language-java123456789101112131415161718192021222324@Bean @Order(2) public SecurityFilterChain defaultFilterChain(HttpSecurity http) throws Exception { http .authorizeHttpRequests((authorize) -&gt; authorize .requestMatchers(new AntPathRequestMatcher(&quot;/actuator/**&quot;)).permitAll() .requestMatchers(new AntPathRequestMatcher(&quot;/login&quot;)).permitAll() .requestMatchers(new AntPathRequestMatcher(&quot;/oauth2/**&quot;)).permitAll() .requestMatchers(new AntPathRequestMatcher(&quot;/**/*.html&quot;)).permitAll() .requestMatchers(new AntPathRequestMatcher(&quot;/**/*.json&quot;)).permitAll() .requestMatchers(new AntPathRequestMatcher(&quot;/auth/**&quot;)).permitAll() .anyRequest().authenticated() ) .formLogin(Customizer.withDefaults()) .oauth2ResourceServer(oauth2 -&gt; oauth2 .jwt(jwt -&gt; jwt .jwtAuthenticationConverter(jwtAuthenticationConverter()) ) ); return http.build(); } 自定义验证转化器（可选） language-java1234567private JwtAuthenticationConverter jwtAuthenticationConverter() { JwtAuthenticationConverter jwtConverter = new JwtAuthenticationConverter(); // 此处可以添加自定义逻辑来提取JWT中的权限等信息 // jwtConverter.setJwtGrantedAuthoritiesConverter(...); return jwtConverter;} 用于管理客户端的 RegisteredClientRepository 实例 language-java123456789101112131415161718192021222324252627282930 @Bean public RegisteredClientRepository registeredClientRepository() { RegisteredClient registeredClient = RegisteredClient.withId(UUID.randomUUID().toString()) .clientId(&quot;XcWebApp&quot;)// .clientSecret(&quot;{noop}XcWebApp&quot;) .clientSecret(&quot;XcWebApp&quot;) .clientAuthenticationMethod(ClientAuthenticationMethod.CLIENT_SECRET_BASIC) .authorizationGrantType(AuthorizationGrantType.AUTHORIZATION_CODE) .authorizationGrantType(AuthorizationGrantType.REFRESH_TOKEN) .authorizationGrantType(AuthorizationGrantType.CLIENT_CREDENTIALS) .redirectUri(&quot;http://www.51xuecheng.cn&quot;)// .postLogoutRedirectUri(&quot;http://localhost:63070/login?logout&quot;) .scope(&quot;all&quot;) .scope(OidcScopes.OPENID) .scope(OidcScopes.PROFILE) .scope(&quot;message.read&quot;) .scope(&quot;message.write&quot;) .scope(&quot;read&quot;) .scope(&quot;write&quot;) .clientSettings(ClientSettings.builder().requireAuthorizationConsent(true).build()) .tokenSettings(TokenSettings.builder() .accessTokenTimeToLive(Duration.ofHours(2)) // 设置访问令牌的有效期 .refreshTokenTimeToLive(Duration.ofDays(3)) // 设置刷新令牌的有效期 .reuseRefreshTokens(true) // 是否重用刷新令牌 .build()) .build(); return new InMemoryRegisteredClientRepository(registeredClient); } 用于对访问令牌进行签名的实例 language-java12345678910111213141516171819202122232425262728@Beanpublic JWKSource&lt;SecurityContext&gt; jwkSource() { KeyPair keyPair = generateRsaKey(); RSAPublicKey publicKey = (RSAPublicKey) keyPair.getPublic(); RSAPrivateKey privateKey = (RSAPrivateKey) keyPair.getPrivate(); RSAKey rsaKey = new RSAKey.Builder(publicKey) .privateKey(privateKey) .keyID(UUID.randomUUID().toString()) .build(); JWKSet jwkSet = new JWKSet(rsaKey); return new ImmutableJWKSet&lt;&gt;(jwkSet);}private static KeyPair generateRsaKey() { KeyPair keyPair; try { KeyPairGenerator keyPairGenerator = KeyPairGenerator.getInstance(&quot;RSA&quot;); keyPairGenerator.initialize(2048); keyPair = keyPairGenerator.generateKeyPair(); } catch (Exception ex) { throw new IllegalStateException(ex); } return keyPair;} 用于解码签名访问令牌的JwtDecoder 实例 language-java12345@Beanpublic JwtDecoder jwtDecoder(JWKSource&lt;SecurityContext&gt; jwkSource) { return OAuth2AuthorizationServerConfiguration.jwtDecoder(jwkSource);} 用于配置Spring Authorization Server 的 AuthorizationServerSettings 实例 language-java12345@Beanpublic AuthorizationServerSettings authorizationServerSettings() { return AuthorizationServerSettings.builder().build();} 这里可以设置各种端点的路径，默认路径点开builder()即可看到，如下 language-java1234567891011121314public static Builder builder() { return new Builder() .authorizationEndpoint(&quot;/oauth2/authorize&quot;) .deviceAuthorizationEndpoint(&quot;/oauth2/device_authorization&quot;) .deviceVerificationEndpoint(&quot;/oauth2/device_verification&quot;) .tokenEndpoint(&quot;/oauth2/token&quot;) .jwkSetEndpoint(&quot;/oauth2/jwks&quot;) .tokenRevocationEndpoint(&quot;/oauth2/revoke&quot;) .tokenIntrospectionEndpoint(&quot;/oauth2/introspect&quot;) .oidcClientRegistrationEndpoint(&quot;/connect/register&quot;) .oidcUserInfoEndpoint(&quot;/userinfo&quot;) .oidcLogoutEndpoint(&quot;/connect/logout&quot;); } 这里我必须吐槽一下，qnmd /.well-known/jwks.json，浪费我一下午。获取公钥信息的端点现在已经替换成了/oauth2/jwks。 四、认证服务器测试基本上跟着Getting Started走就行。只不过端点的变动相较于Oauth2很大，还有使用方法上不同。 在配置RegisteredClient的时候，我们设置了三种GrantType，这里只演示两种AUTHORIZATION_CODE和CLIENT_CREDENTIALS。 1. AUTHORIZATION_CODE（授权码模式）1. 获取授权码用浏览器打开以下网址， language-txt1http://localhost:63070/auth/oauth2/authorize?client_id=XcWebApp&amp;response_type=code&amp;scope=all&amp;redirect_uri=http://www.51xuecheng.cn 对应oauth2/authorize端点，后面的参数和当时设置RegisteredClient 保持对应就行。response_type一定是code。进入到登陆表单，输入lisi - 456登陆。 选择all，同意请求。 url被重定向到http://www.51xuecheng.cn，并携带一个code，这就是授权码。 language-txt1http://www.51xuecheng.cn/?code=9AexK_KFH1m3GiNBKsc0FU2KkedM2h_6yR-aKF-wPnpQT5USKLTqoZiSkHC3GUvt-56_ky-E3Mv5LbMeH9uyd-S1UV6kfJO6znqAcCAF43Yo4ifxTAQ8opoPJTjLIRUC 2. 获取JWT使用apifox演示，postman，idea-http都可以。向localhost:63070/auth服务的/oauth2/token端点发送Post请求，同时需要携带认证信息。认证信息可以如图所填的方法，也可以放到Header中，具体做法是将客户端ID和客户端密码用冒号（:）连接成一个字符串，进行Base64编码放入HTTP请求的Authorization头部中，前缀为Basic 。比如Authorization: Basic bXlDbGllbnRJZDpteUNsaWVudFNlY3JldA== 得到JWT 2. CLIENT_CREDENTIALS(客户端凭证模式)不需要授权码，直接向localhost:63070/auth服务的/oauth2/token端点发送Post请求，同时需要携带认证信息。 五、Gateway至于gateway基础搭建步骤和gateway管理的若干微服务本文不做指导。 相较于auth模块（也就是Authorization Server），gateway的角色是Resource Server。 1. 引入依赖language-xml12345678&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-oauth2-resource-server&lt;/artifactId&gt;&lt;/dependency&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-security&lt;/artifactId&gt;&lt;/dependency&gt; 2. 添加白名单文件在resource下添加security-whitelist.properties文件。写入以下内容 language-properties123/auth/**=????/content/open/**=??????????/media/open/**=?????????? 3. 全局过滤器在全局过滤器中，加载白名单，然后对请求进行判断。 language-java12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061@Component@Slf4jpublic class GatewayAuthFilter implements GlobalFilter, Ordered { //白名单 private static List&lt;String&gt; whitelist = null; static { //加载白名单 try ( InputStream resourceAsStream = GatewayAuthFilter.class.getResourceAsStream(&quot;/security-whitelist.properties&quot;); ) { Properties properties = new Properties(); properties.load(resourceAsStream); Set&lt;String&gt; strings = properties.stringPropertyNames(); whitelist= new ArrayList&lt;&gt;(strings); } catch (Exception e) { log.error(&quot;加载/security-whitelist.properties出错:{}&quot;,e.getMessage()); e.printStackTrace(); } } @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) { String requestUrl = exchange.getRequest().getPath().value(); log.info(&quot;请求={}&quot;,requestUrl); AntPathMatcher pathMatcher = new AntPathMatcher(); //白名单放行 for (String url : whitelist) { if (pathMatcher.match(url, requestUrl)) { return chain.filter(exchange); } } } private Mono&lt;Void&gt; buildReturnMono(String error, ServerWebExchange exchange) { ServerHttpResponse response = exchange.getResponse(); String jsonString = JSON.toJSONString(new RestErrorResponse(error)); byte[] bits = jsonString.getBytes(StandardCharsets.UTF_8); DataBuffer buffer = response.bufferFactory().wrap(bits); response.setStatusCode(HttpStatus.UNAUTHORIZED); response.getHeaders().add(&quot;Content-Type&quot;, &quot;application/json;charset=UTF-8&quot;); return response.writeWith(Mono.just(buffer)); } @Override public int getOrder() { return 0; }} 4. 获取远程JWKS在yml配置中添加jwk-set-uri属性。 language-yml123456spring: security: oauth2: resourceserver: jwt: jwk-set-uri: http://localhost:63070/auth/oauth2/jwks 新建配置类，自动注入JwtDecoder。 language-java123456789101112@Configurationpublic class JwtDecoderConfig { @Value(&quot;${spring.security.oauth2.resourceserver.jwt.jwk-set-uri}&quot;) String jwkSetUri; @Bean public JwtDecoder jwtDecoderLocal() { return NimbusJwtDecoder.withJwkSetUri(jwkSetUri).build(); }} 5. 校验JWT在全局过滤器中补全逻辑。 language-java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384@Component@Slf4jpublic class GatewayAuthFilter implements GlobalFilter, Ordered { @Lazy @Autowired private JwtDecoder jwtDecoderLocal; @Override public Mono&lt;Void&gt; filter(ServerWebExchange exchange, GatewayFilterChain chain) { String requestUrl = exchange.getRequest().getPath().value(); log.info(&quot;请求={}&quot;,requestUrl); AntPathMatcher pathMatcher = new AntPathMatcher(); //白名单放行 for (String url : whitelist) { if (pathMatcher.match(url, requestUrl)) { return chain.filter(exchange); } } //检查token是否存在 String token = getToken(exchange); log.info(&quot;token={}&quot;,token); if (StringUtils.isBlank(token)) { return buildReturnMono(&quot;没有携带Token,没有认证&quot;,exchange); }// return chain.filter(exchange); try { Jwt jwt = jwtDecoderLocal.decode(token); // 如果没有抛出异常，则表示JWT有效 // 此时，您可以根据需要进一步检查JWT的声明 log.info(&quot;token有效期至:{}&quot;, formatInstantTime(jwt.getExpiresAt())); return chain.filter(exchange); } catch (JwtValidationException e) { log.info(&quot;token验证失败:{}&quot;,e.getMessage()); return buildReturnMono(&quot;认证token无效&quot;,exchange); } } /** * 从请求头Authorization中获取token */ private String getToken(ServerWebExchange exchange) { String tokenStr = exchange.getRequest().getHeaders().getFirst(&quot;Authorization&quot;); if (StringUtils.isBlank(tokenStr)) { return null; } String token = tokenStr.split(&quot; &quot;)[1]; if (StringUtils.isBlank(token)) { return null; } return token; } /** * 格式化Instant时间 * * @param expiresAt 在到期 * @return {@link String} */ public String formatInstantTime(Instant expiresAt) { // 将Instant转换为系统默认时区的LocalDateTime LocalDateTime dateTime = LocalDateTime.ofInstant(expiresAt, ZoneId.systemDefault()); // 定义日期时间的格式 DateTimeFormatter formatter = DateTimeFormatter.ofPattern(&quot;yyyy-MM-dd HH:mm:ss&quot;); // 格式化日期时间并打印 return dateTime.format(formatter); }} 6. 测试（如何携带JWT）携带一个正确的JWT向gateway发送请求。把JWT写到Header的Authorization字段中，添加前缀Bearer（用空格隔开），向gateway微服务所在地址发送请求。 gateway日志输出。 六、后记颁发JWT都归一个认证服务器管理，校验JWT都归Gateway管理，至于授权，则由各个微服务自己定义。耦合性低、性能较好。 关于授权，可以接着这篇文章。微服务OAuth 2.1认证授权Demo方案(Spring Security 6)","link":"/Hexo/2024/02/13/2024-H1/2024-02-13-23-03-29/"},{"title":"Spring AMQP(3.1.1)设置ConfirmCallback和ReturnsCallback","text":"环境如下 Version SpringBoot 3.2.1 spring-amqp 3.1.1 RabbitMq 3-management 一、起因老版本的spring-amqp在CorrelationData上设置ConfirmCallback。但是今天却突然发现correlationData.getFuture()没有addCallback函数了。 查询文档和帖子后，发现ConfirmCallback和ReturnsCallback都需要在RabbitTemplate中设置，同时ConfirmCallback中默认无法得到消息内容，如果想在ConfirmCallback中把消息内容存到数据库等地方进行记录，怎么办呢？ 参考手册 Spring AMQP 3.1.1 Spring AMQP 3.1.1 API 二、代码1. 定义exchange和queuelanguage-java12345678910111213141516171819202122232425262728293031323334@Slf4j@Configurationpublic class PayNotifyConfig{ //交换机 public static final String PAYNOTIFY_EXCHANGE_FANOUT = &quot;paynotify_exchange_fanout&quot;; //支付通知队列 public static final String PAYNOTIFY_QUEUE = &quot;paynotify_queue&quot;; //支付结果通知消息类型 public static final String MESSAGE_TYPE = &quot;payresult_notify&quot;; //声明交换机，且持久化 @Bean(PAYNOTIFY_EXCHANGE_FANOUT) public FanoutExchange paynotify_exchange_fanout() { // 三个参数：交换机名称、是否持久化、当没有queue与其绑定时是否自动删除 return new FanoutExchange(PAYNOTIFY_EXCHANGE_FANOUT, true, false); } //支付通知队列,且持久化 @Bean(PAYNOTIFY_QUEUE) public Queue paynotify_queue() { return QueueBuilder.durable(PAYNOTIFY_QUEUE).build(); } //交换机和支付通知队列绑定 @Bean public Binding binding_paynotify_queue(@Qualifier(PAYNOTIFY_QUEUE) Queue queue, @Qualifier(PAYNOTIFY_EXCHANGE_FANOUT) FanoutExchange exchange) { return BindingBuilder.bind(queue).to(exchange); }} 2. RabbitTemplate在上面的类中继续添加RabbitTemplate ，并设置ConfirmCallback和ReturnsCallback。 language-java1234567891011121314151617181920212223242526272829303132333435363738@Bean public RabbitTemplate rabbitTemplate(final ConnectionFactory connectionFactory) { final RabbitTemplate rabbitTemplate = new RabbitTemplate(connectionFactory); //设置confirm callback rabbitTemplate.setConfirmCallback((correlationData, ack, cause) -&gt; { String body = &quot;1&quot;; if (correlationData instanceof EnhancedCorrelationData) { body = ((EnhancedCorrelationData) correlationData).getBody(); } if (ack) { //消息投递到exchange log.debug(&quot;消息发送到exchange成功:correlationData={},message_id={} &quot;, correlationData, body); System.out.println(&quot;消息发送到exchange成功:correlationData={},message_id={}&quot;+correlationData+body); } else { log.debug(&quot;消息发送到exchange失败:cause={},message_id={}&quot;,cause, body); System.out.println(&quot;消息发送到exchange失败:cause={},message_id={}&quot;+cause+body); } }); //设置return callback rabbitTemplate.setReturnsCallback(returned -&gt; { Message message = returned.getMessage(); int replyCode = returned.getReplyCode(); String replyText = returned.getReplyText(); String exchange = returned.getExchange(); String routingKey = returned.getRoutingKey(); // 投递失败，记录日志 log.error(&quot;消息发送失败，应答码{}，原因{}，交换机{}，路由键{},消息{}&quot;, replyCode, replyText, exchange, routingKey, message.toString()); }); return rabbitTemplate; } 3. EnhancedCorrelationData原始的CorrelationData，目前已经无法从中获取消息内容，也就是说现在的ConfirmCallback无法获取到消息的内容，因为设计上只关注是否投递到exchange成功。如果需要在ConfirmCallback中获取消息的内容，需要扩展这个类，并在发消息的时候，放入自定义数据。 language-java12345678910111213141516public class EnhancedCorrelationData extends CorrelationData { private final String body; public EnhancedCorrelationData(String id, String body) { super(id); this.body = body; } public String getBody() { return body; }} 4. 发送消息在EnhancedCorrelationData把消息本身放进去，或者如果你有表记录消息，你可以只放入其id。这样触发ConfirmCallback的时候，就可以获取消息内容。 language-java123456789public void notifyPayResult() { String message = &quot;TEST Message&quot;; Message message1 = MessageBuilder.withBody(message.getBytes(StandardCharsets.UTF_8)) .setDeliveryMode(MessageDeliveryMode.PERSISTENT) .build(); CorrelationData correlationData = new EnhancedCorrelationData(UUID.randomUUID().toString(), message.toString()); rabbitTemplate.convertAndSend(PayNotifyConfig.PAYNOTIFY_EXCHANGE_FANOUT,&quot;&quot;, message1, correlationData); }","link":"/Hexo/2024/02/16/2024-H1/2024-02-16-23-01-49/"},{"title":"Redis之缓存雪崩问题解决方案","text":"一、书接上文Redis之缓存穿透问题解决方案实践SpringBoot3+Docker 二、介绍缓存雪崩，指大量的缓存失效，大量的请求又同时落在数据库。主要的一种诱因是key设置的过期时间都一样。 三、解决方案1. 锁加锁，每次只让一个线程可以访问数据库，随后存入缓存。性能太差。 2. 不同的过期时间最简单有效的解决办法是设置不同的过期时间。比如 language-java12int timeout = 10 + new Random().nextInt(20);redisTemplate.opsForValue().set(key, JSON.toJSONString(coursePublish), timeout, TimeUnit.SECONDS); 3. 缓存预热和定时任务使用缓存预热，把数据提前放入缓存，然后根据过期时间，发布合理的定时任务，主动去更新缓存。缓存预热参考代码如下。 language-java1234567891011121314151617181920@Componentpublic class RedisHandler implements InitializingBean { @Autowired RedisTemplate redisTemplate; @Autowired CoursePublishMapper coursePublishMapper; @Override public void afterPropertiesSet() throws Exception { List&lt;CoursePublish&gt; coursePublishList = coursePublishMapper.selectList(new LambdaQueryWrapper&lt;CoursePublish&gt;()); //缓存预热 coursePublishList.forEach(coursePublish -&gt; { String key = &quot;content:course:publish:&quot; + coursePublish.getId(); redisTemplate.opsForValue().set(key, JSON.toJSONString(coursePublish)); }); }} 至于定时任务，可以使用xxl-job。具体使用方法，可以参考这个文章Docker部署xxl-job调度器并结合SpringBoot测试","link":"/Hexo/2024/02/21/2024-H1/2024-02-21-16-06-52/"},{"title":"Redis之缓存穿透问题解决方案实践SpringBoot3+Docker","text":"一、介绍当一种请求，总是能越过缓存，调用数据库，就是缓存穿透。 比如当请求一个数据库没有的数据，那么缓存也不会有，然后就一直请求，甚至高并发去请求，对数据库压力会增大。 二、方案介绍 如果key具有某种规则，那么可以对key增加校验机制，不符合直接返回。 Redisson布隆过滤器 逻辑修改，当数据库没有此数据，以null为value，也插入redis缓存，但设置较短的过期时间。 三、Redis Docker部署docker-compose示例如下，redis.conf从这里下载 language-yml12345678redis: container_name: redis image: redis:7.2 volumes: - ./redis/redis.conf:/usr/local/etc/redis/redis.conf ports: - &quot;6379:6379&quot; command: [ &quot;redis-server&quot;, &quot;/usr/local/etc/redis/redis.conf&quot; ] 四、SpringBoot3 Base代码1. 依赖配置language-xml1234567891011121314151617&lt;!-- redis --&gt;&lt;dependency&gt; &lt;groupId&gt;org.springframework.boot&lt;/groupId&gt; &lt;artifactId&gt;spring-boot-starter-data-redis&lt;/artifactId&gt; &lt;/dependency&gt; &lt;!-- redis 连接线程池 --&gt; &lt;dependency&gt; &lt;groupId&gt;org.apache.commons&lt;/groupId&gt; &lt;artifactId&gt;commons-pool2&lt;/artifactId&gt; &lt;version&gt;2.11.1&lt;/version&gt; &lt;/dependency&gt; &lt;!-- redisson --&gt; &lt;dependency&gt; &lt;groupId&gt;org.redisson&lt;/groupId&gt; &lt;artifactId&gt;redisson&lt;/artifactId&gt; &lt;version&gt;3.24.3&lt;/version&gt; &lt;/dependency&gt; language-yaml1234567891011121314spring: data: redis: host: 192.168.101.65 # Redis服务器的主机名或IP地址 port: 6379 # Redis服务器的端口号 password: # 用于连接Redis服务器的密码 database: 0 # 要连接的Redis数据库的索引号 lettuce: pool: max-active: 20 # 连接池中最大的活跃连接数 max-idle: 10 # 连接池中最大的空闲连接数 min-idle: 0 # 连接池中最小的空闲连接数 timeout: 10000 # 连接超时时间（毫秒） lock-watchdog-timeout: 100 # Redisson的分布式锁的看门狗超时时间（毫秒） 2. 基本代码要演示的代码很简单，就是一个携带courseId请求过来，调用下面的service函数，然后查询数据库。 language-java12345@Override public CoursePublish getCoursePublish(Long courseId) { return coursePublishMapper.selectById(courseId); } 当我们使用redis改造时，基本代码如下 language-java12345678910111213141516171819202122@Override public CoursePublish getCoursePublishCache(Long courseId) { String key = &quot;content:course:publish:&quot; + courseId; //先查询redis Object object = redisTemplate.opsForValue().get(key); if (object != null){ String string = object.toString(); CoursePublish coursePublish = JSON.parseObject(string, CoursePublish.class); return coursePublish; }else { //后查询数据库 CoursePublish coursePublish = getCoursePublish(courseId); if (coursePublish != null){ redisTemplate.opsForValue().set(key, JSON.toJSONString(coursePublish)); } return coursePublish; } } 五、缓存优化代码1. 校验机制我这里的id没规则，所以加不了，跳过。 2. 布隆过滤器读取yaml配置 language-java123456789101112@Data@Component@ConfigurationProperties(prefix = &quot;spring.data.redis&quot;)public class RedisProperties { private String host; private int port; private String password; private int database; private int lockWatchdogTimeout;} 配置RedissonClient language-java1234567891011121314151617181920212223242526272829303132@Slf4j@Configurationpublic class RedissionConfig { @Autowired private RedisProperties redisProperties; @Bean public RedissonClient redissonClient() { RedissonClient redissonClient; Config config = new Config(); //starter依赖进来的redisson要以redis://开头，其他不用 String url = &quot;redis://&quot;+ redisProperties.getHost() + &quot;:&quot; + redisProperties.getPort(); config.useSingleServer().setAddress(url) //.setPassword(redisProperties.getPassword()) .setDatabase(redisProperties.getDatabase()); try { redissonClient = Redisson.create(config); return redissonClient; } catch (Exception e) { log.error(&quot;RedissonClient init redis url:[{}], Exception:&quot;, url, e); return null; } }} 把布隆过滤器加到service，如下 language-java123456789101112131415161718192021222324252627282930313233343536373839404142434445private RBloomFilter&lt;String&gt; bloomFilter; @PostConstruct public void init(){ //初始化布隆过滤器 bloomFilter = redissonClient.getBloomFilter(&quot;bloom-filter&quot;); bloomFilter.tryInit(100, 0.003); List&lt;CoursePublish&gt; coursePublishList = coursePublishMapper.selectList(new LambdaQueryWrapper&lt;CoursePublish&gt;()); coursePublishList.forEach(coursePublish -&gt; { String key = &quot;content:course:publish:&quot; + coursePublish.getId(); bloomFilter.add(key); }); } @Override public CoursePublish getCoursePublishCache(Long courseId) { String key = &quot;content:course:publish:&quot; + courseId; //布隆过滤器 boolean contains = bloomFilter.contains(key); if (!contains){ return null; } //先查询redis Object object = redisTemplate.opsForValue().get(key); if (object != null){ String string = object.toString(); CoursePublish coursePublish = JSON.parseObject(string, CoursePublish.class); return coursePublish; }else { //后查询数据库 CoursePublish coursePublish = getCoursePublish(courseId); if (coursePublish != null){ bloomFilter.add(key); redisTemplate.opsForValue().set(key, JSON.toJSONString(coursePublish)); } return coursePublish; } } 3. 逻辑优化当数据库没有此数据，以null为value，也插入redis缓存，但设置较短的过期时间。 language-java1234567891011//后查询数据库CoursePublish coursePublish = getCoursePublish(courseId);if (coursePublish != null) { bloomFilter.add(key); redisTemplate.opsForValue().set(key, JSON.toJSONString(coursePublish));}else { redisTemplate.opsForValue().set(key, JSON.toJSONString(coursePublish), 10, TimeUnit.SECONDS);}return coursePublish;","link":"/Hexo/2024/02/21/2024-H1/2024-02-21-17-46-46/"},{"title":"Redis之缓存击穿问题解决方案","text":"一、书接上文Redis之缓存雪崩问题解决方案 二、介绍缓存击穿就是大量并发访问同一个热点数据，一旦这个热点数据缓存失效，则请求压力都来到数据库。 三、解决方案1. 单例双检锁language-java123456789101112131415161718192021222324252627282930313233343536373839404142434445@Override public CoursePublish getCoursePublishCache(Long courseId) { String key = &quot;content:course:publish:&quot; + courseId; //布隆过滤器 boolean contains = bloomFilter.contains(key); if (!contains){ return null; } //先查询redis Object object = redisTemplate.opsForValue().get(key); if (object != null){ String string = object.toString(); CoursePublish coursePublish = JSON.parseObject(string, CoursePublish.class); return coursePublish; }else { //后查询数据库 //加锁，防止缓存击穿 synchronized (this){ //单例双检锁 object = redisTemplate.opsForValue().get(key); if (object != null){ String string = object.toString(); CoursePublish coursePublish = JSON.parseObject(string, CoursePublish.class); return coursePublish; } CoursePublish coursePublish = getCoursePublish(courseId); if (coursePublish != null) { bloomFilter.add(key); redisTemplate.opsForValue().set(key, JSON.toJSONString(coursePublish)); } else { int timeout = 10 + new Random().nextInt(20); redisTemplate.opsForValue().set(key, JSON.toJSONString(coursePublish), timeout, TimeUnit.SECONDS); } return coursePublish; } } } 2. 缓存预热和定时任务使用缓存预热，把数据提前放入缓存，然后根据过期时间，发布合理的定时任务，主动去更新缓存，让热点数据永不过期。","link":"/Hexo/2024/02/21/2024-H1/2024-02-21-17-47-18/"},{"title":"Java - 锁","text":"乐观锁分为三个阶段：数据读取、写入校验、数据写入。 假设数据一般情况下不会造成冲突，只有在数据进行提交更新时，才会正式对数据的冲突与否进行检测，如果发现冲突了，则返回错误信息，让用户决定如何去做。fail-fast机制。 悲观锁正如其名，它指对数据被外界（可能是本机的其他事务，也可能是来自其它服务器的事务处理）的修改持保守态度。在整个数据处理过程中，将数据处于锁定状态。悲观锁大多数情况下依靠数据库的锁机制实现，以保证操作最大程度的独占性。如果加锁的时间过长，其他用户长时间无法访问，影响程序的并发访问性，同时这样对数据库性能开销影响也很大，特别是长事务而言，这样的开销往往无法承受。 分布式锁分布式集群中，对锁接口QPS性能要求很高，单台服务器满足不了要求，可以考虑将锁服务部署在独立的分布式系统中，比如借助分布式缓存来实现。 可重入锁可重入锁，也叫做递归锁，是指在同一个线程在调外层方法获取锁的时候，再进入内层方法会自动获取锁。ReentrantLock 和synchronized 都是 可重入锁。可重入锁的一个好处是可一定程度避免死锁。 这对于设计复杂的程序或库来说是非常重要的。考虑下面这种情况： language-java123456789101112131415161718192021222324252627282930class SomeClass { private final Lock lock = new ReentrantLock(); public void methodA() { lock.lock(); try { // 一些代码 methodB(); // 在 methodA 中调用 methodB // 更多代码 } finally { lock.unlock(); } } public void methodB() { lock.lock(); try { // 一些代码 } finally { lock.unlock(); } }} 在这个例子中，methodA() 和 methodB() 都使用了同一把锁。如果 ReentrantLock 不是可重入的，那么当线程在 methodA() 中已经获取了锁后，再次尝试在 methodB() 中获取锁时，就会导致死锁，因为锁已经被同一个线程持有，而不是其他线程。 因此，”可重入”锁允许在同一线程中多次获取同一把锁，这样就能避免死锁，并且简化了程序设计，因为无需担心方法之间的调用顺序是否会导致死锁。 尽管在您提出的例子中看起来似乎并没有太大意义，但在实际的程序设计中，”可重入”锁确实是一个非常重要的概念。 自旋锁自旋锁是一种基于忙等待（busy-waiting）的锁，它在获取锁时会不断地循环尝试获取锁，而不是让线程进入睡眠状态。自旋锁的主要特点是在锁被其他线程占用时，当前线程会不断地尝试获取锁，直到获取到锁为止，而不会释放 CPU 控制权。 自旋锁适用于以下情况： 锁被持有的时间短：如果锁被持有的时间很短，那么等待锁的线程不需要进入睡眠状态，使用自旋锁可以避免线程切换的开销。 多核处理器：在多核处理器上，一个线程在自旋等待锁的同时，其他线程可以继续执行，因此自旋锁在多核处理器上能够充分利用 CPU 时间，提高并发性能。 高并发场景：在高并发的情况下，锁的竞争可能会很激烈，自旋锁可以减少线程的阻塞时间，提高系统的响应速度。 然而，自旋锁也有一些缺点： 等待时间过长可能会浪费 CPU 资源：如果锁的竞争很激烈，导致线程不断自旋等待锁的释放，可能会浪费大量的 CPU 时间。 不适用于长时间持有锁的情况：如果锁被持有的时间较长，自旋锁会导致其他线程长时间等待，影响系统的响应性能。 因此，在使用自旋锁时需要权衡利弊，根据具体的场景来决定是否使用自旋锁。通常情况下，自旋锁适用于锁被持有时间短、锁的竞争不激烈的情况下，能够有效提高并发性能。 当然可以。以下是一个简单的示例，演示了如何使用自旋锁来保护一个共享资源： language-java123456789101112131415161718192021import java.util.concurrent.atomic.AtomicBoolean;public class SpinLock { private AtomicBoolean locked = new AtomicBoolean(false); public void lock() { // 不断尝试获取锁，直到成功为止 while (!locked.compareAndSet(false, true)) { // 自旋等待，不做其他事情，持续尝试获取锁 } } public void unlock() { // 释放锁 locked.set(false); }} 在这个示例中，SpinLock 类实现了一个自旋锁。AtomicBoolean 类被用作锁状态的标记，初始时为 false 表示未锁定状态。lock() 方法使用了自旋等待的方式来尝试获取锁，它会不断地尝试将 locked 的值从 false 设置为 true，直到成功获取到锁为止。在 unlock() 方法中，锁会被释放，将 locked 的值重新设置为 false。 以下是一个使用 SpinLock 的示例： language-java1234567891011121314151617181920212223242526272829303132333435public class SpinLockExample { private static int counter = 0; private static SpinLock spinLock = new SpinLock(); public static void main(String[] args) throws InterruptedException { Thread t1 = new Thread(() -&gt; { for (int i = 0; i &lt; 1000; i++) { spinLock.lock(); counter++; spinLock.unlock(); } }); Thread t2 = new Thread(() -&gt; { for (int i = 0; i &lt; 1000; i++) { spinLock.lock(); counter++; spinLock.unlock(); } }); t1.start(); t2.start(); t1.join(); t2.join(); System.out.println(&quot;Counter: &quot; + counter); }} 在这个示例中，两个线程 t1 和 t2 分别对 counter 执行了 1000 次增加操作，每次增加操作都在获取自旋锁后执行，并在执行完毕后释放自旋锁。最后输出 counter 的值，由于自旋锁的保护，counter 的增加操作是线程安全的。 独享锁独享锁是指该锁一次只能被一个线程所持有。 共享锁共享锁是指该锁可被多个线程所持有。ReentrantReadWriteLock，其读锁是共享锁，其写锁是独享锁。读锁的共享锁可保证并发读是非常高效的，读写、写读、写写的过程是互斥的。独享锁与共享锁也是通过AQS（AbstractQueuedSynchronizer）来实现的，通过实现不同的方法，来实现独享或者共享。 互斥锁独享锁/共享锁就是一种广义的说法，互斥锁/读写锁指具体的实现。 读写锁读写锁在Java中的具体实现就是ReentrantReadWriteLock 阻塞锁阻塞锁，可以说是让线程进入阻塞状态进行等待，当获得相应的信号（唤醒，时间） 时，才可以进入线程的准备就绪状态，准备就绪状态的所有线程，通过竞争进入运行状态。 JAVA中，能够进入\\退出、阻塞状态或包含阻塞锁的方法有 ，synchronized 关键字（其中的重量锁），ReentrantLock，Object.wait()/notify()，LockSupport.park()/unpark() 公平锁公平锁是指多个线程按照申请锁的顺序来获取锁 非公平锁非公平锁是指多个线程获取锁的顺序并不是按照申请锁的顺序，有可能后申请的线程比先申请的线程优先获取锁。 可能造成优先级反转或者饥饿现象。对于Java ReentrantLock而言，通过构造函数 ReentrantLock(boolean fair) 指定该锁是否是公平锁，默认是非公平锁。 非公平锁的优点在于吞吐量比公平锁大。对于Synchronized而言，也是一种非公平锁。 分段锁分段锁其实是一种锁的设计，目的是细化锁的粒度，并不是具体的一种锁，对于ConcurrentHashMap而言，其并发的实现就是通过分段锁的形式来实现高效的并发操作。 ConcurrentHashMap中的分段锁称为Segment，它即类似于HashMap（JDK7 中HashMap的实现）的结构，即内部拥有一个Entry数组，数组中的每个元素又是一个链表；同时又是一个ReentrantLock（Segment继承了ReentrantLock)。 当需要put元素的时候，并不是对整个HashMap加锁，而是先通过hashcode知道要放在哪一个分段中，然后对这个分段加锁，所以当多线程put时，只要不是放在同一个分段中，可支持并行插入。 对象锁一个线程可以多次对同一个对象上锁。对于每一个对象，java虚拟机维护一个加锁计数器，线程每获得一次该对象，计数器就加1，每释放一次，计数器就减 1，当计数器值为0时，锁就被完全释放了。 synchronized修饰非静态方法、同步代码块的synchronized (this)、synchronized (非this对象)，锁的是对象，线程想要执行对应同步代码，需要获得对象锁。 使用 synchronized 加锁 this 时，只有同一个对象会使用同一把锁，不同对象之间的锁是不同的。 ​ 当需要同步访问对象的实例方法或实例变量时，应该使用 this 作为 synchronized 的参数。例如，在一个多线程环境中，多个线程需要同时访问对象的实例方法或实例变量时，可以使用 synchronized(this) 来确保线程安全。 language-java1234567public void synchronizedBlock() { synchronized (this) { // 同步代码块 }} 类锁synchronized修饰静态方法或者同步代码块的synchronized (类.class)，线程想要执行对应同步代码，需要获得类锁。使用 synchronized 加锁 class 时，无论共享一个对象还是创建多个对象，它们用的都是同一把锁。当需要同步访问类的静态方法或静态变量时，应该使用 MyClass.class 作为 synchronized 的参数。例如，在一个多线程环境中，多个线程需要同时访问类的静态方法或静态变量时，可以使用 synchronized(MyClass.class) 来确保线程安全。 language-java1234567public static void synchronizedStaticBlock() { synchronized (MyClass.class) { // 同步代码块 }} 锁升级锁升级是Java虚拟机中的一种优化策略，它是针对 synchronized 关键字进行的优化，并不是像 ReentrantLock 这样的锁类库，可以在代码逻辑中直接使用的锁。 （无锁、偏向锁、轻量级锁、重量级锁）是指在Java虚拟机中对锁的状态进行优化和调整的过程。这些状态反映了对象的锁定状态以及锁的竞争情况。这种锁升级的目的是为了在不同情况下提供不同的锁定机制，以减少锁的竞争、提高性能。 下面是对这几种锁状态的简要介绍： 无锁状态： 当线程尝试获取锁时，对象的锁状态为无锁状态，表示该对象没有被任何线程锁定。 在无锁状态下，线程会通过CAS（Compare and Swap）等原子操作尝试直接修改对象的指针或标记位，来尝试获取锁。 偏向锁： 当只有一个线程访问同步块时，对象的锁状态会升级为偏向锁状态。 偏向锁会将线程的ID记录在对象头中，表示该线程拥有对象的偏向锁。当其他线程尝试获取锁时，会检查偏向锁的线程ID是否与当前线程ID相同，如果相同则表示获取成功。 轻量级锁： 当有多个线程竞争同步块时，对象的锁状态会升级为轻量级锁状态。 轻量级锁使用CAS操作来避免传统的互斥量操作，尝试在用户态下通过自旋来获取锁。如果自旋获取锁失败，则升级为重量级锁。 重量级锁： 当轻量级锁竞争失败时，对象的锁状态会升级为重量级锁状态。 重量级锁会使得竞争失败的线程进入阻塞状态，从而让出CPU资源，减少竞争。 锁升级是Java虚拟机对锁状态的动态调整过程，旨在根据实际的锁竞争情况和线程行为来选择最适合的锁策略，以提高程序的并发性能。","link":"/Hexo/2024/02/23/2024-H1/2024-02-23-16-02-07/"},{"title":"JavaSE-多线程","text":"1.创建线程创建线程有三种方式，都需要子类，然后在主程序中使用它。 其一继承Thread类，重写run方法，这种方式简单，但是没法继承其他类。 language-java1234567891011public class Test01_01 extends Thread{ @Override public void run() { for (int i = 0; i &lt; 5; i++) { logger.info(&quot;thread sout:&quot;+i); } }} 运行方式如下 language-java12Thread t = new Test01_01();t.start(); 其二实现Runnable接口，重写run方法，这种方式避免了无法继承别的类的缺陷。 language-java123456789101112public class Test02_01 implements Runnable{ @Override public void run() { Thread cut = Thread.currentThread(); for (int i = 0; i &lt; 5; i++) { System.out.println(&quot;thread [&quot;+cut.getName()+&quot;]&quot;+i); } }} 运行方式如下 language-java12Runnable target = new Test02_01();new Thread(target).start(); 或者使用lambda表达式 language-java12345678new Thread(()-&gt;{ Thread cut = Thread.currentThread(); for (int i = 0; i &lt; 5; i++) { System.out.println(&quot;thread [&quot;+cut.getName()+&quot;]&quot;+i); } }).start(); 其三实现Callable接口，重写call方法，这种方式可以取得线程的返回值。 language-java123456789101112131415161718private static class Test04_01 implements Callable&lt;Long&gt;{ @Override public Long call() throws Exception { Thread cut = Thread.currentThread(); System.out.println(&quot;当前线程:&quot;+cut.getName()); long res = 0; for (int i = 0; i &lt; 100; i++) { for (int j = 0; j &lt; 100; j++) { res += j; } } return res; }}; 运行方式如下 language-java12345Callable&lt;Long&gt; call = new Test04_01();FutureTask&lt;Long&gt; task = new FutureTask&lt;&gt;(call);new Thread(task).start();Long l = task.get();System.out.println(l); 2.线程常用方式 3.线程同步三种办法 其一同步代码块，在类中使用 language-java1234synchronized (LockObject){ //your code} 对于示例方法，使用this作为LockObject，对于静态方法，使用类名.class作为LockObject 其二同步方法，在方法前加上synchronized 关键字同步方法其实底层也是有隐式锁对象的,只是锁的范围是整个方法代码。如果方法是实例方法：同步方法默认用this作为的锁对象。如果方法是静态方法：同步方法默认用类名.class作为的锁对象。 其三Lock锁，定义一把锁，需要加锁时lock，结束时unlock， language-java123456789101112private final Lock lk = new ReentrantLock();try { lk.lock(); money -= 1; } catch (Exception e) { throw new RuntimeException(e); } finally { lk.unlock(); } 4.线程池创建线程的开销是很大的。使用线程池可以复用线程，迭代任务不迭代线程，这样意味着，我们只能只用Runnable和Callable的方式开多线程。 创建线程池language-java1234ThreadPoolExecutor threadPool = new ThreadPoolExecutor(3, 5, 8, TimeUnit.SECONDS, new ArrayBlockingQueue&lt;&gt;(4), Executors.defaultThreadFactory(), new ThreadPoolExecutor.CallerRunsPolicy()); 七个参数的意思分别是： 核心线程数（一直存活的线程数） 最大线程数（最大-核心=允许存在的临时线程数） 临时线程存活时间（如果临时线程超过这个时间没有被分配任务就消亡） 存活时间单位 等待队列（ArrayBlockingQueue对象，需指定长度，被线程拿走的任务不算在等待队列） 线程工厂（使用Executors工具类即可） 拒绝策略（线程都在忙，等待队列满了，新的任务怎么处理） 临时线程的开启条件为，一个新任务来了，核心线程都在忙，同时等待队列已满，同时线程数还没达到最大线程数时，临时线程被创建，拿走新任务。 线程池常用方法 执行Runnable任务如下 language-java12Runnable target1 = new MyRunnable();threadPool.execute(target1);// core 1 执行Callable任务如下 language-java12Callable&lt;Integer&gt; callableTask = new MyCallable();Future&lt;Integer&gt; future = threadPool.submit(callableTask); 拒绝策略 线程池工具类 这样就不用自己去设计ThreadPoolExecutor了，Executors底层是封装ThreadPoolExecutor的。 一个经验之谈计算密集型任务：核心线程数量=CPU核数 + 1IO密集型任务：核心线程数量=CPU核数 * 2 5.并行并发 并发 并行 CPU能同时处理线程的数量有限,为了保证全部线程都能往前执行,CPU会轮巡为系统的每个线程服务,由于CPU切换的速度很快,给我们的感觉这些线程在同时执行,这就是并发。 在同一个时刻上，同时有多个线程在被CPU调度执行。 多线程是并发和并行同时进行的！ 6.悲观乐观锁 悲观锁 乐观锁 一上来就加锁，没有安全感。每次只能一个线程进入访问完毕后,再解锁。线程安全，性能较差！ 一开始不上锁，认为是没有问题的，大家一起跑，等要出现线程安全问题的时候才开始控制。线程安全，性能较好。 上述三种线程同步默认都是悲观锁。以下是一个悲观锁和乐观锁比较代码 language-java12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364public class PostLock01 { private static class MyRunnable01 implements Runnable{ private int number; @Override public void run() { for (int i = 0; i &lt; 1000; i++) { synchronized (this){ ++number; } } } }; private static class MyRunnable02 implements Runnable{ // private int number; private AtomicInteger number = new AtomicInteger(); @Override public void run() { for (int i = 0; i &lt; 1000; i++) { number.incrementAndGet(); } } }; public static void main(String[] args) { long timeStart, timeEnd; timeStart = System.currentTimeMillis(); pessLock(); timeEnd = System.currentTimeMillis(); System.out.println(&quot;pessimism : &quot;+(timeEnd - timeStart)+&quot; ms&quot;); timeStart = System.currentTimeMillis(); optiLock(); timeEnd = System.currentTimeMillis(); System.out.println(&quot;optimism : &quot;+(timeEnd - timeStart)+&quot; ms&quot;); } public static void pessLock(){ Runnable target = new MyRunnable01(); for (int i = 0; i &lt; 32; i++) { new Thread(target).start(); } } public static void optiLock(){ Runnable target = new MyRunnable02(); for (int i = 0; i &lt; 32; i++) { new Thread(target).start(); } }}","link":"/Hexo/2024/02/23/2024-H1/2024-02-23-20-04-04/"},{"title":"Java - JVM","text":"一、JVM1. JVM的作用 Java代码编译成java字节码后，运行在JVM中，只要针对不同的系统都开发JVM后，java就实现了跨平台。 2. JVM、JRE、JDK的关系 3. JVM的组成 类加载器（ClassLoader） 运行时数据区（Runtime Data Area) 执行引擎(Execution Engine) 本地库接口（Native Interface） 4. JVM工作流程 ClassLoader负责加载字节码文件，至于是否可以运行，由Execution Engine决定。Execution Engine把指令和数据信息加载到内存中，并且负责把命令解释到操作系统，将JVM指令集翻译成操作系统指令集。当Execution Engine执行指令时，可能会调用一些本地的接口，这时就需要用到Native Interface，主要负责调用本地的接口给java程序使用，会在本地方法栈中记录对应的本地方法。 5. 运行时方法区Runtime Data Area是JVM最重要的部分，运行时数据区的组成主要包含以下 PC Register（程序计数器）程序计数器是程序控制流的指示器，循环，跳转，异常处理，线程的恢复等工作都需要依赖程序计数器去完成。程序计数器是线程私有的，它的生命周期是和线程保持一致的，我们知道，N 个核数的 CPU 在同一时刻，最多有 N个线程同时运行，在我们真实的使用过程中可能会创建很多线程，JVM 的多线程其实是通过线程轮流切换，分配处理器执行时间来实现的。既然涉及的线程切换，所以每条线程必须有一个独立的程序计数器。 Stack (Java虚拟机栈）虚拟机栈，其描述的就是线程内存模型，也可以称作线程栈，也是每个线程私有的，生命周期与线程保持一致。在每个方法执行的时候，jvm 都会同步创建一个栈帧去存储局部变量表，操作数栈，动态连接，方法出口等信息。一个方法的生命周期就贯彻了一个栈帧从入栈到出栈的全部过程。 Native Method Stack (本地方法栈)本地方法栈的概念很好理解，我们知道，java底层用了很多c的代码去实现，而其调用c端的方法上都会有native，代表本地方法服务，而本地方法栈就是为其服务的。 Heap(堆)可以说是 JVM 中最大的一块儿内存区域了，它是所有线程共享的，不管你是初学者还是资深开发，多少都会听说过堆，毕竟几乎所有的对象都会在堆中分配。 Method Area（方法区）方法区也是所有线程共享的区域，它存储了被 jvm 加载的类型信息、常量、静态变量等数据。运行时常量池就是方法区的一部分，编译期生成的各种字面量与符号引用就存储在其中。 💡 随着Java 7及以后版本的发布，虽然字符串常量池被移至堆内存，运行时常量池仍然是方法区（或Java 8中的元空间）的一部分。💡 在Java 8之前，方法区的实现被称为永久代（PermGen），并且是堆的一部分。所以，当我们说”方法区”时，从概念上讲，它是JVM的一个独立逻辑部分，但在HotSpot JVM的具体实现中，直到Java 7为止，它是作为堆内存结构的一个部分（即永久代）来实现的，永久代是堆的一个物理部分。💡从Java 8开始，HotSpot JVM去除了永久代的概念，引入了元空间（Metaspace），并且元空间是在本地内存中，而不是在堆内存中。因此，在Java 8及以后的版本中，方法区的实现从永久代变为了元空间，方法区（现在通常指的是元空间）与堆内存是完全分开的。 💡 元空间在本地内存中，只要内存足够，就不会出现OOM（Out of Memory）。元空间的概念仍然在JVM内存模型中。 二、深入JVM内存模型（JMM）。。。待续","link":"/Hexo/2024/03/05/2024-H1/2024-03-05-14-31-40/"},{"title":"Docker部署MySQL8主从模式","text":"​ 文章目录 一、运行容器 二、配置主从 三、测试效果 Mysql 8.1.0 Docker 24.0.5 关于主从模式，Mysql从8.0一些版本开始，有许多变化，这里使用8.1.0 。 一、运行容器新建两个MySQL文件夹，分别新建data文件夹和conf/my.cnf文件。根据需要理解并更改以下脚本。 language-bash123456789101112131415161718192021222324#!/bin/bashcontainerName=&quot;MyWeb02-MySQL&quot;MySQLData=&quot;/root/MyWeb02/MySQL/data&quot;MySQLConf=&quot;/root/MyWeb02/MySQL/conf/my.cnf&quot;containerSlaveName=&quot;MyWeb02-MySQL-Slave&quot;MySQLSlaveData=&quot;/root/MyWeb02/MySQL-Slave/data&quot;MySQLSlaveConf=&quot;/root/MyWeb02/MySQL-Slave/conf/my.cnf&quot;docker run -d --name &quot;$containerName&quot; \\ -p 3307:3306 \\ -v &quot;$MySQLData&quot;:/var/lib/mysql \\ -v &quot;$MySQLConf&quot;:/etc/mysql/my.cnf \\ -e MYSQL_ROOT_PASSWORD=20028888 \\ mysql:8docker run -d --name &quot;$containerSlaveName&quot; \\ -p 3308:3306 \\ -v &quot;$MySQLSlaveData&quot;:/var/lib/mysql \\ -v &quot;$MySQLSlaveConf&quot;:/etc/mysql/my.cnf \\ -e MYSQL_ROOT_PASSWORD=20028888 \\ mysql:8 主节点的my.cnf容器如下 language-bash123[mysqld]server-id=1log_bin=mysql-bin 从节点的my.cnf容器如下 language-bash12[mysqld]server-id=2 运行脚本。 二、配置主从到主节点命令行，运行以下命令 language-sql12CREATE USER 'replica'@'%' IDENTIFIED WITH mysql_native_password BY 'replica';GRANT REPLICATION SLAVE ON *.* TO 'replica'@'%'; 到从节点命令行，运行以下命令 language-sql1234567CHANGE REPLICATION SOURCE TO SOURCE_HOST='172.17.0.6',SOURCE_PORT=3306,SOURCE_USER='replica',SOURCE_PASSWORD='replica';START REPLICA; //开启备份SHOW REPLICA STATUS\\G //查看主从情况 其中SOURCE_HOST为主节点容器的ip。查看主从情况时，主要注意下面两个字段是否为Yes。不是的话，就有问题，读docker logs然后去解决它。 language-bash12Slave_IO_Running: YesSlave_SQL_Running: Yes Navicat等第三方软件可能不支持\\G，结果以行显示。 三、测试效果在主节点新建一个数据库 language-bash1create database `test`; 随后可以在从节点也看到效果。","link":"/Hexo/2024/04/02/2024-H1/2024-04-02-17-17-56/"},{"title":"Redis基础文档-01-安装","text":"参考文档-Redis快速入门指南-中文参考文档-Redis 教程 一、启动并连接本地启动一个redis或者用redis cloud免费账户，都可以。 language-bash1docker run --name CommonTrain -p 6379:6379 -itd redis:7.2 然后下载REDISINSIGHT。 二、支持的数据类型 字符串string 哈希hash 列表list 集合set 有序集合sorted set 位图bitmaps 基数统计hyperLogLogs","link":"/Hexo/2024/04/03/2024-H1/2024-04-03-11-42-39/"},{"title":"视频分块上传Vue3+SpringBoot3+Minio","text":"一、简化演示分块上传、合并分块前端将完整的视频文件分割成多份文件块，依次上传到后端，后端将其保存到文件系统。前端将文件块上传完毕后，发送合并请求，后端拿取文件块，合并后重新上传到文件系统。 断点续传前端遍历文件块，每次上传之前，先询问文件块是否存在，只有不存在的情况下，才会上传。 秒传前端分割视频文件前，先询问此视频是否已经存在，存在则不再上传，后端之间返回视频信息。前端看起来就像是被秒传了。 二、更详细的逻辑和细节问题 视频文件和文件块都通过文件本身计算MD5值作为唯一标志 文件系统使用Minio，只要提供buckerName和path就可以操作文件 后端合并文件块成功后会删除文件块，并以MD5值为id存入数据库 Minio存储文件块时，依据其md5值计算path，比如取前两个字符构建二级文件夹，文件名为md5值，无后缀。所以只需要提供文件块的md5值就可以操作文件块。 Minio存储完整视频文件时，依据其md5值计算path，同上，文件名为md5值，携带.mp4等后缀，所以只需要提供视频文件的md5值就可以操作视频文件。 首先，前端计算视频文件的MD5值，记为fileMd5，传递MD5值来询问后端此视频文件是否存在，后端查询数据库返回结果，如果存在，则前端触发”秒传”。 如果不存在，则将视频文件分割成文件块，循环上传，每次循环，首先计算文件块的md5值，传递md5值询问后端此文件块是否存在，后端根据md5判断文件块是否存在，如果存在，前端跳过此文件块上传，直接标记为上传成功，如果不存在，则上传至后端，后端将其保存到minio。这其实就是”分块上传，断点续传”。 最后所有分块文件都上传成功，前端发起合并请求，传递视频文件的md5值和所有文件块的md5值到后端，后端进行文件块合并、文件块的删除、合并文件的上传，将信息存储在mysql数据库，将执行结果告知前端。这就是”合并分块” 可能存在的隐患 一个视频文件的文件块没有全部上传完成就终止，此时文件块将一直保存在minio中，如果之后此视频再也没有发起过上传请求，那么这些文件块都是是一种垃圾。 可以写一个定时任务，遍历Minio没有后缀的文件块，判断其创建时间距离当前是否足够久，是则删除。 三、代码示例前端代码language-html123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188&lt;template&gt; &lt;div class=&quot;p-2&quot;&gt; &lt;el-button icon=&quot;Plus&quot; plain type=&quot;primary&quot; @click=&quot;handleAdd&quot;&gt;新增&lt;/el-button&gt; &lt;!-- 添加或修改media对话框 --&gt; &lt;el-dialog v-model=&quot;dialog.visible&quot; :title=&quot;dialog.title&quot; append-to-body width=&quot;500px&quot;&gt; &lt;el-form ref=&quot;mediaFormRef&quot; :model=&quot;form&quot; :rules=&quot;rules&quot; label-width=&quot;80px&quot;&gt; &lt;el-form-item label=&quot;上传视频&quot; prop=&quot;originalName&quot; v-show=&quot;dialog.title=='添加视频'&quot;&gt; &lt;el-upload ref=&quot;uploadRef&quot; :http-request=&quot;onUpload&quot; :before-upload=&quot;beforeUpload&quot; :limit=&quot;1&quot; action=&quot;#&quot; class=&quot;upload-demo&quot; &gt; &lt;template #trigger&gt; &lt;el-button type=&quot;primary&quot;&gt;选择视频&lt;/el-button&gt; &lt;/template&gt; &lt;template #tip&gt; &lt;div class=&quot;el-upload__tip&quot;&gt; 支持分块上传、端点续传 &lt;/div&gt; &lt;/template&gt; &lt;/el-upload&gt; &lt;/el-form-item&gt; &lt;el-form-item v-show=&quot;percentageShow&quot;&gt; &lt;el-progress :percentage=&quot;percentage&quot; style=&quot;width: 100%&quot;/&gt; &lt;/el-form-item&gt; &lt;/el-form&gt; &lt;/el-dialog&gt; &lt;/div&gt;&lt;/template&gt;&lt;script lang=&quot;ts&quot; name=&quot;Media&quot; setup&gt;import type { UploadInstance, UploadRawFile, UploadRequestOptions, UploadUserFile} from 'element-plus'import SparkMD5 from &quot;spark-md5&quot;;import { HttpStatus} from &quot;@/enums/RespEnum&quot;;const dialog = reactive&lt;DialogOption&gt;({ visible: false, title: ''});//上传视频const baseUrl = import.meta.env.VITE_APP_BASE_API;const uploadImgUrl = ref(baseUrl + &quot;/media/media/image&quot;); // 上传的图片服务器地址const uploadRef = ref&lt;UploadInstance&gt;()const needUpload = ref(true)const chunkSize = 5*1024*1024;const percentage = ref(0)const percentageShow = ref(false)/** 新增按钮操作 */const handleAdd = () =&gt; { dialog.visible = true; dialog.title = &quot;添加视频&quot;; percentageShow.value = false;}//获取文件的MD5const getFileMd5 = (file:any) =&gt; { return new Promise((resolve, reject) =&gt; { let fileReader = new FileReader() fileReader.onload = function (event) { let fileMd5 = SparkMD5.ArrayBuffer.hash(event.target.result) resolve(fileMd5) } fileReader.readAsArrayBuffer(file) } )}//在上传之前，使用视频md5判断视频是否已经存在const beforeUpload = async (rawFile: UploadRawFile) =&gt; { needUpload.value = true; const fileMd5 = await getFileMd5(rawFile); form.value.id = fileMd5; const rsp = await getMedia(fileMd5); if(!!rsp.data &amp;&amp; rsp.data['id'] == fileMd5){ needUpload.value = false; proxy?.$modal.msgWarning(&quot;视频文件已存在，请勿重复上传。文件名为&quot;+rsp.data['originalName']) }}//分块上传、合并分块const onUpload = async (options: UploadRequestOptions) =&gt; { if(!needUpload.value){ //秒传 percentageShow.value = true; percentage.value = 100; dialog.visible = false; return; } percentageShow.value = true; const file = options.file const totalChunks = Math.ceil(file.size / chunkSize); let isUploadSuccess = true;//记录分块文件是否上传成功 //合并文件参数 let mergeVo = { &quot;chunksMd5&quot;: [] as string[], &quot;videoMd5&quot;: undefined as string | undefined, &quot;videoName&quot;: file.name, &quot;videoSize&quot;: file.size, &quot;remark&quot;: undefined as string | undefined } //循环切分文件，并上传分块文件 for(let i=0; i&lt;totalChunks; ++i){ const start = i * chunkSize; const end = Math.min(start + chunkSize, file.size); const chunk = file.slice(start, end); //计算 chunk md5 const md5 = await getFileMd5(chunk); mergeVo.chunksMd5.push(md5); // 准备FormData const formData = new FormData(); formData.append('file', chunk); formData.append('filename', file.name); formData.append('chunkIndex', i.toString()); formData.append('totalChunks', totalChunks.toString()); formData.append('md5', md5); //上传当前分块 try { //先判断这个分块是否已经存在 const isExistRsp = await isChunkExist({ &quot;md5&quot;: formData.get(&quot;md5&quot;)}); const isExist = isExistRsp.data; //不存在则上传 if (!isExist){ const rsp = await addChunk(formData); console.log(`Chunk ${ i + 1}/${ totalChunks} uploaded`, rsp.data); }else { console.log(`Chunk ${ i + 1}/${ totalChunks} is exist`); } percentage.value = (i)*100 / totalChunks; } catch (error) { isUploadSuccess = false; console.error(`Error uploading chunk ${ i + 1}`, error); proxy?.$modal.msgError(`上传分块${ i + 1}出错`); break; } } //合并分块文件 if(isUploadSuccess){ proxy?.$modal.msgSuccess(&quot;分块文件上传成功&quot;) mergeVo.videoMd5 = form.value.id;//beforeUpload已经计算过视频文件的md5 //合并文件 const rsp = await mergeChunks(mergeVo); if (rsp.code == HttpStatus.SUCCESS){ //合并文件后，实际上媒资已经插入数据库。 percentage.value = 100; proxy?.$modal.msgSuccess(&quot;文件合并成功&quot;) proxy?.$modal.msgSuccess(&quot;视频上传成功&quot;) }else{ proxy?.$modal.msgSuccess(&quot;文件合并异常&quot;) } }else { proxy?.$modal.msgSuccess(&quot;文件未上传成功，请重试或联系管理员&quot;) }}&lt;/script&gt; language-javascript1234567891011121314151617181920212223242526272829303132333435363738394041424344454647export const getMedia = (id: string | number): AxiosPromise&lt;MediaVO&gt; =&gt; { return request({ url: '/media/media/' + id, method: 'get' });};/** * 分块文件是否存在 * */export const isChunkExist = (data: any) =&gt; { return request({ url: '/media/media/video/chunk', method: 'get', params: data });};/** * 上传分块文件 * */export const addChunk = (data: any) =&gt; { return request({ url: '/media/media/video/chunk', method: 'post', data: data });};/** * 合并分块文件 * */export const mergeChunks = (data: any) =&gt; { return request({ url: '/media/media/video/chunk/merge', method: 'post', data: data });}; 后端代码language-java12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061@RestController@RequestMapping(&quot;/media&quot;)public class MediaFilesController extends BaseController { /** * 获取media详细信息 * * @param id 主键 */ @GetMapping(&quot;/{id}&quot;) public R&lt;MediaFilesVo&gt; getInfo(@NotNull(message = &quot;主键不能为空&quot;) @PathVariable String id) { return R.ok(mediaFilesService.queryById(id)); } @Log(title = &quot;视频分块文件上传&quot;) @PostMapping(value = &quot;/video/chunk&quot;) public R&lt;String&gt; handleChunkUpload( @RequestParam(&quot;file&quot;) MultipartFile file, @RequestParam(&quot;md5&quot;) String md5, @RequestParam(&quot;filename&quot;) String filename, @RequestParam(&quot;chunkIndex&quot;) int chunkIndex, @RequestParam(&quot;totalChunks&quot;) int totalChunks) { if (ObjectUtil.isNull(file)) { return R.fail(&quot;上传文件不能为空&quot;); } Boolean b = mediaFilesService.handleChunkUpload(file, md5); if (b){ return R.ok(); }else { return R.fail(); } } @Log(title = &quot;分块文件是否已经存在&quot;) @GetMapping(value = &quot;/video/chunk&quot;) public R&lt;Boolean&gt; isChunkExist(@RequestParam(&quot;md5&quot;) String md5) { return R.ok(mediaFilesService.isChunkExist(md5)); } @Log(title = &quot;合并视频文件&quot;) @PostMapping(value = &quot;/video/chunk/merge&quot;) public R&lt;Boolean&gt; mergeChunks(@RequestBody MediaVideoMergeBo bo) { bo.setCompanyId(LoginHelper.getDeptId()); Boolean b = mediaFilesService.mergeChunks(bo); if (b){ return R.ok(); }else { return R.fail(); } }} 关于如何操作Minio等文件系统，不详细写明解释。只需要知道，给Minio提供文件本身、bucketName、path即可完成上传、下载、删除等操作。具体代码不同的包都不一样。 language-java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113@Servicepublic class MediaFilesServiceImpl implements MediaFilesService { @Autowired private MediaFilesMapper mediaFilesMapper; /** * 分块文件上传 * &lt;br/&gt; * 分块文件不存放mysql信息，同时文件名不含后缀，只有md5 * @param file 文件 * @param md5 md5 * @return {@link Boolean} */ @Override public Boolean handleChunkUpload(MultipartFile file, String md5) { //只上传至minio OssClient storage = OssFactory.instance(); String path = getPathByMD5(md5, &quot;&quot;); try { storage.upload(file.getInputStream(), path, file.getContentType(), minioProperties.getVideoBucket()); } catch (IOException e) { throw new RuntimeException(e); } return true; } @Override public Boolean isChunkExist(String md5) { OssClient storage = OssFactory.instance(); String path = getPathByMD5(md5, &quot;&quot;); return storage.doesFileExist(minioProperties.getVideoBucket(), path); } @Override public Boolean mergeChunks(MediaVideoMergeBo bo) { OssClient storage = OssFactory.instance(); String originalfileName = bo.getVideoName(); String suffix = StringUtils.substring(originalfileName, originalfileName.lastIndexOf(&quot;.&quot;), originalfileName.length()); //创建临时文件，用来存放合并文件 String tmpDir = System.getProperty(&quot;java.io.tmpdir&quot;); String tmpFileName = UUID.randomUUID().toString() + &quot;.tmp&quot;; File tmpFile = new File(tmpDir, tmpFileName); try( FileOutputStream fOut = new FileOutputStream(tmpFile); ) { //将分块文件以流的形式copy到临时文件 List&lt;String&gt; chunksMd5 = bo.getChunksMd5(); chunksMd5.forEach(chunkMd5 -&gt; { String chunkPath = getPathByMD5(chunkMd5, &quot;&quot;); InputStream chunkIn = storage.getObjectContent(minioProperties.getVideoBucket(), chunkPath); IoUtil.copy(chunkIn, fOut); }); //合并文件上传到minio String videoMd5 = bo.getVideoMd5(); String path = getPathByMD5(videoMd5, suffix); storage.upload(tmpFile, path, minioProperties.getVideoBucket()); //删除分块文件 chunksMd5.forEach(chunkMd5-&gt;{ String chunkPath = getPathByMD5(chunkMd5, &quot;&quot;); storage.delete(chunkPath, minioProperties.getVideoBucket()); }); } catch (Exception e) { throw new RuntimeException(e); }finally { if (tmpFile.exists()){ tmpFile.delete(); } } //上传信息到mysql MediaFiles mediaFiles = new MediaFiles(); mediaFiles.setId(bo.getVideoMd5()); mediaFiles.setCompanyId(bo.getCompanyId()); mediaFiles.setOriginalName(originalfileName); mediaFiles.setFileSuffix(suffix); mediaFiles.setSize(bo.getVideoSize()); mediaFiles.setPath(getPathByMD5(bo.getVideoMd5(), suffix)); mediaFiles.setRemark(bo.getRemark()); mediaFiles.setAuditStatus(MediaStatusEnum.UNREVIEWED.getValue()); return mediaFilesMapper.insert(mediaFiles) &gt; 0; } /** * 通过md5生成文件路径 * &lt;br/&gt; * 比如 * md5 = 6c4acb01320a21ccdbec089f6a9b7ca3 * &lt;br/&gt; * path = 6/c/md5 + suffix * @param prefix 前缀 * @param suffix 后缀 * @return {@link String} */ public String getPathByMD5(String md5, String suffix) { // 文件路径 String path = md5.charAt(0) + &quot;/&quot; + md5.charAt(1) + &quot;/&quot; + md5; return path + suffix; }}","link":"/Hexo/2024/04/17/2024-H1/2024-04-17-11-39-47/"},{"title":"SpringBoot和Axios数据的传递和接收-Restful完全版","text":"一、基础知识铺垫Axios使用使用axios发送请求，一般有三个最常用的属性。 属性 含义 url 请求的端点 URL。 method HTTP 请求方法（如 get, post, put, delete, patch 等）。 params / data 如果 method 是 get 或 delete，使用 params 来传递 URL 查询参数。如果是 post, put, patch，则使用 data 传递请求体数据。通常是一个对象 {}。 HTTP请求方式Restful风格定义了多种请求方式。 方式 简介 常用场景 GET 请求指定的资源。通常用来获取或查询资源。 读取或查询资源，如获取用户列表或特定用户的详细信息。 POST 向指定资源提交数据，请求服务器进行处理（如创建或修改）。数据包含在请求体中。 创建新资源（如新用户、新帖子），或提交用户数据表单。 PUT 用请求体中的数据替换目标资源的所有当前表示。 更新现有资源的全部内容，如编辑用户的完整个人信息。 PATCH 对资源应用部分修改。 更新资源的一部分，如修改用户的邮箱地址或密码。 DELETE 删除指定的资源。 删除资源，如删除用户账户或帖子。 数据传输方式 方式 介绍 URL路径参数（Path Variables） 通过 URL 的路径部分传递数据。在 Spring Boot 中使用 @PathVariable 注解获取。适用于 RESTful 风格的 API，例如获取特定资源的详情。 查询参数（Query Parameters） 通过 URL 的查询字符串（?key=value 形式）传递数据。在 Spring Boot 中使用 @RequestParam 注解获取。适用于 GET 和 DELETE 请求。 请求体（Request Body） 通过 HTTP 请求的 body 部分传递数据。在 Spring Boot 中使用 @RequestBody 注解获取。适用于 POST , PUT 和 PATCH请求，发送复杂的数据结构。 SpringBoot获取数据的方式需要提及的是，单单从”获取数据”的角度，我们可以把Delete和Get归为一类，把Put、Patch、Post归为一类。 前者在axios中使用params传递参数，属于Query Parameters。 后者在axios中使用data传递参数，属于Request Body。 无论是哪一种，都可以有Path Variables。 在 Spring Boot（及一般的 HTTP 服务开发）中，将请求分为”GET 体系”和”POST 体系”可能会导致一些混淆，因为每种 HTTP 方法（GET、POST、PUT、PATCH、DELETE 等）都设计有其独特的用途和语义。不过，如果我们从”如何获取请求中的数据”这个角度来看，可以有一种比较宽泛的分类方式，尤其是关注于数据是通过 URL 还是请求体传递。 体系 获取数据的常用注解 Path Variables @PathVariable Get、Delete类 @RequestParam、@ModelAttribute Post、Put、Patch类 @RequestBody 二、基础传递代码示例除了特殊的数据类型，普通的数据传递，默认以axios.defaults.headers['Content-Type'] = 'application/json;charset=utf-8';为策略。 （一）Path VariablesPath Variables数据在url上，无关乎get还是post。 language-javascript12345678910return request({ url: '/test/users/123', method: 'get' }); return request({ url: '/test/users/345/info', method: 'post' }); language-java123456789101112131415161718@RestController@RequestMapping(&quot;/test&quot;)public class CourseTestController { @GetMapping(&quot;/users/{userId}&quot;) public String getUser(@PathVariable String userId) { return &quot;Received GET request for User ID: &quot; + userId; } @PostMapping(&quot;/users/{userId}/info&quot;) public String updateUser(@PathVariable String userId) { return &quot;Received POST request for User ID: &quot; + userId; }} （二）Get、Delete@RequestParam@RequestParam 主要用于将单个请求参数绑定到方法的参数上，通过指定 value 或 name 属性，你可以明确告诉 Spring Boot 请求参数的实际名称。 language-javascript12345678910return request({ url: '/users', method: 'get', params:{ type:&quot;1&quot;, status:&quot;2&quot;, } }); language-java12345@GetMapping(&quot;/users&quot;) public String getUser(@RequestParam String type, @RequestParam(name = &quot;status&quot;) String userStatus) { return &quot;Received GET request for&quot; + type + &quot; &quot; + userStatus; } @ModelAttribute利用 @ModelAttribute 注解。这个注解会告诉 Spring Boot，应该将请求中的查询参数自动绑定到方法参数对象的属性上。 language-javascript12345678910return request({ url: '/users', method: 'get', params:{ type:&quot;1&quot;, status:&quot;2&quot;, } }); language-java1234567891011@GetMapping(&quot;/users&quot;) public String getUser(@ModelAttribute Query query) { return &quot;Received GET request for&quot; + query.toString(); }@Dataclass Query{ String type; String status;} 通常情况下，我们会将所有的查询参数封装到一个对象中，而不是分开为两个对象，除非这两个对象在逻辑上代表着完全不同的东西，且您希望显式地区分它们。如果您确实有特定的理由需要这样做，也是可行的。比如第二个Query2表示分页查询时的分页参数。 language-javascript12345678910return request({ url: '/users', method: 'delete', params:{ type:&quot;1&quot;, status:&quot;2&quot;, } }); language-java1234567891011121314151617181920212223 @DeleteMapping(&quot;/users&quot;) public String deleteUser(@ModelAttribute Query1 query1, @ModelAttribute Query2 query2) { return &quot;Received GET request for&quot; + query1.toString() + query2.toString(); } @Data class Query1{ String type; } @Data class Query2{ String userStatus; // 如果您希望整个对象通过 @ModelAttribute 来绑定，同时又有个别属性名不匹配 // 您可以在后端对象中添加 setter 方法，并在其中处理名称不匹配的问题 // 注意：Lombok @Data 注解会生成默认的 setter 方法， // 所以如果使用 Lombok，您需要手动添加一个额外的 setter 方法来处理不匹配的情况 public void setStatus(String status) { this.userStatus = status; }} （三）Post、Put、Patch@RequestBodylanguage-javascript123456789101112return request({ url: '/users', method: 'post', data:{ userId: 123, userName: &quot;John Doe&quot;, userAge: 30, userSex: &quot;Male&quot; }}); language-java12345678910111213 @PostMapping(&quot;/users&quot;) public String getUser(@RequestBody UserVo userVo) { return userVo.toString(); }@Dataclass UserVo{ Long userId; String userName; Long userAge; String userSex;} 当 Spring Boot 后端的 UserVo 类中的属性名和前端传递的 JSON 对象的键名不一致时，可以使用@JsonProperty。 language-javascript123456789101112return request({ url: '/users', method: 'put', data:{ userId: 123, userName: &quot;John Doe&quot;, userAge: 32, userSex: &quot;Male&quot; }}); language-java1234567891011121314 @PutMapping(&quot;/users&quot;) public String getUser(@RequestBody UserVo userVo) { return userVo.toString(); }@Dataclass UserVo{ Long userId; @JsonProperty(&quot;userName&quot;) String name; Long userAge; String userSex;} language-javascript12345678910return request({ url: '/users', method: 'patch', data:{ userId: 123, userAge: 34, }}); language-java1234567891011121314 @PatchMapping(&quot;/users&quot;) public String getUser(@RequestBody UserVo userVo) { return userVo.toString(); }@Dataclass UserVo{ Long userId; @JsonProperty(&quot;userName&quot;) String name; Long userAge; String userSex;} 如果你不想额外写一个类作为@RequestBody的参数，你可以选择使用Map或者JsonNode。 language-java1234567@PutMapping(&quot;/users&quot;)public R&lt;Boolean&gt; getUser(@RequestBody Map&lt;String, Object&gt; body) { Long id = Long.valueOf(body.get(&quot;userId&quot;).toString()); String mind = (String) body.get(&quot;name&quot;); // 业务逻辑} language-java1234567@PutMapping(&quot;/users&quot;)public R&lt;Boolean&gt; getUser(@RequestBody JsonNode body) { Long id = body.get(&quot;userId&quot;).asLong(); String mind = body.get(&quot;name&quot;).asText(); // 业务逻辑} 三、稍微复杂一点的传递（一）数组如果用的是Post，那么一般一切安好。 language-javascript12345678910return request({ url: '/users', method: 'post', data:{ userId: 123, userOrder: ['1223', '3445', '556'], }}); language-java1234567891011 @PostMapping(&quot;/users&quot;) public String getUser(@RequestBody UserVo userVo) { return userVo.toString(); }@Dataclass UserVo{ Long userId; List&lt;String&gt; userOrder;} 如果用的是Get，就需要注意默认情况下，Spring Boot 期望列表或数组类型的查询参数以特定的格式传递，例如：userOrder=1223&amp;userOrder=3445&amp;userOrder=556。但在你的例子中，由于是通过 axios 发送请求，并且当你在请求的 params 中包含一个数组时，axios 会将数组转换为 userOrder[0]=1223&amp;userOrder[1]=3445&amp;userOrder[2]=556 的格式，这与 Spring Boot 的默认期望不匹配。 language-javascript12345678910return request({ url: '/users', method: 'get', params:{ userId: 123, userOrder: ['1223', '3445', '556'].join(','), }}); language-java12345@GetMapping(&quot;/users&quot;) public String getUser(@RequestParam String userId, @RequestParam List&lt;String&gt; userOrder) { return userId + &quot;\\n&quot; + userOrder.toString(); } 对于数组元素是简单类型，直接用字符’,’拼接即可，变成userOrder=1223,3445,556，Springboot也能匹配。或者可以去参考qs.stringify也就是qs库的用法。 如果数组元素比较复杂呢？如果你仍然坚持使用get，建议去阅读qs使用。一般的做法是用post，可以省去很多麻烦。 language-javascript1234567891011121314151617return request({ url: '/users', method: 'post', data:{ userId: 123, userOrder: [ { id: '1223', name: 'Order1' }, { id: '3445', name: 'Order2' }, { id: '556', name: 'Order3' } ] }}); language-java123456789101112131415161718 @PostMapping(&quot;/users&quot;) public String getUser(@RequestBody UserVo userVo) { return userVo.toString(); } @Dataclass UserVo{ Long userId; List&lt;Item&gt; userOrder;}@Dataclass Item{ String id; String name;} （二）GET/POST复合型对于复合型请求，即在URL中通过查询参数（例如分页信息）传递部分数据，同时在请求体中通过JSON传递更复杂的数据（例如筛选条件），Spring Boot可以通过同时使用@RequestParam和@RequestBody注解来接收这两种类型的数据。 language-javascript1234567891011121314151617const pageParams = { page: 1, size: 10};return request({ url: `/users?page=${ pageParams.page}&amp;size=${ pageParams.size}`, method: 'post', data:{ userId: 123, userName: &quot;Jack&quot; }}); language-java123456789101112131415 @PostMapping(&quot;/users&quot;) public String getUser( @RequestBody UserVo userVo, @RequestParam(&quot;page&quot;) int page, @RequestParam(&quot;size&quot;) int size ) { return userVo.toString(); }@Dataclass UserVo{ Long userId; String userName;} 四、特殊数据（一）文件上传文件时，使用的 Content-Type 通常是 multipart/form-data。这种类型允许将请求体中的数据作为一系列部分（parts）发送，每个部分可以包含文件内容或其他数据。这种方式非常适合文件上传，因为它支持在单个请求中发送文件数据及其他表单字段。 language-javascript1234567891011121314151617const formData = new FormData();formData.append('file', file);formData.append('filename', file.name);formData.append('chunkIndex', i.toString());formData.append('totalChunks', totalChunks.toString());formData.append('md5', md5);const rsp = await addChunk(formData);export const addChunk = (data: any) =&gt; { return request({ url: '/video/chunk', method: 'post', data: data });}; language-java123456789101112131415161718192021@PostMapping(value = &quot;/video/chunk&quot;) public R&lt;String&gt; handleChunkUpload( @RequestParam(&quot;file&quot;) MultipartFile file, @RequestParam(&quot;md5&quot;) String md5, @RequestParam(&quot;filename&quot;) String filename, @RequestParam(&quot;chunkIndex&quot;) int chunkIndex, @RequestParam(&quot;totalChunks&quot;) int totalChunks) { if (ObjectUtil.isNull(file)) { return R.fail(&quot;上传文件不能为空&quot;); } Boolean b = mediaFilesService.handleChunkUpload(file, md5); if (b){ return R.ok(); }else { return R.fail(); } } 在 Vue 3 的框架 Element Plus中，el-upload 组件用于文件上传，它底层使用的也是 multipart/form-data 这种 Content-Type 来上传文件。这是因为 multipart/form-data 允许在一个请求中发送多部分数据，包括文本字段和文件，非常适合文件上传的场景 language-html12345678910111213141516171819202122232425262728293031323334353637&lt;template&gt; &lt;el-upload action=&quot;http://example.com/upload&quot; :data=&quot;extraData&quot; :on-success=&quot;handleSuccess&quot; :on-error=&quot;handleError&quot; &gt; &lt;el-button size=&quot;small&quot; type=&quot;primary&quot;&gt;点击上传&lt;/el-button&gt; &lt;/el-upload&gt;&lt;/template&gt;&lt;script setup&gt;import { ElMessage } from 'element-plus';import { ref } from 'vue';// 额外数据const extraData = ref({ userId: &quot;123&quot;, description: &quot;这是一个文件描述&quot;});const handleSuccess = (response, file, fileList) =&gt; { // 文件上传成功的回调 ElMessage.success('文件上传成功');};const handleError = (err, file, fileList) =&gt; { // 文件上传失败的回调 ElMessage.error('文件上传失败');};&lt;/script&gt; language-java123456789101112@RestControllerpublic class FileUploadController { @PostMapping(&quot;/upload&quot;) public String handleFileUpload( @RequestParam(&quot;file&quot;) MultipartFile file, @RequestParam(&quot;userId&quot;) String userId, @RequestParam(&quot;description&quot;) String description) { return &quot;文件上传成功，用户ID: &quot; + userId + &quot;，描述: &quot; + description; }} （二）CookiessaultValue`指定的默认值 “”会被使用。","link":"/Hexo/2024/04/17/2024-H1/2024-04-17-11-39-58/"},{"title":"Vue3炫酷商品卡牌 组件设计","text":"感谢来自BinaryMoon-CSS 艺术之暗系魔幻卡牌的博文。💕 演示 代码接口类型 language-typescript12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667export interface CourseBaseVO { /** * 主键 */ id: string | number; /** * 机构ID */ companyId: string | number; /** * 课程名称 */ name: string; /** * 大分类 */ mt: string; /** * 小分类 */ st: string; /** * 课程图片 */ pic: string; /** * 是否收费 */ charge: boolean; /** * 原价 */ originalPrice: number; /** * 现价 */ price: number; /** * 评分 */ star: number; /** * UNPUBLISHED(1, &quot;未发布&quot;), UNDER_REVIEW(2, &quot;审核中&quot;), REVIEW_FAILED(3, &quot;审核不通过&quot;), REVIEW_PASSED(4, &quot;审核通过&quot;) */ status: number; /** * 审核意见 */ mind: string;}interface CourseBaseExtraHotVo extends CourseBaseVO { isHot: boolean;} 外部资源wave_orange.svg language-txt1&lt;svg width=&quot;100%&quot; height=&quot;100%&quot; id=&quot;svg&quot; viewBox=&quot;0 0 1440 490&quot; xmlns=&quot;http://www.w3.org/2000/svg&quot; class=&quot;transition duration-300 ease-in-out delay-150&quot;&gt;&lt;defs&gt;&lt;linearGradient id=&quot;gradient&quot; x1=&quot;0%&quot; y1=&quot;51%&quot; x2=&quot;100%&quot; y2=&quot;49%&quot;&gt;&lt;stop offset=&quot;5%&quot; stop-color=&quot;#fcb900&quot;&gt;&lt;/stop&gt;&lt;stop offset=&quot;95%&quot; stop-color=&quot;#ff6900&quot;&gt;&lt;/stop&gt;&lt;/linearGradient&gt;&lt;/defs&gt;&lt;path d=&quot;M 0,500 L 0,0 C 90.96650717703349,54.02870813397129 181.93301435406698,108.05741626794259 268,115 C 354.066985645933,121.94258373205741 435.23444976076553,81.79904306220095 535,84 C 634.7655502392345,86.20095693779905 753.129186602871,130.7464114832536 867,132 C 980.870813397129,133.2535885167464 1090.248803827751,91.2153110047847 1185,62 C 1279.751196172249,32.78468899521531 1359.8755980861245,16.392344497607656 1440,0 L 1440,500 L 0,500 Z&quot; stroke=&quot;none&quot; stroke-width=&quot;0&quot; fill=&quot;url(#gradient)&quot; fill-opacity=&quot;0.53&quot; class=&quot;transition-all duration-300 ease-in-out delay-150 path-0&quot;&gt;&lt;/path&gt;&lt;defs&gt;&lt;linearGradient id=&quot;gradient&quot; x1=&quot;0%&quot; y1=&quot;51%&quot; x2=&quot;100%&quot; y2=&quot;49%&quot;&gt;&lt;stop offset=&quot;5%&quot; stop-color=&quot;#fcb900&quot;&gt;&lt;/stop&gt;&lt;stop offset=&quot;95%&quot; stop-color=&quot;#ff6900&quot;&gt;&lt;/stop&gt;&lt;/linearGradient&gt;&lt;/defs&gt;&lt;path d=&quot;M 0,500 L 0,0 C 111.98086124401911,108.89952153110048 223.96172248803822,217.79904306220095 335,271 C 446.0382775119618,324.20095693779905 556.133971291866,321.7033492822967 626,309 C 695.866028708134,296.2966507177033 725.5023923444976,273.3875598086125 820,274 C 914.4976076555024,274.6124401913875 1073.8564593301435,298.7464114832536 1188,257 C 1302.1435406698565,215.25358851674642 1371.0717703349283,107.62679425837321 1440,0 L 1440,500 L 0,500 Z&quot; stroke=&quot;none&quot; stroke-width=&quot;0&quot; fill=&quot;url(#gradient)&quot; fill-opacity=&quot;1&quot; class=&quot;transition-all duration-300 ease-in-out delay-150 path-1&quot;&gt;&lt;/path&gt;&lt;/svg&gt; 组件源码 language-html123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203&lt;template&gt; &lt;div id=&quot;card&quot; style=&quot;padding: 5px;margin: 20px&quot; &gt; &lt;el-card shadow=&quot;hover&quot; style=&quot;width: 350px; border-radius: 10px&quot; &gt; &lt;div class=&quot;wave-orange-card&quot;&gt;&lt;/div&gt; &lt;div style=&quot;display: flex;flex-direction: column;justify-content: center;align-items: center;&quot;&gt; &lt;el-image :src=&quot;fileBaseUrl+courseBase.pic&quot; fit=&quot;fill&quot; style=&quot;width: 200px&quot; /&gt; &lt;/div&gt; &lt;div style=&quot;height: 30px; font-size: 20px;margin-top: 10px&quot;&gt; &lt;span&gt;{ { courseBase.name }}&lt;/span&gt; &lt;/div&gt; &lt;div style=&quot;height: 40px; &quot;&gt; &lt;el-rate v-model=&quot;courseBase.star&quot; size=&quot;large&quot; show-score text-color=&quot;#ff9900&quot; :score-template=&quot;courseBase.star.toString() + 'points'&quot; disabled /&gt; &lt;/div&gt; &lt;div style=&quot;height: 40px; &quot;&gt; &lt;el-tag v-if=&quot;courseBase.charge&quot; type=&quot;warning&quot; size=&quot;large&quot; effect=&quot;light&quot;&gt; &lt;span style=&quot;font-size: 20px;font-weight: bold&quot;&gt;￥{ { courseBase.price }}&lt;/span&gt; &amp;nbsp;&amp;nbsp; &lt;span class=&quot;slash-deleted-text&quot; style=&quot;font-size: 14px;color: #909399&quot;&gt;{ { courseBase.originalPrice }}&lt;/span&gt; &lt;/el-tag&gt; &lt;el-tag v-else type=&quot;success&quot; size=&quot;large&quot;&gt;&lt;span style=&quot;font-size: 20px&quot;&gt;免费&lt;/span&gt;&lt;/el-tag&gt; &lt;span&gt;&amp;nbsp;&amp;nbsp; 6w人报名&lt;/span&gt; &lt;/div&gt; &lt;/el-card&gt; &lt;/div&gt;&lt;/template&gt;&lt;script lang=&quot;ts&quot; setup&gt;import { CourseBaseVO} from &quot;@/api/course/types&quot;;import { PropType} from &quot;vue&quot;;const fileBaseUrl = import.meta.env.VITE_APP_MINIO_FILE_URL;interface CourseBaseExtraHotVo extends CourseBaseVO { isHot: boolean;}const props = defineProps({ courseBase: Object as PropType&lt;CourseBaseExtraHotVo&gt;,});const emit = defineEmits(['update:courseBase'])&lt;/script&gt;&lt;style scoped&gt;/* 卡片图片背景 */:deep(.wave-orange-card){ background-image: url(&quot;src/assets/svg/wave_orange.svg&quot;); background-repeat: no-repeat; background-size: cover; /* 或使用 100% 100% 来确保完全覆盖 */ background-position: center; /* 根据需要调整 */ overflow: hidden; /* 避免内容溢出 */ position: absolute; /* 固定定位，不随滚动条移动 */ width: 310px; /* card的宽度为350 */ height: 200px; /*pic的大小为200*200*/ opacity: 0.6;}/* 删除线 */:deep(.slash-deleted-text) { position: relative; overflow: hidden; /* 防止斜线溢出容器 */}:deep(.slash-deleted-text::after) { content: ''; position: absolute; left: 0; top: 10%; /* 调整为文本高度的一半 */ width: 100%; /* 与容器同宽 */ border-bottom: 1px solid #F56C6C; /* 删除线的样式 */ transform: rotate(25deg); /* 调整角度为倾斜 */ transform-origin: left bottom;}/* 卡片背景 */:deep(:root) { --margin: 100px; /* 上演一出黄金分割率的好戏 */ --card-width: 360px; /* 上演一出黄金分割率的好戏 */ --card-height: calc(var(--card-height) * 1.618);}#card{ width: var(--card-width); height: var(--card-height); position: relative; cursor: pointer; transition: transform 0.4s ease; /* 设置放大动画的过渡效果为2秒 */}/* 定义自定义属性 --rotate */@property --rotate{ /* 自定义属性的默认值 */ initial-value: 90deg; /* 定义自定义属性允许的语法结构， 此处定义该元素仅接受角度值。 */ syntax: '&lt;angle&gt;'; /* 定义该自定义属性是否允许被其他元素所继承 */ inherits: false;}/* 定义动画 */@keyframes edge{ from{ --rotate: 0deg; } to{ --rotate: 360deg; }}#card::before{ content: ''; width: 104%; height: 102%; background: linear-gradient(var(--rotate), rgb(44, 251, 255), rgb(81, 154, 255), rgb(97, 57, 242)); position: absolute; z-index: -1; top: -1%; left: -2%; /* 设置边框圆角半径 */ border-radius: 0.5vw; /* 为当前元素指定使用的动画，并将该动画的 持续时间设置为 3.5s，动画速度保持不变， 动画播放次数为无限次。 */ animation: edge 10s linear infinite;}#card::after{ content: ''; width: 80%; height: 100%; background: linear-gradient(var(--rotate), rgb(44, 251, 255), rgb(81, 154, 255), rgb(97, 57, 242)); position: absolute; top: 5%; left: 10%; filter: blur(2vw); z-index: -1; /* 使用动画 */ animation: edge 3.5s linear infinite;}/* 卡片悬浮变化背景 */#card:hover { transform: scale(1.02); /* 鼠标悬浮时放大到1.1倍 */}#card::before, #card::after { transition: background 1s ease; /* 将过渡应用于background，确保背景渐变的平滑变化 */}#card:hover::before, #card:hover::after { background: linear-gradient(var(--rotate), #f82747, #fc5c7c, #ffc3d3); /* 渐变为淡红色 */}&lt;/style&gt; 使用示例 language-html123456789&lt;template&gt;&lt;CourseCard v-for=&quot;(course, index) in hotList&quot; :course-base=&quot;course&quot;/&gt;&lt;/template&gt;&lt;script lang=&quot;ts&quot; setup&gt; const hotList = ref&lt;CourseBaseExtraHotVo[]&gt;([]);&lt;/script&gt;","link":"/Hexo/2024/04/22/2024-H1/2024-04-22-13-17-20/"},{"title":"ruoyi-cloud-plus添加一个不要认证的公开新页面","text":"版本 RuoYiCloudPlus v2.1.2 plus-ui Vue3 ts 以新增一个公开的课程搜索页面为例。 一、前端1. 组件创建在view目录下创建一个页面的vue代码，比如 language-bash1src/views/customer/searchPage/index.vue 2. src/router/index.ts为其编制一个路由。在constantRoutes中添加一组dict信息。比如 language-typescript123456{ path: '/courseSearch', component: () =&gt; import('@/views/customer/searchPage/index.vue'), hidden: true}, 3. src/permission.ts把页面加入前端的whiteList。 language-typescript123456const whiteList = [ '/login', '/register', '/social-callback', '/courseSearch']; 在浏览器输入http://localhost/courseSearch，至此这个页面已经不用登录就可以访问了。 二、后端但是后端是有网关和认证模块的，虽然前端页面可以不用登陆了，但是如果这个页面还需要从后端获取数据，那么后端对应的controller也应该被open。 1. 设计思想不同模块有不同的url前缀，比如 language-txt123456789101112131415routes: # 认证中心 - id: ruoyi-auth uri: lb://ruoyi-auth predicates: - Path=/auth/** filters: - StripPrefix=1 # 代码生成 - id: ruoyi-gen uri: lb://ruoyi-gen predicates: - Path=/tool/** filters: - StripPrefix=1 并且每个模块都有可能需要open一些controller，不需要认证。那么我们进行统一设定，比如课程模块，url前缀为course，那么/course/open/**就都是被公开的端点。于是在gateway只需要把/*/open/**加入白名单即可。 2. ruoyi-gateway.yml在nacos中修改gateway的配置文件，把/*/open/**加入whites。 language-yaml123456789101112131415security: ignore: whites: - /auth/code - /auth/logout - /auth/login - /auth/binding/* - /auth/social/callback - /auth/register - /auth/tenant/list - /resource/sms/code - /*/v3/api-docs - /*/error - /csrf - /*/open/** 3. 开发Controller在course模块中，新建一个CourseOpenController.java，内容示例如下 language-java123456789101112131415161718192021222324252627282930package org.dromara.course.controller;import org.dromara.course.domain.bo.CourseCategoryBo;import org.dromara.course.domain.vo.CourseCategoryVo;import org.dromara.course.service.CourseCategoryService;import org.springframework.beans.factory.annotation.Autowired;import org.springframework.web.bind.annotation.GetMapping;import org.springframework.web.bind.annotation.RequestMapping;import org.springframework.web.bind.annotation.RestController;import java.util.List;@RestController@RequestMapping(&quot;/open&quot;)public class CourseOpenController { @Autowired CourseCategoryService categoryService; @GetMapping(&quot;/category/list&quot;) public List&lt;CourseCategoryVo&gt; list(CourseCategoryBo bo) { return categoryService.queryList(bo); }} 重启网关和课程模块即可。","link":"/Hexo/2024/04/22/2024-H1/2024-04-22-20-24-27/"},{"title":"支付宝沙箱版模拟网站在线完整支付流程(无营业无费用)内网穿透+局域网测试","text":"环境如下 Version 手机 安卓 支付平台 支付宝 SpringBoot 3.2.1 alipay-sdk-java 4.38.200.ALL 一、介绍系统处于开发阶段时，无需营业执照，无需任何费用，沙箱模拟网站在线完整支付流程。 参考资料如下： 手机网站支付快速接入 alipay.trade.query(统一收单交易查询) 异步通知说明 1. 支付有一个在线网站，可以为商品生成支付二维码，手机支付宝扫码，支付。 支付流程大体如下： 2. 支付结果获取支付结果有两种方法 一种为主动查询。在顾客支付后再查询方可得到正确的结果，然而这个时机是无法确定的。 一种为被动接收。顾客支付后，支付宝服务器向微服务发送消息通知。 二、前提准备1. 支付宝开放平台 注册支付宝开放平台https://openhome.alipay.com/ 来到控制台下滑找到沙箱https://openhome.alipay.com/develop/manage或者点这里进入沙箱环境https://openhome.alipay.com/develop/sandbox/app 下载支付宝沙箱版到手机 2. 内网穿透 下载软件https://hsk.oray.com/download本文选择的是贝锐花生壳，会赠送一个域名。 添加映射 映射类型：HTTPS 外网端口：貌似改不了 内网ip:port：order微服务的地址端口。 这样之后，谁往https://5m34y83626.vicp.fun/orders/receivenotify发送请求，就相当于往order微服务的/orders/receivenotify这个端点发送请求。 3. 局域网参考这篇文章同一Wifi下允许手机访问电脑（win10） 主要目的就是要知道，手机通过什么ip可以访问到电脑。本文是192.168.0.102，所以访问192.168.0.102:63030就相当于访问到了order微服务。 三、order微服务1. 依赖、配置language-xml1234567891011121314151617&lt;!-- 支付宝SDK --&gt;&lt;dependency&gt; &lt;groupId&gt;com.alipay.sdk&lt;/groupId&gt; &lt;artifactId&gt;alipay-sdk-java&lt;/artifactId&gt; &lt;version&gt;4.38.200.ALL&lt;/version&gt; &lt;/dependency&gt; &lt;!--生成二维码--&gt; &lt;dependency&gt; &lt;groupId&gt;com.google.zxing&lt;/groupId&gt; &lt;artifactId&gt;core&lt;/artifactId&gt; &lt;version&gt;3.3.3&lt;/version&gt; &lt;/dependency&gt; &lt;dependency&gt; &lt;groupId&gt;com.google.zxing&lt;/groupId&gt; &lt;artifactId&gt;javase&lt;/artifactId&gt; &lt;version&gt;3.3.3&lt;/version&gt; &lt;/dependency&gt; language-yml123456789101112server: servlet: context-path: /orders port: 63030pay: #扫描二维码得到url qrcodeurl: http://???:63030/orders/requestpay?payNo=%s alipay: APP_ID: ??? APP_PRIVATE_KEY: ??? ALIPAY_PUBLIC_KEY: ??? ???填充分别为 在同一局域网中手机访问电脑的ip 沙箱环境-&gt;沙箱应用-&gt;应用信息-&gt;基本信息 沙箱环境-&gt;沙箱应用-&gt;应用信息-&gt;开发信息-&gt;应用私钥 沙箱环境-&gt;沙箱应用-&gt;应用信息-&gt;开发信息-&gt;支付宝公钥 2. 工具类1. 二维码生成language-java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748package com.xuecheng.orders.config;import com.google.zxing.BarcodeFormat;import com.google.zxing.EncodeHintType;import com.google.zxing.client.j2se.MatrixToImageWriter;import com.google.zxing.common.BitMatrix;import com.google.zxing.qrcode.QRCodeWriter;import com.google.zxing.qrcode.decoder.ErrorCorrectionLevel;import com.xuecheng.base.utils.EncryptUtil;import jakarta.servlet.ServletOutputStream;import org.apache.commons.lang3.StringUtils;import javax.imageio.ImageIO;import java.awt.image.BufferedImage;import java.io.ByteArrayOutputStream;import java.io.IOException;import java.util.HashMap;/** * @author mumu * @version 1.0 * @description 二维码生成工具 * @date 2024/02/16 14:56 */public class QRCodeUtil { /** * 生成二维码 * * @param content 二维码对应的URL * @param width 二维码图片宽度 * @param height 二维码图片高度 * @return */ public String createQRCode(String content, int width, int height) throws IOException { String resultImage = &quot;&quot;; //除了尺寸，传入内容不能为空 if (!StringUtils.isEmpty(content)) { ServletOutputStream stream = null; ByteArrayOutputStream os = new ByteArrayOutputStream(); //二维码参数 @SuppressWarnings(&quot;rawtypes&quot;) HashMap&lt;EncodeHintType,&lt;","link":"/Hexo/2024/04/28/2024-H1/2024-04-28-11-18-37/"},{"title":"Vue3 v3.4之前如何实现组件中多个值的双向绑定？","text":"官方给的例子是关于el-input的，如下。但是@input不是所有组件标签都有的属性啊，有没有一种通用的办法呢？ language-html12345678910111213141516171819202122&lt;script setup&gt;defineProps({ firstName: String, lastName: String})defineEmits(['update:firstName', 'update:lastName'])&lt;/script&gt;&lt;template&gt; &lt;input type=&quot;text&quot; :value=&quot;firstName&quot; @input=&quot;$emit('update:firstName', $event.target.value)&quot; /&gt; &lt;input type=&quot;text&quot; :value=&quot;lastName&quot; @input=&quot;$emit('update:lastName', $event.target.value)&quot; /&gt;&lt;/template&gt; 基础代码以一个Dialog组件为例。我们自己写一个course-buy.vue language-html12345678910111213141516171819202122232425262728293031323334353637&lt;template&gt; &lt;el-dialog v-model=&quot;localValue.dialogVisible&quot; title=&quot;Warning&quot; width=&quot;500&quot; align-center &gt; &lt;span&gt;Open the dialog from the center from the screen&lt;/span&gt; &lt;template #footer&gt; &lt;div class=&quot;dialog-footer&quot;&gt; &lt;el-button @click=&quot;localValue.dialogVisible = false&quot;&gt;Cancel&lt;/el-button&gt; &lt;el-button type=&quot;primary&quot; @click=&quot;localValue.dialogVisible = false&quot;&gt; Confirm &lt;/el-button&gt; &lt;/div&gt; &lt;/template&gt; &lt;/el-dialog&gt;&lt;/template&gt;&lt;script setup lang=&quot;ts&quot;&gt;import { PropType} from &quot;vue&quot;;//对外变量const props = defineProps({ dialogVisible: Object as PropType&lt;boolean&gt;, courseId: Object as PropType&lt;string | number&gt;,})const emit = defineEmits(['update:dialogVisible','update:courseId'])//本地变量const localValue = reactive({ dialogVisible: props.dialogVisible, courseId: props.courseId})&lt;/script&gt; 外部在使用时（假设为base.vue），如下使用 language-html12345678910111213&lt;template&gt; &lt;CourseBuy v-model:dialog-visible=&quot;orderPayParams.dialogVisible&quot; v-model:course-id=&quot;orderPayParams.courseId&quot; /&gt;&lt;/template&gt;&lt;script setup lang=&quot;ts&quot;&gt;const orderPayParams = reactive({ dialogVisible: false, courseId: 1});&lt;/script&gt; 上述代码，course-buy.vue中真正使用的变量是localValue本地变量，localValue的值来自base.vue。但是上述的基础代码，dialogVisible和courseId的值只能从base.vue流向course-buy.vue。如何实现course-buy.vue本身修改localValue的值后，修改变化同步到base.vue呢？ 1. watch如果要让dialogVisible双向绑定，可以写两个watch互相监听并更新。要实现courseId双向绑定也是同理。 language-html123456789101112131415161718192021222324252627&lt;script setup lang=&quot;ts&quot;&gt;import { PropType} from &quot;vue&quot;;//对外变量const props = defineProps({ dialogVisible: Object as PropType&lt;boolean&gt;, courseId: Object as PropType&lt;string | number&gt;,})const emit = defineEmits(['update:dialogVisible','update:courseId'])//本地变量const localValue = reactive({ dialogVisible: props.dialogVisible, courseId: props.courseId})//值双向绑定watch(() =&gt; props.dialogVisible, (newValue) =&gt; { localValue.dialogVisible = newValue;});watch(() =&gt; localValue.dialogVisible, (newValue) =&gt; { emit('update:dialogVisible', newValue);});&lt;/script&gt; 2. computed（推荐）不过使用computed可以更简洁，性能也更好。 language-html12345678910111213141516171819202122&lt;script setup lang=&quot;ts&quot;&gt;import { PropType} from &quot;vue&quot;;//对外变量const props = defineProps({ dialogVisible: Object as PropType&lt;boolean&gt;, courseId: Object as PropType&lt;string | number&gt;,})const emit = defineEmits(['update:dialogVisible','update:courseId'])//本地变量const localValue = reactive({ dialogVisible: computed({ get: () =&gt; props.dialogVisible, set: (value) =&gt; emit('update:dialogVisible', value) }), courseId: props.courseId})&lt;/script&gt;","link":"/Hexo/2024/04/28/2024-H1/2024-04-28-20-55-44/"},{"title":"Navicat导出表结构到Excel或Word","text":"sql语句language-sql12345678910111213141516171819202122SELECT cols.COLUMN_NAME AS 字段, cols.COLUMN_TYPE AS 数据类型, IF(pks.CONSTRAINT_TYPE = 'PRIMARY KEY', 'YES', 'NO') AS 是否为主键, IF(idxs.INDEX_NAME IS NOT NULL, 'YES', 'NO') AS 是否为索引, cols.IS_NULLABLE AS 是否为空, cols.COLUMN_DEFAULT AS 默认值, cols.COLUMN_COMMENT AS 备注FROM INFORMATION_SCHEMA.COLUMNS AS colsLEFT JOIN INFORMATION_SCHEMA.KEY_COLUMN_USAGE AS kc ON kc.TABLE_SCHEMA = cols.TABLE_SCHEMA AND kc.TABLE_NAME = cols.TABLE_NAME AND kc.COLUMN_NAME = cols.COLUMN_NAMELEFT JOIN INFORMATION_SCHEMA.TABLE_CONSTRAINTS AS pks ON pks.TABLE_SCHEMA = kc.TABLE_SCHEMA AND pks.TABLE_NAME = kc.TABLE_NAME AND pks.CONSTRAINT_TYPE = 'PRIMARY KEY' AND kc.CONSTRAINT_NAME = pks.CONSTRAINT_NAMELEFT JOIN INFORMATION_SCHEMA.STATISTICS AS idxs ON idxs.TABLE_SCHEMA = cols.TABLE_SCHEMA AND idxs.TABLE_NAME = cols.TABLE_NAME AND idxs.COLUMN_NAME = cols.COLUMN_NAMEWHERE cols.TABLE_SCHEMA = 'db' -- 替换为您的数据库名称 AND cols.TABLE_NAME = 'table' -- 替换为您的表名称ORDER BY cols.ORDINAL_POSITION ASC; -- 按列在表中的顺序排列 复制到excel 在查询结果中，Ctrl+A全选，然后复制。到Excel中，自己写好表头，然后粘贴，就复制到Excel了。 复制到Word从Excel全选数据，就可以直接复制到Word。","link":"/Hexo/2024/05/08/2024-H1/2024-05-08-19-47-59/"},{"title":"基于Ruoyi-Cloud-Plus重构黑马项目-学成在线","text":"一、系统介绍毕设：基于主流微服务技术栈的在线教育系统的设计与实现 前端仓库：https://github.com/Xiamu-ssr/Dragon-Edu-Vue3后端仓库：https://github.com/Xiamu-ssr/Dragon-Edu 感谢来自”疯狂的狮子”开源精神，RuoYi 微服务Plus版本： 文档地址: plus-doc 二、系统架构图 三、参考教程主要以视频录制的方式展示。包含：服务器选购，环境初始化，本地开发，部署系统，功能测试，性能测试，代码解析，架构探讨。 b站-木子dn 四、演示图例机构端 运营端 用户端 开发端","link":"/Hexo/2024/05/22/2024-H1/2024-05-22-15-06-08/"},{"title":"深入探讨5种单例模式","text":"一、对比总览以下是不同单例模式实现方式的特性对比表格。表格从线程安全性、延迟加载、实现复杂度、反序列化安全性、防反射攻击性等多个方面进行考量。 特性 饿汉式 饱汉式 饱汉式-双检锁 静态内部类 枚举单例（推荐） 线程安全性 √ × √ √ √ 延迟加载 × √ √ √ × 实现复杂度 √ √ × √ √ 反序列化安全性 × × × × √ 防反射攻击性 × × × × √ 详细解释 线程安全性： 饿汉式：类加载时即创建实例（因为instance是static），线程安全。 饱汉式：未使用同步机制，线程不安全。 饱汉式-双检锁：使用同步块和双重检查锁，线程安全。 静态内部类：通过类加载机制，线程安全。 枚举单例：JVM确保线程安全。 延迟加载： 饿汉式：类加载时即创建实例，不具备延迟加载。 饱汉式：实例在首次使用时创建，具备延迟加载。 饱汉式-双检锁：实例在首次使用时创建，具备延迟加载。 静态内部类：实例在首次使用时创建（因为静态内部类只有在使用时才会加载），具备延迟加载。 枚举单例：类加载时即创建实例，不具备延迟加载。 实现复杂度： 饿汉式：实现简单。 饱汉式：实现简单。 饱汉式-双检锁：实现相对复杂。 静态内部类：实现简单。 枚举单例：实现简单。 反序列化安全性： 饿汉式 、饱汉式 、饱汉式-双检锁 、静态内部类 ：需要实现 readResolve 方法以防止反序列化创建新实例。 枚举单例：天然防止反序列化创建新实例，JVM保证。 防反射攻击性： 饿汉式 、饱汉式 、饱汉式-双检锁 、静态内部类：可能通过反射创建新实例。 枚举单例 ：防止反射攻击，创建新实例时抛出 IllegalArgumentException。 二、代码1. 饿汉式language-java123456789101112131415161718192021222324252627282930public class OrderManager1 { @Getter @Setter private Map&lt;String, TradeOrder&gt; orders = new HashMap&lt;&gt;(); @Getter private static final OrderManager1 instance = new OrderManager1(); /** * 添加订单 * * @param order 顺序 */ public void addOrder(TradeOrder order) { orders.put(order.getId(), order); } /** * 获取订单 * * @param orderId 订单id * @return {@link TradeOrder} */ public TradeOrder getOrder(String orderId) { return orders.get(orderId); }} 2. 饱汉式language-java1234567891011121314151617181920212223242526272829303132333435363738public class OrderManager2 { @Getter @Setter private Map&lt;String, TradeOrder&gt; orders = new HashMap&lt;&gt;(); private static OrderManager2 instance; public static OrderManager2 getInstance(){ if (instance == null){ instance = new OrderManager2(); } return instance; } /** * 添加订单 * * @param order 顺序 */ public void addOrder(TradeOrder order) { orders.put(order.getId(), order); } /** * 获取订单 * * @param orderId 订单id * @return {@link TradeOrder} */ public TradeOrder getOrder(String orderId) { return orders.get(orderId); }} 3. 饱汉式-双检锁language-java123456789101112131415161718192021222324252627282930313233343536373839404142434445public class OrderManager3 { @Getter @Setter private Map&lt;String, TradeOrder&gt; orders = new HashMap&lt;&gt;(); private static OrderManager3 instance; public static OrderManager3 getInstance(){ if (instance == null){ synchronized (OrderManager3.class){ if (instance == null){ instance = new OrderManager3(); } } instance = new OrderManager3(); } return instance; } /** * 添加订单 * * @param order 顺序 */ public void addOrder(TradeOrder order) { orders.put(order.getId(), order); } /** * 获取订单 * * @param orderId 订单id * @return {@link TradeOrder} */ public TradeOrder getOrder(String orderId) { return orders.get(orderId); }} 4. 静态内部类language-java1234567891011121314151617181920212223242526272829303132333435363738public class OrderManager4 { @Getter @Setter private Map&lt;String, TradeOrder&gt; orders = new HashMap&lt;&gt;(); private static class SingletonHelper{ private static final OrderManager4 INSTANCE = new OrderManager4(); } public static OrderManager4 getInstance(){ return SingletonHelper.INSTANCE; } /** * 添加订单 * * @param order 顺序 */ public void addOrder(TradeOrder order) { orders.put(order.getId(), order); } /** * 获取订单 * * @param orderId 订单id * @return {@link TradeOrder} */ public TradeOrder getOrder(String orderId) { return orders.get(orderId); }} 5. 枚举单例language-java1234567891011121314151617181920212223242526272829public enum OrderManager5 { INSTANCE; @Getter @Setter private Map&lt;String, TradeOrder&gt; orders = new HashMap&lt;&gt;(); /** * 添加订单 * * @param order 顺序 */ public void addOrder(TradeOrder order) { orders.put(order.getId(), order); } /** * 获取订单 * * @param orderId 订单id * @return {@link TradeOrder} */ public TradeOrder getOrder(String orderId) { return orders.get(orderId); }} 三、性能对比language-java123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264package org.dragon.singleton;import lombok.extern.slf4j.Slf4j;import java.util.*;import java.util.concurrent.CountDownLatch;import java.util.concurrent.ExecutorService;import java.util.concurrent.Executors;import java.util.concurrent.TimeUnit;import java.util.function.Supplier;@Slf4jpublic class SingletonPerformanceTest { static long timeout = 20; // 超时时间，单位为秒 static int testIterations = 10_000_000; // 测试次数 static int threadCount = 1000; // 并发线程数 static Map&lt;String, HashMap&lt;String, Long&gt;&gt; result = new HashMap&lt;&gt;(); public static void main(String[] args) { /* * 多次调用，结果是最后一次调用存入。为什么多次调用，因为单次test不准确，总是靠前的OrderManager跑的快，可能是因为Java某些机制导致的 * 所以多次调用，逐渐平稳。 * */ firstCreationTest(); mulAccessTest(); mulAccessTest(); mulAccessTest(); ConcurrentAccessTest(); ConcurrentAccessTest(); printRes(); ConcurrentAccessTest(); printRes(); ConcurrentAccessTest(); printRes(); } /** * 打印结果 */ private static void printRes(){ ArrayList&lt;String&gt; names = new ArrayList&lt;&gt;(); names.add(OrderManager1.class.getSimpleName()); names.add(OrderManager2.class.getSimpleName()); names.add(OrderManager3.class.getSimpleName()); names.add(OrderManager4.class.getSimpleName()); names.add(OrderManager5.class.getSimpleName()); // 表头 System.out.printf(&quot;%-20s%-20s%-25s%-25s%-20s%n&quot;, &quot;Singleton Type&quot;, &quot;First Creation (ms)&quot;, &quot;Multiple Access (ms)&quot;, &quot;Concurrent Access (ms)&quot;, &quot;Memory Used (MB)&quot;); System.out.println(&quot;---------------------------------------------------------------------------------------------------------------&quot;); for (String name : names) { // 打印结果，转换时间为毫秒 System.out.printf(&quot;%-20s%-20.3f%-25.3f%-25.3f%-20.3f%n&quot;, name, result.get(name).get(&quot;firstCreation&quot;) / 1_000_000.0, result.get(name).get(&quot;mulAccess&quot;) / 1_000_000.0, result.get(name).get(&quot;ConcurrentAccess&quot;) / 1_000_000.0, 0 / (1024.0 * 1024.0)); } } /** * 首次创建测试 */ private static void firstCreationTest(){ List&lt;Runnable&gt; tests = new ArrayList&lt;&gt;(); tests.add(()-&gt;firstCreation(OrderManager1::getInstance)); tests.add(()-&gt;firstCreation(OrderManager2::getInstance)); tests.add(()-&gt;firstCreation(OrderManager3::getInstance)); tests.add(()-&gt;firstCreation(OrderManager4::getInstance)); tests.add(()-&gt;firstCreation(() -&gt; OrderManager5.INSTANCE)); // 随机化测试顺序 Collections.shuffle(tests); //run for (Runnable test : tests) { test.run(); log.info(&quot;Complete one test&quot;); try { Thread.sleep(200); } catch (InterruptedException e) { throw new RuntimeException(e); } } } /** * 多次访问测试 */ private static void mulAccessTest(){ List&lt;Runnable&gt; tests = new ArrayList&lt;&gt;(); tests.add(()-&gt;mulAccess(OrderManager1::getInstance, testIterations)); tests.add(()-&gt;mulAccess(OrderManager2::getInstance, testIterations)); tests.add(()-&gt;mulAccess(OrderManager3::getInstance, testIterations)); tests.add(()-&gt;mulAccess(OrderManager4::getInstance, testIterations)); tests.add(()-&gt;mulAccess(() -&gt; OrderManager5.INSTANCE, testIterations)); // 随机化测试顺序 Collections.shuffle(tests); //run for (Runnable test : tests) { test.run(); log.info(&quot;Complete one test&quot;); try { Thread.sleep(200); } catch (InterruptedException e) { throw new RuntimeException(e); } } } /** * 多线程访问测试 */ private static void ConcurrentAccessTest(){ List&lt;Runnable&gt; tests = new ArrayList&lt;&gt;(); tests.add(()-&gt;ConcurrentAccess(OrderManager1::getInstance, testIterations, threadCount)); tests.add(()-&gt;ConcurrentAccess(OrderManager2::getInstance, testIterations, threadCount)); tests.add(()-&gt;ConcurrentAccess(OrderManager3::getInstance, testIterations, threadCount)); tests.add(()-&gt;ConcurrentAccess(OrderManager4::getInstance, testIterations, threadCount)); tests.add(()-&gt;ConcurrentAccess(() -&gt; OrderManager5.INSTANCE, testIterations, threadCount)); // 随机化测试顺序 Collections.shuffle(tests); //run for (Runnable test : tests) { test.run(); log.info(&quot;Complete one test&quot;); try { Thread.sleep(200); } catch (InterruptedException e) { throw new RuntimeException(e); } } } /** * 首次创建 * * @param singletonSupplier 单一供应商 * @return long ns */ private static &lt;T&gt; long firstCreation(Supplier&lt;T&gt; singletonSupplier){ // 测试首次创建时间 long startTime = System.nanoTime(); T instance = singletonSupplier.get(); long endTime = System.nanoTime(); long resTime = endTime - startTime; //save res String simpleName = instance.getClass().getSimpleName(); HashMap&lt;String, Long&gt; resMap = result.computeIfAbsent(simpleName, k-&gt;new HashMap&lt;&gt;()); resMap.put(&quot;firstCreation&quot;, resTime); return resTime; } /** * 多次访问 * * @param singletonSupplier 单一供应商 * @param iterations 迭代 * @return long ns */ private static &lt;T&gt; long mulAccess(Supplier&lt;T&gt; singletonSupplier, int iterations){ //预热 for (int i = 0; i &lt; 100_000; i++) { T instance = singletonSupplier.get(); } //计算 long startTime = System.nanoTime(); for (int i = 0; i &lt; iterations; i++) { T instance = singletonSupplier.get(); } long endTime = System.nanoTime(); long resTime = endTime - startTime; //save res String simpleName = singletonSupplier.get().getClass().getSimpleName(); HashMap&lt;String, Long&gt; resMap = result.computeIfAbsent(simpleName, k-&gt;new HashMap&lt;&gt;()); resMap.put(&quot;mulAccess&quot;, resTime); return resTime; } /** * 并发访问 * * @param singletonSupplier 单一供应商 * @param iterations 迭代 * @param threadCount 线程数 * @return long ns */ private static &lt;T&gt; long ConcurrentAccess(Supplier&lt;T&gt; singletonSupplier, int iterations, int threadCount){ ExecutorService executorService = Executors.newFixedThreadPool(100); //预热 CountDownLatch latch1 = new CountDownLatch(100); for (int i = 0; i &lt; threadCount; i++) { executorService.submit(() -&gt; { for (int j = 0; j &lt; 100_000; j++) { T instance = singletonSupplier.get(); } latch1.countDown(); }); } try { boolean completed = latch1.await(timeout, TimeUnit.SECONDS); if (!completed) { System.out.println(&quot;Concurrent access test for 预热&quot; + singletonSupplier.get().getClass().getSimpleName() + &quot; timed out!&quot;); } } catch (InterruptedException e) { e.printStackTrace(); } //计算 CountDownLatch latch2 = new CountDownLatch(threadCount); long startTime = System.nanoTime(); for (int i = 0; i &lt; threadCount; i++) { executorService.submit(() -&gt; { for (int j = 0; j &lt; iterations; j++) { T instance = singletonSupplier.get(); } latch2.countDown(); }); } try { boolean completed = latch2.await(timeout, TimeUnit.SECONDS); if (!completed) { System.out.println(&quot;Concurrent access test for &quot; + singletonSupplier.getClass().getSimpleName() + &quot; timed out!&quot;); } } catch (InterruptedException e) { e.printStackTrace(); } long endTime = System.nanoTime(); long concurrentAccessTime = endTime - startTime; executorService.shutdown(); //save res String simpleName = singletonSupplier.get().getClass().getSimpleName(); HashMap&lt;String, Long&gt; resMap = result.computeIfAbsent(simpleName, k-&gt;new HashMap&lt;&gt;()); resMap.put(&quot;ConcurrentAccess&quot;, concurrentAccessTime); return concurrentAccessTime; }} 结果输出如下 language-txt123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263[17:15:54.519] [INFO ] org.dragon.singleton.SingletonPerformanceTest 73 firstCreationTest - Complete one test[17:15:54.730] [INFO ] org.dragon.singleton.SingletonPerformanceTest 73 firstCreationTest - Complete one test[17:15:54.936] [INFO ] org.dragon.singleton.SingletonPerformanceTest 73 firstCreationTest - Complete one test[17:15:55.141] [INFO ] org.dragon.singleton.SingletonPerformanceTest 73 firstCreationTest - Complete one test[17:15:55.347] [INFO ] org.dragon.singleton.SingletonPerformanceTest 73 firstCreationTest - Complete one test[17:15:55.554] [INFO ] org.dragon.singleton.SingletonPerformanceTest 97 mulAccessTest - Complete one test[17:15:55.782] [INFO ] org.dragon.singleton.SingletonPerformanceTest 97 mulAccessTest - Complete one test[17:15:56.007] [INFO ] org.dragon.singleton.SingletonPerformanceTest 97 mulAccessTest - Complete one test[17:15:56.227] [INFO ] org.dragon.singleton.SingletonPerformanceTest 97 mulAccessTest - Complete one test[17:15:56.445] [INFO ] org.dragon.singleton.SingletonPerformanceTest 97 mulAccessTest - Complete one test[17:15:56.669] [INFO ] org.dragon.singleton.SingletonPerformanceTest 97 mulAccessTest - Complete one test[17:15:56.906] [INFO ] org.dragon.singleton.SingletonPerformanceTest 97 mulAccessTest - Complete one test[17:15:57.146] [INFO ] org.dragon.singleton.SingletonPerformanceTest 97 mulAccessTest - Complete one test[17:15:57.376] [INFO ] org.dragon.singleton.SingletonPerformanceTest 97 mulAccessTest - Complete one test[17:15:57.598] [INFO ] org.dragon.singleton.SingletonPerformanceTest 97 mulAccessTest - Complete one test[17:15:57.818] [INFO ] org.dragon.singleton.SingletonPerformanceTest 97 mulAccessTest - Complete one test[17:15:58.054] [INFO ] org.dragon.singleton.SingletonPerformanceTest 97 mulAccessTest - Complete one test[17:15:58.276] [INFO ] org.dragon.singleton.SingletonPerformanceTest 97 mulAccessTest - Complete one test[17:15:58.495] [INFO ] org.dragon.singleton.SingletonPerformanceTest 97 mulAccessTest - Complete one test[17:15:58.716] [INFO ] org.dragon.singleton.SingletonPerformanceTest 97 mulAccessTest - Complete one test[17:15:59.430] [INFO ] org.dragon.singleton.SingletonPerformanceTest 121 ConcurrentAccessTest - Complete one test[17:15:59.658] [INFO ] org.dragon.singleton.SingletonPerformanceTest 121 ConcurrentAccessTest - Complete one test[17:16:02.737] [INFO ] org.dragon.singleton.SingletonPerformanceTest 121 ConcurrentAccessTest - Complete one test[17:16:08.533] [INFO ] org.dragon.singleton.SingletonPerformanceTest 121 ConcurrentAccessTest - Complete one test[17:16:13.700] [INFO ] org.dragon.singleton.SingletonPerformanceTest 121 ConcurrentAccessTest - Complete one test[17:16:19.432] [INFO ] org.dragon.singleton.SingletonPerformanceTest 121 ConcurrentAccessTest - Complete one test[17:16:24.632] [INFO ] org.dragon.singleton.SingletonPerformanceTest 121 ConcurrentAccessTest - Complete one test[17:16:30.366] [INFO ] org.dragon.singleton.SingletonPerformanceTest 121 ConcurrentAccessTest - Complete one test[17:16:35.516] [INFO ] org.dragon.singleton.SingletonPerformanceTest 121 ConcurrentAccessTest - Complete one test[17:16:40.431] [INFO ] org.dragon.singleton.SingletonPerformanceTest 121 ConcurrentAccessTest - Complete one testSingleton Type First Creation (ms) Multiple Access (ms) Concurrent Access (ms) Memory Used (MB) ---------------------------------------------------------------------------------------------------------------OrderManager1 0.010 16.848 4928.236 0.000 OrderManager2 0.010 18.592 5504.781 0.000 OrderManager3 0.009 19.127 5513.309 0.000 OrderManager4 0.241 18.772 4920.940 0.000 OrderManager5 0.117 16.637 4704.835 0.000 [17:16:45.002] [INFO ] org.dragon.singleton.SingletonPerformanceTest 121 ConcurrentAccessTest - Complete one test[17:16:48.982] [INFO ] org.dragon.singleton.SingletonPerformanceTest 121 ConcurrentAccessTest - Complete one test[17:16:52.778] [INFO ] org.dragon.singleton.SingletonPerformanceTest 121 ConcurrentAccessTest - Complete one test[17:16:57.834] [INFO ] org.dragon.singleton.SingletonPerformanceTest 121 ConcurrentAccessTest - Complete one test[17:17:02.298] [INFO ] org.dragon.singleton.SingletonPerformanceTest 121 ConcurrentAccessTest - Complete one testSingleton Type First Creation (ms) Multiple Access (ms) Concurrent Access (ms) Memory Used (MB) ---------------------------------------------------------------------------------------------------------------OrderManager1 0.010 16.848 4217.333 0.000 OrderManager2 0.010 18.592 4340.869 0.000 OrderManager3 0.009 19.127 4824.581 0.000 OrderManager4 0.241 18.772 3743.032 0.000 OrderManager5 0.117 16.637 3558.995 0.000 [17:17:06.778] [INFO ] org.dragon.singleton.SingletonPerformanceTest 121 ConcurrentAccessTest - Complete one test[17:17:11.231] [INFO ] org.dragon.singleton.SingletonPerformanceTest 121 ConcurrentAccessTest - Complete one test[17:17:15.733] [INFO ] org.dragon.singleton.SingletonPerformanceTest 121 ConcurrentAccessTest - Complete one test[17:17:20.812] [INFO ] org.dragon.singleton.SingletonPerformanceTest 121 ConcurrentAccessTest - Complete one test[17:17:25.837] [INFO ] org.dragon.singleton.SingletonPerformanceTest 121 ConcurrentAccessTest - Complete one testSingleton Type First Creation (ms) Multiple Access (ms) Concurrent Access (ms) Memory Used (MB) ---------------------------------------------------------------------------------------------------------------OrderManager1 0.010 16.848 4281.649 0.000 OrderManager2 0.010 18.592 4849.279 0.000 OrderManager3 0.009 19.127 4782.224 0.000 OrderManager4 0.241 18.772 4267.228 0.000 OrderManager5 0.117 16.637 4233.907 0.000 进程已结束，退出代码为 0 可以去多跑几次，基本上最后一种枚举单例，性能属于最好的一批。并且也最安全。","link":"/Hexo/2024/06/06/2024-H1/2024-06-06-17-19-19/"},{"title":"22种常用设计模式示例代码","text":"仓库地址https://github.com/Xiamu-ssr/DesignPatternsPractice参考教程 refactoringguru设计模式-目录 创建型模式 软件包 复杂度 流行度 工厂方法 factorymethod ❄️ ⭐️⭐️⭐️ 抽象工厂 abstractfactory ❄️❄️ ⭐️⭐️⭐️ 生成器 builder ❄️❄️ ⭐️⭐️⭐️ 原型 prototype ❄️ ⭐️⭐️ 单例 singleton ❄️ ⭐️⭐️⭐️ 结构型模式 软件包 复杂度 流行度 适配器 adapter ❄️ ⭐️⭐️⭐️ 桥接 bridge ❄️❄️❄️ ⭐️ 组合 composite ❄️❄️ ⭐️⭐️ 装饰 decorator ❄️❄️ ⭐️⭐️ 外观 facade ❄️ ⭐️⭐️ 享元 flyweight ❄️❄️❄️ ⭐️ 代理 proxy ❄️❄️ ⭐️ 行为模式 软件包 复杂度 流行度 责任链 chainofresponsibility ❄️❄️ ⭐️ 命令 command ❄️ ⭐️⭐️⭐️ 迭代器 iterator ❄️❄️ ⭐️⭐️⭐️ 中介者 mediator ❄️❄️ ⭐️⭐️ 备忘录 memento ❄️❄️❄️ ⭐️ 观察者 observer ❄️❄️ ⭐️⭐️⭐️ 状态 state ❄️ ⭐️⭐️ 策略 strategy ❄️ ⭐️⭐️⭐️ 模版方法 templatemethod ❄️ ⭐️⭐️ 访问者 visitor ❄️❄️❄️ ⭐️","link":"/Hexo/2024/06/18/2024-H1/2024-06-18-16-28-24/"},{"title":"如何优雅的使用Github Action服务来将Hexo部署到Github Pages","text":"参考文章Bilibili视频教程-9分钟零成本搭建自动化部署个人博客(Hexo + Github Action + Page)Hexo官方文档利用 GitHub Action 自动部署 Hexo 博客Hexo主题-Icarus快速上手 前提条件当前PC环境中有Node和Git。版本可以参考Hexo文档。 文章中出现的yourusername为Github用户名，your-repo为仓库名。 1. 初始化Hexo安装脚手架，初始化hexo，这会新建blog文件夹，进入后安装依赖。 1234npm install -g hexo-clihexo init blogcd blognpm install 2. 初始化仓库可以选择利用VSCode等软件直接对项目开源到github仓库。 也可以手动去github创建一个空仓库，然后手动在命令行中推送。 12345git initgit remote add origin https://github.com/yourusername/your-repo.gitgit add .git commit -m &quot;Initial commit&quot;git push -u origin main 3. 创建Token在个人设置中新增一个Personal access tokens。至少要包含repo权限，然后记住token。这个token是给Github Action用的，Github Action会把Hexo编译部署到gh-pages分支。 随后在存放Hexo代码的仓库里把这个Token新增进去，名称为GH_TOKEN(随意，后面需要一致)。 4. 修改_config.yml在_config.yml中修改deploy字段。指示Hexo在deploy时的推送地址。 1234deploy: type: git repo: https://github.com/yourusername/your-repo.git branch: gh-pages 5. 配置Github Action工作流在.github文件夹下新增workflows文件夹，然后新增deploy.yml文件，内容如下。 里面有个node-version要和你本地的node一致。步骤大致意思就是使用ubuntu-latest作为基础环境，然后安装各种依赖，随后hexo generate生成博客网站静态文件夹，把这个文件夹推送到同一仓库的gh-pages分支。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950name: Deploy Hexo to GitHub Pageson: push: branches: - main # 当推送到 main 分支时触发jobs: build: runs-on: ubuntu-latest steps: - name: Checkout repository uses: actions/checkout@v2 with: submodules: false # 禁用子模块检查 - name: Setup Node.js uses: actions/setup-node@v2 with: node-version: '18' - name: Install Dependencies run: npm install - name: Install Hexo Git Deployer run: | npm install hexo-deployer-git --save npm install hexo-cli -g - name: Clean and Generate Static Files run: | hexo clean hexo generate - name: Configure Git run: | git config --global user.name 'github-actions[bot]' git config --global user.email 'github-actions[bot]@users.noreply.github.com' - name: Deploy to GitHub Pages env: GH_TOKEN: ${{ secrets.GH_TOKEN }} run: | cd public/ git init git add -A git commit -m &quot;Create by workflows&quot; git remote add origin https://${{ secrets.GH_TOKEN }}@github.com/yourusername/your-repo.git git push origin HEAD:gh-pages -f 6. 推送验证把刚才更新的所有文件都推送一遍，github就会触发工作流，然后去网站看工作流运转的如何。等一切运转完毕，就会发现仓库多出一个gh-pages分支。 7. 配置Github Pages在仓库settings中配置page来源为gh-pages分支即可。等待网站部署完毕，就可以看了。网站链接可以在settings的GitHub Pages看到，也可以去action里看到。 8. 修改Hexo主题样式以一个比较热门的主题为演示示例，参考地址https://github.com/ppoffice/hexo-theme-icarus。 若要使用NPM将Icarus安装为Node包，在你的Hexo站点根目录运行如下命令： 1npm install -S hexo-theme-icarus hexo-renderer-inferno 接下来，使用hexo命令修改主题为Icarus: 1hexo config theme icarus 会发现多出一个_config.icarus.yml文件。这是Icarus主题的配置文件。 最后推送到仓库，等待部署后，就可以了。 10. 添加文章你可以执行下列命令来创建一篇新文章或者新的页面。 1$ hexo new [layout] &lt;title&gt; 您可以在命令中指定文章的布局（layout），默认为 post，可以通过修改 _config.yml 中的 default_layout 参数来指定默认布局。 文章添加编辑后，现在只需要推送到仓库，那么github不仅会保存你的Hexo个人博客源码，还会自动更新个人博客静态页面到gh-pages，由此触发github-page功能来更新你的个人博客网站。 遇到了一些问题和方案1. 网站没有样式问题在网站打开F12，发现css等样式资源无法加载，仔细查看报错原因和请求地址，发现并不是当前仓库。 缺少仓库地址，所以把请求地址复制一份，并在后面添加上仓库名即可，这需要修改_config.yml中修改url字段。yourusername似乎为小写。 推送后等待工作流执行，查看结果。 12url: https://yourusername.github.io/your-reporoot: /your-repo/ 2. 图片不显示在_config.yml中设置 1post_asset_folder: true 意思是每个md博文会单独配套一个同名文件夹，用来存放图片。形如 1234source/_posts/├── my-new-post.md└── my-new-post/ └── example.jpg hexo提供三种语法 123{% asset_path slug %}{% asset_img slug [title] %}{% asset_link slug [title] %} 那么在md中可以这样引用图片 1{% asset_img example.jpg This is an example image %} 这样一来，部署的时候图片就不会不显示了，但是有个新的问题，我在本地编辑md的时候无法预览图片怎么办。 建议用VSCode下载插件vscode-hexo和Hexo Utils，随后在左边栏目就可以看到新Hexo Utils的新菜单，只要你的VSCode当前打开的文件夹是hexo的根目录，那么插件就会自动识别到，当你对md文件使用“侧边预览”时，图片就正常显示了。","link":"/Hexo/2024/06/19/2024-H1/2024-06-19-12-31-52/"},{"title":"实现Hexo新建博文时自带随机默认封面","text":"前提是选择的主题在Front-matter中支持cover和thumbnail，主题之间对于这两个属性的定义可能并不用，如果不适用，只需要根据逻辑修改脚本即可。 1. Hexo模版在scaffolds文件夹下，有三个md文件即模版文件，平时我们hexo new post &quot;title&quot;的时候就是基于post.md生成的。 1234scaffolds draft.md page.md post.md 将其修改为如下内容，补充属性，并添加2个特殊的字符串COVER_PLACEHOLDER和THUMBNAIL_PLACEHOLDER，作为占位符，方便替换。 123456789101112---title: {{ title }}date: {{ date }}comments: truecover: COVER_PLACEHOLDERthumbnail: THUMBNAIL_PLACEHOLDERtags: - 未分类categories: - 未分类description:--- 2. 准备封面和缩略图在source文件夹下新建gallery文件夹，并放入5张封面图和5张缩略图，封面建议1920*1080，缩略图建议200*200 。封面和缩略图是一一对应的。 1234567891011source\\gallery defaultCover1.png defaultCover2.png defaultCover3.png defaultCover4.png defaultCover5.png defaultThumbnail1.png defaultThumbnail2.png defaultThumbnail3.png defaultThumbnail4.png defaultThumbnail5.png 3. 新建博文脚本我们不再手动hexo new post来创建博文，而是使用脚本，可以在前后多一些自定义事件。 windowswindows系统可以使用以下powershell脚本来创建新博文MD，这会随机使用某一套封面和缩略图。 12345678910111213141516171819202122232425262728# 获取当前时间戳$timestamp = Get-Date -Format &quot;yyyy-MM-dd-HH-mm-ss&quot;# 创建带有时间戳的 Markdown 文件hexo new post $timestamp# 替换新创建文件中的标题$file = &quot;source/_posts/$timestamp.md&quot;# 随机选择封面和缩略图$randomIndex = Get-Random -Minimum 1 -Maximum 6$cover = &quot;/gallery/defaultCover$randomIndex.png&quot;$thumbnail = &quot;/gallery/defaultThumbnail$randomIndex.png&quot;# 读取文件内容，指定编码方式$mdContent = Get-Content $file -Raw -Encoding utf8# 替换标题和封面占位符$mdContent = $mdContent -replace 'cover: COVER_PLACEHOLDER', &quot;cover: $cover&quot;$mdContent = $mdContent -replace 'thumbnail: THUMBNAIL_PLACEHOLDER', &quot;thumbnail: $thumbnail&quot;# 将更新后的内容写回文件，指定编码方式Set-Content -Path $file -Value $mdContent -Encoding utf8Write-Output &quot;Post created: $file&quot;Write-Output &quot;Cover image: $cover&quot;Write-Output &quot;Thumbnail image: $thumbnail&quot; LinuxLiunx系统可以使用这个脚本。 123456789101112131415161718192021222324#!/bin/bash# 获取当前时间戳timestamp=$(date +%Y-%m-%d-%H-%M-%S)# 创建带有时间戳的 Markdown 文件hexo new post &quot;$timestamp&quot;# 替换新创建文件中的标题file=&quot;source/_posts/$timestamp.md&quot;# 随机选择封面和缩略图randomIndex=$(( (RANDOM % 5) + 1 ))cover=&quot;/gallery/defaultCover${randomIndex}.png&quot;thumbnail=&quot;/gallery/defaultThumbnail${randomIndex}.png&quot;# 替换封面和缩略图占位符sed -i &quot;s|cover: COVER_PLACEHOLDER|cover: $cover|&quot; &quot;$file&quot;sed -i &quot;s|thumbnail: THUMBNAIL_PLACEHOLDER|thumbnail: $thumbnail|&quot; &quot;$file&quot;echo &quot;Post created: $file&quot;echo &quot;Cover image: $cover&quot;echo &quot;Thumbnail image: $thumbnail&quot; 4. 效果展示","link":"/Hexo/2024/06/20/2024-H1/2024-06-20-15-46-45/"},{"title":"爬取CSDN博文到本地(包含图片，标签等信息)","text":"csdnToMD项目原作者：https://gitee.com/liushili888/csdn-is---mark-down 改进后仓库地址：https://github.com/Xiamu-ssr/csdnToMD 改进这里进行一定的改进，可以更准确获取时间，也可以选择图片的存放方式是否集中或分离到每篇文章的同名文件夹，以适应部分md扩展语法，比如{% asset_img 1.png %} 爬取结果截图 将CSDN文章转化为Markdown文档 很多情况下，我们需要将CSDN中的文章转化为markdown文档，直接复制全文是不可以的，CSDN不支持。 那有什么办法快速得到md文档？原理: 由于CSDN不是获取数据不是前后端分离的，所以无法根据接口获取文章的所有数据，它的数据是和页面元素组合在一起的，需要根据页面中的元素标签转化为markdown中的元素标签。 使用jsoup解析csdn文档 利用jericho-html、flexmark-all、jsoup、selenium等工具将html文档转化为markdown文档 使用: 去https://googlechromelabs.github.io/chrome-for-testing/下载chromedriver，解压后修改DynamicScraperTime函数的驱动地址。如果不下载驱动也可以，把String time = DynamicScraperTime(startUrl);的获取换成下一行被注释的就行，但是因为页面动态加载的原因，会无法获取准确的时间。 然后直接将CSDN文章的url放入crawler类即可 例如：获取单个文章markdown12345678public class Main { private static final String CSDN_URL = &quot;https://blog.csdn.net/m0_51390969/&quot;; public static void main(String[] args) { AbstractCrawler crawler = new CsdnCrawler(); crawler.crawlOne(&quot;https://blog.csdn.net/m0_51390969&quot;, &quot;131172667&quot;); }} 获取所有的文章markdown12345678public class Main { private static final String CSDN_URL = &quot;https://blog.csdn.net/m0_51390969/&quot;; public static void main(String[] args) { AbstractCrawler crawler = new CsdnCrawler(); crawler.crawl(CSDN_URL); }} 项目中待解决的问题 TODO ‘&gt; ’标签中包含代码块，需要处理TODO 代码中格式待处理TODO 增加GUI页面TODO 公式、表格标签的处理","link":"/Hexo/2024/06/20/2024-H1/2024-06-20-21-37-36/"},{"title":"Nginx基础概念和常用操作","text":"1. 安装、启动、连接直接拿docker安装，拉取镜像，运行，开放端口。 1docker pull nginx:stable-perl 虽然在容器中性能有所损失，但是方便，加快学习进度。 启动后浏览器访问localhost，写着Welcome等欢迎语，就是启动成功了。 在VSCode下载一些Docker常用插件，然后就可以拿VSCode直接连上’正在运行的容器’，和连接Linux服务器一样。 输入nginx -V，查看nginx信息，包括安装目录、编译参数、配置文件位置、日志文件位置等信息。可以看到配置文件位于--conf-path=/etc/nginx/nginx.conf 。 123456root@f4f6c922d837:/# nginx -Vnginx version: nginx/1.26.1built by gcc 12.2.0 (Debian 12.2.0-14) built with OpenSSL 3.0.11 19 Sep 2023TLS SNI support enabledconfigure arguments: --prefix=/etc/nginx --sbin-path=/usr/sbin/nginx --modules-path=/usr/lib/nginx/modules --conf-path=/etc/nginx/nginx.conf --error-log-path=/var/log/nginx/error.log --http-log-path=/var/log/nginx/access.log --pid-path=/var/run/nginx.pid --lock-path=/var/run/nginx.lock --http-client-body-temp-path=/var/cache/nginx/client_temp --http-proxy-temp-path=/var/cache/nginx/proxy_temp --http-fastcgi-temp-path=/var/cache/nginx/fastcgi_temp --http-uwsgi-temp-path=/var/cache/nginx/uwsgi_temp --http-scgi-temp-path=/var/cache/nginx/scgi_temp --user=nginx --group=nginx --with-compat --with-file-aio --with-threads --with-http_addition_module --with-http_auth_request_module --with-http_dav_module --with-http_flv_module --with-http_gunzip_module --with-http_gzip_static_module --with-http_mp4_module --with-http_random_index_module --with-http_realip_module --with-http_secure_link_module --with-http_slice_module --with-http_ssl_module --with-http_stub_status_module --with-http_sub_module --with-http_v2_module --with-http_v3_module --with-mail --with-mail_ssl_module --with-stream --with-stream_realip_module --with-stream_ssl_module --with-stream_ssl_preread_module --with-cc-opt='-g -O2 -ffile-prefix-map=/data/builder/debuild/nginx-1.26.1/debian/debuild-base/nginx-1.26.1=. -fstack-protector-strong -Wformat -Werror=format-security -Wp,-D_FORTIFY_SOURCE=2 -fPIC' --with-ld-opt='-Wl,-z,relro -Wl,-z,now -Wl,--as-needed -pie' 2. 快速尝试部署网站查看nginx配置文件，可以找到如下部分。 1234567891011121314server { listen 80; listen [::]:80; server_name localhost; location / { root /usr/share/nginx/html; index index.html index.htm; } error_page 500 502 503 504 /50x.html; location = /50x.html { root /usr/share/nginx/html; }} 这意味着，nginx 把所有对服务器根路径的请求，代理到 /usr/share/nginx/html 目录下，并且把 index.html 或 index.htm 作为默认页面。 如果你使用Vue或者Hex开发网站，它们的打包输出目录，大致结构分别如下 1234567dist/├── css/│ └── app.12345.css├── js/│ └── app.12345.js├── index.html└── favicon.ico 12345678910public/├── css/│ └── style.css├── js/│ └── script.js├── index.html├── about/│ └── index.html└── archives/ └── index.html 你只需要把dist或者public下的所有文件，直接复制到/usr/share/nginx/html目录下，重启nginx即可。 3. 配置文件这个版本的nginx自带2个配置文件，首先是nginx.conf。 如果你修改了配置文件，可以用nginx -t来校验配置是否合法。然后使用nginx -s reload来重新加载配置文件。 1. nginx.conf全局配置12345user nginx;worker_processes auto;error_log /var/log/nginx/error.log notice;pid /var/run/nginx.pid; user 指令: 用法：user &lt;username&gt;; 描述：指定 Nginx 运行时使用的系统用户。 示例：user nginx; 表示使用 nginx 用户。 worker_processes 指令: 用法：worker_processes &lt;number|auto&gt;; 描述：设置工作进程数，auto 会自动根据 CPU 核心数设置。 示例：worker_processes 4; 表示使用 4 个工作进程。 error_log 指令: 用法：error_log &lt;file&gt; &lt;level&gt;; 描述：设置错误日志的路径和日志级别。 日志级别选项： debug：调试信息 info：一般信息 notice：通知信息（默认） warn：警告信息 error：错误信息 crit：严重错误信息 alert：需要立即处理的问题 emerg：紧急情况 示例：error_log /var/log/nginx/error.log notice; 表示记录通知级别及以上的日志。 pid 指令: 用法：pid &lt;file&gt;; 描述：指定存储 Nginx 进程 ID 的文件路径。 示例：pid /var/run/nginx.pid; 表示将 PID 存储在 /var/run/nginx.pid 文件中。 可能改动的部分： worker_processes auto; 自动设置为 CPU 核心数，适用于大多数情况。 可以手动设置为特定的进程数以微调性能，但一般不需要。 事件模块123events { worker_connections 1024;} worker_connections 指令: 用法：worker_connections &lt;number&gt;; 描述：设置每个工作进程允许的最大连接数。 示例：worker_connections 1024; 表示每个工作进程允许最多 1024 个连接。 可能改动的部分： worker_connections 1024; 默认设置为 1024，适用于大多数小到中型网站。 对于高流量网站，可以增加连接数，以提高并发处理能力。 需要根据系统的 ulimit 设置进行调整，确保系统支持更多的连接。 HTTP 模块12345678910111213141516171819http { include /etc/nginx/mime.types; default_type application/octet-stream; log_format main '$remote_addr - $remote_user [$time_local] &quot;$request&quot; ' '$status $body_bytes_sent &quot;$http_referer&quot; ' '&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;'; access_log /var/log/nginx/access.log main; sendfile on; #tcp_nopush on; keepalive_timeout 65; #gzip on; include /etc/nginx/conf.d/*.conf;} include 指令: 用法：include &lt;file|directory&gt;; 描述：包含指定的文件或目录下的所有配置文件。 示例：include /etc/nginx/mime.types; 包含 MIME 类型配置文件。 default_type 指令: 用法：default_type &lt;MIME-type&gt;; 描述：设置默认的 MIME 类型。 示例：default_type application/octet-stream; 表示未能确定文件类型时使用 application/octet-stream。 log_format 指令: 用法：log_format &lt;name&gt; &lt;format&gt;; 描述：定义日志格式。 示例： 123log_format main '$remote_addr - $remote_user [$time_local] &quot;$request&quot; ' '$status $body_bytes_sent &quot;$http_referer&quot; ' '&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;'; 定义名为 main 的日志格式。 access_log 指令: 用法：access_log &lt;file&gt; &lt;format&gt;; 描述：设置访问日志的路径和日志格式。 示例：access_log /var/log/nginx/access.log main; 使用 main 格式记录访问日志。 sendfile 指令: 用法：sendfile &lt;on|off&gt;; 描述：启用或禁用 sendfile 选项，用于提高文件传输效率。 示例：sendfile on; 启用 sendfile。 tcp_nopush 指令: 用法：tcp_nopush &lt;on|off&gt;; 描述：用于优化传输数据时的 TCP 性能，通常与 sendfile 一起使用。 示例：#tcp_nopush on; 默认注释掉。 keepalive_timeout 指令: 用法：keepalive_timeout &lt;timeout&gt;; 描述：设置保持客户端连接的超时时间，单位是秒。 示例：keepalive_timeout 65; 设置超时时间为 65 秒。 gzip 指令: 用法：gzip &lt;on|off&gt;; 描述：启用或禁用 gzip 压缩。 示例：#gzip on; 默认注释掉。 include指令 用法：include &lt;file|directory&gt;; 描述：include 指令用于包含其他配置文件或目录中的所有配置文件。这可以帮助将配置文件分割成更小的部分，以便于管理和维护。 示例：include /etc/nginx/mime.types;：包含 MIME 类型配置文件。include /etc/nginx/conf.d/*.conf;：包含 /etc/nginx/conf.d/ 目录下的所有以 .conf 结尾的配置文件。 可能改动的部分： keepalive_timeout 65; 默认设置为 65 秒，适用于大多数情况。 对于高并发的场景，可以适当调低以减少资源占用。 tcp_nopush on; 通常注释掉，如果启用，可以优化数据传输，尤其是在发送大文件时。 启用 tcp_nopush 后，Nginx 会尝试将数据块一次性发送到网络，而不是逐个包地发送，从而减少包的数量，提高传输效率。 通常与sendfile on;一起使用。启用 sendfile 后，数据在内核空间中直接从一个文件描述符传输到另一个文件描述符，避免了在用户空间和内核空间之间的多次拷贝，从而提高了传输效率。 gzip on; 通常开启后，可以启用 gzip 压缩以减少传输数据量，提高传输速度。 启用后还需配置 gzip_types 和其他参数，以确保正确压缩所需的文件类型。如 1234http { gzip on; gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript;} 其他 gzip 配置选项： gzip_min_length：设置压缩的最小文件大小。 gzip_comp_level：设置压缩级别（1-9），级别越高压缩率越大，但消耗的 CPU 资源更多。 gzip_buffers：设置用于存储压缩结果的缓冲区大小。 gzip_vary：设置 Vary: Accept-Encoding 响应头，指示代理服务器和浏览器缓存可以根据请求的 Accept-Encoding 头进行不同的缓存。 Gzip 压缩是通过压缩算法（如 DEFLATE）将 HTTP 响应内容压缩成更小的体积，然后再发送给客户端。解压缩的过程是nginx和浏览器自动完成的。 性能优化建议 **增加 worker_connections**： 提高每个工作进程的最大连接数可以显著提升 Nginx 的并发处理能力。 需要确保系统的文件描述符限制足够高。 启用 gzip 压缩： 减少传输数据量，尤其适用于文本类型的资源（如 HTML、CSS、JavaScript）。 配置示例：nginx复制代码gzip on; gzip_types text/plain text/css application/json application/javascript text/xml application/xml application/xml+rss text/javascript; **优化 keepalive_timeout**： 在高并发情况下，适当调低 keepalive 超时时间以减少长时间占用连接资源。 **使用 tcp_nopush 和 tcp_nodelay**： 对于需要优化数据传输性能的场景，可以启用 tcp_nopush 和 tcp_nodelay。 2. default.conf好的，让我们对 default.conf 文件的每一行进行解析： server 块123456789101112131415161718192021server { listen 80; listen [::]:80; server_name localhost; #access_log /var/log/nginx/host.access.log main; location / { root /usr/share/nginx/html; index index.html index.htm; } #error_page 404 /404.html; # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; location = /50x.html { root /usr/share/nginx/html; }} 基本设置 **server { ... }**： 定义一个虚拟服务器块，包含服务器的配置。 **listen 80;**： 监听 IPv4 的 80 端口，用于处理 HTTP 请求。 **listen [::]:80;**： 监听 IPv6 的 80 端口，用于处理 HTTP 请求。 **server_name localhost;**： 定义服务器的名称为 localhost，用于匹配请求的 Host 头。 日志设置 **#access_log /var/log/nginx/host.access.log main;**： 配置访问日志的路径和格式，此处被注释掉。如果启用，将使用 main 日志格式记录访问日志。 根路径设置 **location / { ... }**： 配置根路径（即所有请求）的处理方式。 **root /usr/share/nginx/html;**： 指定请求的根目录为 /usr/share/nginx/html。 **index index.html index.htm;**： 指定默认的索引文件为 index.html 或 index.htm。 4. 反向代理正向代理是代理客户端，客户端对于服务端来说是不可见的。 反向代理是代理服务端，服务端对于客户端来说是不可见的。 1. 模拟3个Web1docker pull python:3.9-slim 在桌面或任意地方新建app.py，内容为 123456789101112from flask import Flaskimport osapp = Flask(__name__)@app.route('/')def hello(): return f&quot;Hello from the backend server running on port {os.environ.get('PORT')}!&quot;if __name__ == &quot;__main__&quot;: app.run(host='0.0.0.0', port=int(os.environ.get('PORT', 5000))) 启动3个python容器，模拟3个web服务。 12345678C:\\Users\\mumu\\Desktop&gt;docker run --name web1 -d -e PORT=8081 -p 8081:8081 -v /c/Users/mumu/Desktop/app.py:/app/app.py python:3.9-slim sh -c &quot;pip install flask &amp;&amp; python /app/app.py&quot;ab2ded77eafa82fbf4027f5714e5cb71bcb9775696f0e8c5423a70a7916a80acC:\\Users\\mumu\\Desktop&gt;docker run --name web2 -d -e PORT=8082 -p 8082:8082 -v /c/Users/mumu/Desktop/app.py:/app/app.py python:3.9-slim sh -c &quot;pip install flask &amp;&amp; python /app/app.py&quot;e6c5321ea3926157dc2f2d9ed38df53c715da51c496c5ff0e7ff0c4e68c85696C:\\Users\\mumu\\Desktop&gt;docker run --name web3 -d -e PORT=8083 -p 8083:8083 -v /c/Users/mumu/Desktop/app.py:/app/app.py python:3.9-slim sh -c &quot;pip install flask &amp;&amp; python /app/app.py&quot;f0bea8ac956af515fe35159fe94c86e919dfd566b782d06641472621a6299e26 需要保证nginx和3个python在同一个docker网络中，默认应该都是bridge。 2. 链接使用docker inspect bridge查看刚才3个容器的ip。然后修改nginx的default.conf文件。 1234567891011121314151617181920212223242526upstream backend { server 172.17.0.3:8081; server 172.17.0.4:8082; server 172.17.0.5:8083;}server { listen 80; listen [::]:80; server_name localhost; location / { root /usr/share/nginx/html; index index.html index.htm; } location /app { proxy_pass http://backend/; } error_page 500 502 503 504 /50x.html; location = /50x.html { root /usr/share/nginx/html; }} **upstream backend**：定义了一个名为 backend 的上游服务器组。 **location /app { ... }**：配置如何处理以 /app 开头的所有请求。 **proxy_pass http://backend/;**：将这些请求代理到上游服务器组 backend。请求的路径 /app 的前缀将被去除，然后传递给上游服务器。例如，/app/foo 将被代理为 /foo。 重启服务。 访问localhost/app并多次刷新试试。 5. 负载均衡在不断刷新页面会发现，反向代理是以“轮询”的方式，将请求分发到3个web服务之一的。 除了轮询之外，还有以下方式。 1. 加权轮询，Weighted Round Robin可以为不同的服务器设置权重，权重越高，服务器被请求的概率越大。 12345upstream backend { server 172.17.0.3:8081 weight=3; server 172.17.0.4:8082 weight=2; server 172.17.0.5:8083 weight=1;} weight默认为1 。 2. 最少连接，Least Connections将请求分发给当前连接数最少的服务器，适用于处理时间长、连接占用多的请求。 123456upstream backend { least_conn; server 172.17.0.3:8081; server 172.17.0.4:8082; server 172.17.0.5:8083;} 3. IP哈希，IP Hash根据客户端 IP 地址进行哈希计算，保证同一客户端的请求总是转发到同一台服务器，适用于会话保持。 123456upstream backend { ip_hash; server 172.17.0.3:8081; server 172.17.0.4:8082; server 172.17.0.5:8083;} 4. 哈希，Hash根据自定义的键值进行哈希计算来分发请求。 123456upstream backend { hash $request_uri; server 172.17.0.3:8081; server 172.17.0.4:8082; server 172.17.0.5:8083;} 可以使用以下变量作为键值： $remote_addr：客户端 IP 地址 $request_uri：请求的 URI $http_cookie：请求的 Cookie ip_hash和hash $remote_addr一样都可以实现同一个客户端的请求分配到同一个后端服务器。但是一般这种情况使用前者更多。 6. HTTPS首先要安装有openssl，然后创建一个存放证书和私钥的文件夹，比如mkdir C:\\nginx\\ssl 执行 1openssl req -x509 -nodes -days 365 -newkey rsa:2048 -keyout C:\\nginx\\ssl\\nginx-selfsigned.key -out C:\\nginx\\ssl\\nginx-selfsigned.crt 按问题填写信息，就可以。 得到2个文件后，复制到容器中，比如/etc/nginx/ssl目录下，然后再default.conf中添加一个server块，如下 12345678910111213141516171819202122server { listen 443 ssl; listen [::]:443 ssl; server_name localhost; ssl_certificate /etc/nginx/ssl/nginx-selfsigned.crt; ssl_certificate_key /etc/nginx/ssl/nginx-selfsigned.key; location / { root /usr/share/nginx/html; index index.html index.htm; } location /app { proxy_pass http://backend/; } error_page 500 502 503 504 /50x.html; location = /50x.html { root /usr/share/nginx/html; }} 打开浏览器访问https://localhost 7. 虚拟主机一个server块就是一个虚拟主机。 新建一个conf文件和default.conf同一目录。 12345678910111213141516171819202122232425upstream backend2 { server 172.17.0.3:8081 weight=2; server 172.17.0.4:8082 weight=2; server 172.17.0.5:8083 weight=6;}server { listen 81; listen [::]:81; server_name localhost; location / { root /usr/share/nginx/html; index index.html index.htm; } location /app { proxy_pass http://backend2/; } error_page 500 502 503 504 /50x.html; location = /50x.html { root /usr/share/nginx/html; }} 重启服务，浏览器访问http://localhost:81/app 。 利用这种方式，我们可以在同一台机器上部署多个网站。","link":"/Hexo/2024/06/23/2024-H1/2024-06-23-15-47-04/"},{"title":"Typora + Hexo 图片路径问题(Typedown)","text":"1. 冲突来源Hexo上对于图片在md中的引用，使用了post_asset_folder: true配置，来更好的管理图片。当一篇名为xxx.md的文章引用1.png图片时，默认让1.png保持在xxx文件夹下，那么md中即可使用{% asset_img 1.png %}来引用图片。 而typora中，或者Typedown中，复制图片时，一般使用![](./xxx/1.png)。 2. 解决思路 让每次图片复制到md时，typora都能将其自动放入和md文件同名同级文件夹下。 然后在Hexo编译前使用脚本将![](./xxx/1.png)转化为{% asset_img 1.png %}，并且保持md源文件不变。 3. 实现1. typora图片路径 这很简单。 但是如果你是typedown就会发现，不支持解析${filename}，那么只有每次写的时候手动选择同级同名文件夹了。 2. hexo脚本在scripts\\before_generate.js中写入 1234567891011121314151617181920212223242526272829303132333435363738394041424344// const path = require('path');// hexo.extend.filter.register('before_post_render', data =&gt; {// if (data.layout === 'post') {// const postName = path.basename(data.source, '.md');// const imgRegex = new RegExp(`!\\\\[.*?\\\\]\\\\(\\\\.\\\\/${postName}\\\\/([^\\\\)]+)\\\\)`, 'g');// data.content = data.content.replace(imgRegex, (match, p1) =&gt; {// return `{% asset_img ${p1} %}`;// });// }// return data;// });const path = require('path');hexo.extend.filter.register('before_post_render', data =&gt; { if (data.layout === 'post') { const postName = path.basename(data.source, '.md'); const imgRegex = new RegExp(`!\\\\[.*?\\\\]\\\\(\\\\.\\\\/${postName}\\\\/([^\\\\)]+)\\\\)`, 'g'); // 原始内容 const originalContent = data.content; // 转换内容 let match; let modifiedContent = originalContent; while ((match = imgRegex.exec(originalContent)) !== null) { const originalLine = match[0]; const newLine = `{% asset_img ${match[1]} %}`; // 打印转换前后的对比 console.log(`Original line: ${originalLine}`); console.log(`Converted line: ${newLine}\\n`); // 进行替换 modifiedContent = modifiedContent.replace(originalLine, newLine); } // 更新数据内容 data.content = modifiedContent; } return data;}); 被注释掉了是不会打印日志对比前后修改的，没注释的会。 执行hexo clean和hexo generate，然后hexo server看看效果。","link":"/Hexo/2024/06/23/2024-H1/2024-06-23-21-05-01/"},{"title":"Hexo结合多个主题扩展为Gallery画廊并实现文章加密","text":"可能参考的文章： 如何优雅的使用Github Action服务来将Hexo部署到Github Pages - Hexo 当前PC环境中有Node和Git。版本可以参考Hexo文档。 文章中出现的yourusername为Github用户名，your-repo为仓库名。 1. 初始化新建一个项目根目录HexoNote，并初始化hexo（主Hexo）。然后新建一个子文件夹hexoB，在里面也初始化Hexo（副Hexo），用于存放第二个hexo。副Hexo的主题是一个简单的主题，很适合作为画廊。 123456根目录 - public - hexoB - public - ... - ... 把项目传达github，私有仓库，名为HexoNotePrivate。 假设存放Hexo编译后的静态文件夹的仓库名为HexoNote，公共的public。 我们利用github action编译HexoNotePrivate里面的2个hexo，然后整合静态文件夹，推送到HexoNote仓库，HexoNote配置github pages。 2. 安装加密1npm install --save hexo-blog-encrypt 在主Hexo的_config.yml文件新增配置 12345678# Securityencrypt: # hexo-blog-encrypt abstract: 这是一篇加密文章，需要密码才能继续阅读。 message: 当前文章暂不对外可见，请输入密码后查看！ tags: - {name: private, password: MKL1009} wrong_pass_message: 抱歉，您输入的密码错误，请检查后重新输入。 wrong_hash_message: 抱歉, 当前文章不能被校验, 不过您还是可以看看解密后的内容。 在md中的tags中新增private即可设置为加密文章。 12tags: - private 3. 配置文件把主Hexo的_config.yml文件修改 12url: https://yourusername.github.io/HexoNoteroot: /HexoNote/ 并且在主Hexo的主题中新增菜单（导航栏）的一个元素，相对地址为/gallery，具体按主题的文档设置 1234567navbar: # Navigation menu items menu: Home: / Archives: /archives Gallery: /gallery About: /about 把副Hexo的_config.yml文件修改 12url: https://yourusername.github.io/HexoNote/galleryroot: /HexoNote/gallery/ 4. 创建Token详情看顶部的文章链接，把token放入private私有仓库。 5. 新建公开仓库新建公开仓库HexoNote，作为github pages的代码仓库。 6. 工作流新建文件.github\\workflows\\deploy.yml node版本和推送地址要按情况修改。 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566name: Deploy Hexo to GitHub Pageson: push: branches: - main # 当推送到 main 分支时触发jobs: build: runs-on: ubuntu-latest steps: - name: Checkout repository uses: actions/checkout@v2 with: submodules: false # 禁用子模块检查 - name: Setup Node.js uses: actions/setup-node@v2 with: node-version: '18' - name: Install Dependencies run: npm install - name: Install Hexo Git Deployer run: | npm install hexo-deployer-git --save npm install hexo-cli -g - name: Clean and Generate Static Files for Theme A run: | hexo clean hexo generate - name: Generate Static Files for Theme B run: | cd hexoB npm install npm install hexo-deployer-git --save npm install hexo-cli -g hexo clean hexo generate cd .. - name: Move Theme B Output to Gallery run: | mv hexoB/public public/gallery - name: Configure Git run: | git config --global user.name 'github-actions[bot]' git config --global user.email 'github-actions[bot]@users.noreply.github.com' - name: Deploy to GitHub Pages env: GH_TOKEN: ${{ secrets.GH_TOKEN }} run: | cd public/ git init git add -A git commit -m &quot;Create by workflows&quot; git remote add origin https://${{ secrets.GH_TOKEN }}@github.com/yourusername/HexoNote.git git push origin HEAD:gh-pages -f 7. 实现效果1. 加密 2. 画廊B主题","link":"/Hexo/2024/06/25/2024-H1/2024-06-25-19-03-04/"}],"tags":[{"name":"docker","slug":"docker","link":"/Hexo/tags/docker/"},{"name":"运维","slug":"运维","link":"/Hexo/tags/%E8%BF%90%E7%BB%B4/"},{"name":"容器","slug":"容器","link":"/Hexo/tags/%E5%AE%B9%E5%99%A8/"},{"name":"c++","slug":"c","link":"/Hexo/tags/c/"},{"name":"排序算法","slug":"排序算法","link":"/Hexo/tags/%E6%8E%92%E5%BA%8F%E7%AE%97%E6%B3%95/"},{"name":"java","slug":"java","link":"/Hexo/tags/java/"},{"name":"hadoop","slug":"hadoop","link":"/Hexo/tags/hadoop/"},{"name":"ambari","slug":"ambari","link":"/Hexo/tags/ambari/"},{"name":"大数据","slug":"大数据","link":"/Hexo/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"linux","slug":"linux","link":"/Hexo/tags/linux/"},{"name":"vue.js","slug":"vue-js","link":"/Hexo/tags/vue-js/"},{"name":"前端","slug":"前端","link":"/Hexo/tags/%E5%89%8D%E7%AB%AF/"},{"name":"javascript","slug":"javascript","link":"/Hexo/tags/javascript/"},{"name":"typescript","slug":"typescript","link":"/Hexo/tags/typescript/"},{"name":"服务器","slug":"服务器","link":"/Hexo/tags/%E6%9C%8D%E5%8A%A1%E5%99%A8/"},{"name":"spring boot","slug":"spring-boot","link":"/Hexo/tags/spring-boot/"},{"name":"mysql","slug":"mysql","link":"/Hexo/tags/mysql/"},{"name":"redis","slug":"redis","link":"/Hexo/tags/redis/"},{"name":"echarts","slug":"echarts","link":"/Hexo/tags/echarts/"},{"name":"ecmascript","slug":"ecmascript","link":"/Hexo/tags/ecmascript/"},{"name":"开发语言","slug":"开发语言","link":"/Hexo/tags/%E5%BC%80%E5%8F%91%E8%AF%AD%E8%A8%80/"},{"name":"web","slug":"web","link":"/Hexo/tags/web/"},{"name":"excel","slug":"excel","link":"/Hexo/tags/excel/"},{"name":"后端","slug":"后端","link":"/Hexo/tags/%E5%90%8E%E7%AB%AF/"},{"name":"vue","slug":"vue","link":"/Hexo/tags/vue/"},{"name":"mybatis","slug":"mybatis","link":"/Hexo/tags/mybatis/"},{"name":"正则表达式","slug":"正则表达式","link":"/Hexo/tags/%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F/"},{"name":"springboot","slug":"springboot","link":"/Hexo/tags/springboot/"},{"name":"nginx","slug":"nginx","link":"/Hexo/tags/nginx/"},{"name":"负载均衡","slug":"负载均衡","link":"/Hexo/tags/%E8%B4%9F%E8%BD%BD%E5%9D%87%E8%A1%A1/"},{"name":"springcloud","slug":"springcloud","link":"/Hexo/tags/springcloud/"},{"name":"css3","slug":"css3","link":"/Hexo/tags/css3/"},{"name":"ubuntu","slug":"ubuntu","link":"/Hexo/tags/ubuntu/"},{"name":"elasticsearch","slug":"elasticsearch","link":"/Hexo/tags/elasticsearch/"},{"name":"jenkins","slug":"jenkins","link":"/Hexo/tags/jenkins/"},{"name":"架构","slug":"架构","link":"/Hexo/tags/%E6%9E%B6%E6%9E%84/"},{"name":"Kafka","slug":"Kafka","link":"/Hexo/tags/Kafka/"},{"name":"kafka","slug":"kafka","link":"/Hexo/tags/kafka/"},{"name":"zookeeper","slug":"zookeeper","link":"/Hexo/tags/zookeeper/"},{"name":"集群","slug":"集群","link":"/Hexo/tags/%E9%9B%86%E7%BE%A4/"},{"name":"未分类","slug":"未分类","link":"/Hexo/tags/%E6%9C%AA%E5%88%86%E7%B1%BB/"},{"name":"分区","slug":"分区","link":"/Hexo/tags/%E5%88%86%E5%8C%BA/"},{"name":"拦截器","slug":"拦截器","link":"/Hexo/tags/%E6%8B%A6%E6%88%AA%E5%99%A8/"},{"name":"生产者","slug":"生产者","link":"/Hexo/tags/%E7%94%9F%E4%BA%A7%E8%80%85/"},{"name":"幂等","slug":"幂等","link":"/Hexo/tags/%E5%B9%82%E7%AD%89/"},{"name":"事务","slug":"事务","link":"/Hexo/tags/%E4%BA%8B%E5%8A%A1/"},{"name":"存储","slug":"存储","link":"/Hexo/tags/%E5%AD%98%E5%82%A8/"},{"name":"Consumer","slug":"Consumer","link":"/Hexo/tags/Consumer/"},{"name":"消费者","slug":"消费者","link":"/Hexo/tags/%E6%B6%88%E8%B4%B9%E8%80%85/"},{"name":"git","slug":"git","link":"/Hexo/tags/git/"},{"name":"intellij-idea","slug":"intellij-idea","link":"/Hexo/tags/intellij-idea/"},{"name":"缓存","slug":"缓存","link":"/Hexo/tags/%E7%BC%93%E5%AD%98/"},{"name":"openresty","slug":"openresty","link":"/Hexo/tags/openresty/"},{"name":"rabbitmq","slug":"rabbitmq","link":"/Hexo/tags/rabbitmq/"},{"name":"ruby","slug":"ruby","link":"/Hexo/tags/ruby/"},{"name":"分布式","slug":"分布式","link":"/Hexo/tags/%E5%88%86%E5%B8%83%E5%BC%8F/"},{"name":"postman","slug":"postman","link":"/Hexo/tags/postman/"},{"name":"spring","slug":"spring","link":"/Hexo/tags/spring/"},{"name":"spring cloud","slug":"spring-cloud","link":"/Hexo/tags/spring-cloud/"},{"name":"gateway","slug":"gateway","link":"/Hexo/tags/gateway/"},{"name":"hdfs","slug":"hdfs","link":"/Hexo/tags/hdfs/"},{"name":"windows","slug":"windows","link":"/Hexo/tags/windows/"},{"name":"数据库","slug":"数据库","link":"/Hexo/tags/%E6%95%B0%E6%8D%AE%E5%BA%93/"},{"name":"JWT","slug":"JWT","link":"/Hexo/tags/JWT/"},{"name":"RSA","slug":"RSA","link":"/Hexo/tags/RSA/"},{"name":"web安全","slug":"web安全","link":"/Hexo/tags/web%E5%AE%89%E5%85%A8/"},{"name":"Spring Security","slug":"Spring-Security","link":"/Hexo/tags/Spring-Security/"},{"name":"微服务","slug":"微服务","link":"/Hexo/tags/%E5%BE%AE%E6%9C%8D%E5%8A%A1/"},{"name":"spring security","slug":"spring-security","link":"/Hexo/tags/spring-security/"},{"name":"OAuth2.1","slug":"OAuth2-1","link":"/Hexo/tags/OAuth2-1/"},{"name":"springamqp","slug":"springamqp","link":"/Hexo/tags/springamqp/"},{"name":"锁","slug":"锁","link":"/Hexo/tags/%E9%94%81/"},{"name":"jvm","slug":"jvm","link":"/Hexo/tags/jvm/"},{"name":"视频","slug":"视频","link":"/Hexo/tags/%E8%A7%86%E9%A2%91/"},{"name":"文件系统","slug":"文件系统","link":"/Hexo/tags/%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"name":"分布式文件系统","slug":"分布式文件系统","link":"/Hexo/tags/%E5%88%86%E5%B8%83%E5%BC%8F%E6%96%87%E4%BB%B6%E7%B3%BB%E7%BB%9F/"},{"name":"restful","slug":"restful","link":"/Hexo/tags/restful/"},{"name":"ruoyi","slug":"ruoyi","link":"/Hexo/tags/ruoyi/"},{"name":"Vue3","slug":"Vue3","link":"/Hexo/tags/Vue3/"},{"name":"支付","slug":"支付","link":"/Hexo/tags/%E6%94%AF%E4%BB%98/"},{"name":"支付宝","slug":"支付宝","link":"/Hexo/tags/%E6%94%AF%E4%BB%98%E5%AE%9D/"},{"name":"SpringBoot","slug":"SpringBoot","link":"/Hexo/tags/SpringBoot/"},{"name":"word","slug":"word","link":"/Hexo/tags/word/"},{"name":"重构","slug":"重构","link":"/Hexo/tags/%E9%87%8D%E6%9E%84/"},{"name":"单例模式","slug":"单例模式","link":"/Hexo/tags/%E5%8D%95%E4%BE%8B%E6%A8%A1%E5%BC%8F/"},{"name":"枚举单例","slug":"枚举单例","link":"/Hexo/tags/%E6%9E%9A%E4%B8%BE%E5%8D%95%E4%BE%8B/"},{"name":"双检锁","slug":"双检锁","link":"/Hexo/tags/%E5%8F%8C%E6%A3%80%E9%94%81/"},{"name":"设计模式","slug":"设计模式","link":"/Hexo/tags/%E8%AE%BE%E8%AE%A1%E6%A8%A1%E5%BC%8F/"},{"name":"个人博客","slug":"个人博客","link":"/Hexo/tags/%E4%B8%AA%E4%BA%BA%E5%8D%9A%E5%AE%A2/"},{"name":"网站","slug":"网站","link":"/Hexo/tags/%E7%BD%91%E7%AB%99/"},{"name":"Hexo","slug":"Hexo","link":"/Hexo/tags/Hexo/"},{"name":"爬虫","slug":"爬虫","link":"/Hexo/tags/%E7%88%AC%E8%99%AB/"},{"name":"博客","slug":"博客","link":"/Hexo/tags/%E5%8D%9A%E5%AE%A2/"},{"name":"Nginx","slug":"Nginx","link":"/Hexo/tags/Nginx/"},{"name":"反向代理","slug":"反向代理","link":"/Hexo/tags/%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86/"},{"name":"md","slug":"md","link":"/Hexo/tags/md/"},{"name":"hexo","slug":"hexo","link":"/Hexo/tags/hexo/"},{"name":"github","slug":"github","link":"/Hexo/tags/github/"}],"categories":[{"name":"SpringBoot3","slug":"SpringBoot3","link":"/Hexo/categories/SpringBoot3/"},{"name":"其他","slug":"其他","link":"/Hexo/categories/%E5%85%B6%E4%BB%96/"},{"name":"Docker","slug":"SpringBoot3/Docker","link":"/Hexo/categories/SpringBoot3/Docker/"},{"name":"JavaSE","slug":"JavaSE","link":"/Hexo/categories/JavaSE/"},{"name":"大数据","slug":"大数据","link":"/Hexo/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/"},{"name":"Front-End","slug":"Front-End","link":"/Hexo/categories/Front-End/"},{"name":"SpringBoot2","slug":"SpringBoot2","link":"/Hexo/categories/SpringBoot2/"},{"name":"Utils","slug":"Utils","link":"/Hexo/categories/Utils/"},{"name":"SpringCloud","slug":"SpringCloud","link":"/Hexo/categories/SpringCloud/"},{"name":"Vue","slug":"Front-End/Vue","link":"/Hexo/categories/Front-End/Vue/"},{"name":"未分类","slug":"未分类","link":"/Hexo/categories/%E6%9C%AA%E5%88%86%E7%B1%BB/"},{"name":"RabbitMQ","slug":"SpringCloud/RabbitMQ","link":"/Hexo/categories/SpringCloud/RabbitMQ/"},{"name":"Nacos","slug":"SpringCloud/Nacos","link":"/Hexo/categories/SpringCloud/Nacos/"},{"name":"OpenAPI3","slug":"SpringBoot3/OpenAPI3","link":"/Hexo/categories/SpringBoot3/OpenAPI3/"},{"name":"MyBatisPlus","slug":"SpringBoot3/MyBatisPlus","link":"/Hexo/categories/SpringBoot3/MyBatisPlus/"},{"name":"Elasticsearch","slug":"SpringCloud/Elasticsearch","link":"/Hexo/categories/SpringCloud/Elasticsearch/"},{"name":"Gateway","slug":"SpringCloud/Gateway","link":"/Hexo/categories/SpringCloud/Gateway/"},{"name":"Kafka","slug":"SpringCloud/Kafka","link":"/Hexo/categories/SpringCloud/Kafka/"},{"name":"Minio","slug":"SpringCloud/Minio","link":"/Hexo/categories/SpringCloud/Minio/"},{"name":"xxl-job","slug":"SpringCloud/xxl-job","link":"/Hexo/categories/SpringCloud/xxl-job/"},{"name":"OpenFeign","slug":"SpringCloud/OpenFeign","link":"/Hexo/categories/SpringCloud/OpenFeign/"},{"name":"认证授权","slug":"SpringCloud/认证授权","link":"/Hexo/categories/SpringCloud/%E8%AE%A4%E8%AF%81%E6%8E%88%E6%9D%83/"},{"name":"Redis","slug":"SpringCloud/Redis","link":"/Hexo/categories/SpringCloud/Redis/"},{"name":"MySQL","slug":"SpringBoot3/MySQL","link":"/Hexo/categories/SpringBoot3/MySQL/"},{"name":"RuoYi-Cloud-Plus","slug":"SpringCloud/RuoYi-Cloud-Plus","link":"/Hexo/categories/SpringCloud/RuoYi-Cloud-Plus/"},{"name":"支付","slug":"SpringCloud/支付","link":"/Hexo/categories/SpringCloud/%E6%94%AF%E4%BB%98/"},{"name":"Hexo","slug":"Hexo","link":"/Hexo/categories/Hexo/"},{"name":"Nginx","slug":"Front-End/Nginx","link":"/Hexo/categories/Front-End/Nginx/"},{"name":"Seata","slug":"SpringCloud/Seata","link":"/Hexo/categories/SpringCloud/Seata/"},{"name":"多级缓存架构","slug":"SpringCloud/多级缓存架构","link":"/Hexo/categories/SpringCloud/%E5%A4%9A%E7%BA%A7%E7%BC%93%E5%AD%98%E6%9E%B6%E6%9E%84/"}],"pages":[{"title":"","text":"Document + + Hexo基于Github Action实现自动更新Github Pages Preview | Documentation | Icarus Docs","link":"/Hexo/about/index.html"},{"title":"","text":".container { max-width: 1400px; /* 这里设置你需要的宽度 */ margin: 0 auto; /* 居中对齐 */ }","link":"/Hexo/css/custom.css"},{"title":"","text":"/* 背景色 */ html { background-color: #2e2e2e !important; } /* 顶部导航栏背景色 */ .navbar { background-color: #000 !important; } /* 卡片背景色 */ .card { background-color: #1e1e1e !important; } /* 顶部导航栏字体颜色 */ .navbar-item, .navbar-link { color: #e1e1e1 !important; } /* 文章正文字体颜色 */ .card { color: #eeeeee !important; } /* 文章标题字体颜色 */ .content h1, .content h2, .content h3, .content h4, .content h5, .content h6 { color: #e1e1e1 !important; } /* 其他文字颜色 */ .title { color: #e1e1e1 !important; } .menu-list a { color: #e1e1e1 !important; }","link":"/Hexo/css/dark-theme.css"}]}