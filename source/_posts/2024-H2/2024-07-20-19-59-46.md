---
title: Kafka之存储设计
comments: true
cover: /gallery/defaultCover2.png
thumbnail: /gallery/defaultThumbnail2.png
tags:
  - Kafka
  - 存储
categories:
-
  - SpringCloud
  - Kafka
date: 2024-07-20 19:59:49
description:
---



# 1. 分区和副本的存储结构

在一个多 broker 的 Kafka 集群中，topic 的分区和副本在各个 broker 上的存储文件夹分布如下：

假设有以下设置：

- 一个 Kafka 集群包含 3 个 broker（broker 0, broker 1, broker 2）。
- 一个 topic `my-topic`，有 3 个分区（partition 0, partition 1, partition 2）。
- 每个分区有 2 个副本。

### 1. 分区和副本的分布

Kafka 会在多个 broker 之间分配分区和副本。假设分配如下：

- `partition 0`：
  - leader: broker 0
  - follower: broker 1
- `partition 1`：
  - leader: broker 1
  - follower: broker 2
- `partition 2`：
  - leader: broker 2
  - follower: broker 0

### 2. 存储目录结构

每个 broker 的数据目录结构如下（假设 `log.dirs` 配置为 `/var/lib/kafka/data`）：

* Broker 0 (`/var/lib/kafka/data`)

```
/var/lib/kafka/data
└── my-topic-0  # partition 0 leader
    ├── 00000000000000000000.log
    ├── 00000000000000000000.index
    ├── 00000000000000000000.timeindex
└── my-topic-2  # partition 2 follower
    ├── 00000000000000000000.log
    ├── 00000000000000000000.index
    ├── 00000000000000000000.timeindex
```

* Broker 1 (`/var/lib/kafka/data`)

```
/var/lib/kafka/data
└── my-topic-0  # partition 0 follower
    ├── 00000000000000000000.log
    ├── 00000000000000000000.index
    ├── 00000000000000000000.timeindex
└── my-topic-1  # partition 1 leader
    ├── 00000000000000000000.log
    ├── 00000000000000000000.index
    ├── 00000000000000000000.timeindex
```

* Broker 2 (`/var/lib/kafka/data`)

```
/var/lib/kafka/data
└── my-topic-1  # partition 1 follower
    ├── 00000000000000000000.log
    ├── 00000000000000000000.index
    ├── 00000000000000000000.timeindex
└── my-topic-2  # partition 2 leader
    ├── 00000000000000000000.log
    ├── 00000000000000000000.index
    ├── 00000000000000000000.timeindex
```

### 3. 文件描述

每个分区目录包含多个文件：

- `.log` 文件：存储实际的消息数据。
- `.index` 文件：存储消息偏移量索引，以便快速定位消息。
- `.timeindex` 文件：存储消息时间戳索引，以便基于时间进行查找。
  
  

# 2. 相关配置

在 Apache Kafka 中，消息到达 leader broker 后，实际上是先写入操作系统的页缓存，然后由操作系统决定何时将数据刷入磁盘。

Kafka 允许通过配置参数来控制消息何时刷入磁盘。主要有以下几个重要的参数：

* `log.flush.interval.messages`：指定在写入多少条消息后，强制将数据刷入磁盘。默认为 `Long.MAX_VALUE`，即不基于消息数量进行刷盘。
* `log.flush.interval.ms`：指定时间间隔（以毫秒为单位），强制将数据刷入磁盘。默认为 `Long.MAX_VALUE`，即不基于时间进行刷盘。
* `log.flush.scheduler.interval.ms`：默认值为 `3000` 毫秒。这只是一个检查的频率，实际的刷盘行为是由 `log.flush.interval.ms` 决定的。当调度器检查时，如果发现已经超过了 `log.flush.interval.ms` 设置的时间间隔，就会触发刷盘操作。
* `log.segment.bytes`：控制单个日志段文件的最大大小，当一个日志段文件达到指定大小时，Kafka 会创建一个新的日志段文件，默认值1G。
* `log.segment.delete.delay.ms`：控制日志段文件在被删除之前的延迟时间。当一个日志段文件被标记为删除后，Kafka 会等待指定的延迟时间才会真正删除该文件。这为潜在的恢复操作提供了缓冲时间。默认值60000 ms。
* `log.roll.ms` 和 `log.roll.hours`：控制日志段文件的滚动时间间隔，无论日志段文件的大小如何，当达到指定的时间间隔时，Kafka 会创建一个新的日志段文件。`log.roll.hours`默认值168 小时（7 天）。
  
  

# 3. 数据文件类型

![8689aab7-3f63-48b0-9da6-279b832d5fb3](./2024-07-20-19-59-46/8689aab7-3f63-48b0-9da6-279b832d5fb3.png)

1. **.index 文件**：
   
   - **描述**：这是 Kafka 的偏移量索引文件。它用于快速查找消息在日志文件中的位置。
   - **命名格式**：`00000000000000000000.index`
   - **作用**：通过这个索引文件，Kafka 可以快速定位消息在日志文件中的物理位置，以便更快地读取消息。

2. **.log 文件**：
   
   - **描述**：这是 Kafka 的日志文件，存储实际的消息数据。
   - **命名格式**：`00000000000000000000.log`
   - **作用**：包含了生产者发送的消息内容。每个日志文件是一个分区的一部分，日志文件的命名表示消息的起始偏移量。

3. **.timeindex 文件**：
   
   - **描述**：这是 Kafka 的时间戳索引文件，存储消息的时间戳索引。
   - **命名格式**：`00000000000000000000.timeindex`
   - **作用**：通过这个文件，Kafka 可以根据时间戳快速查找消息。这个文件对于实现基于时间的消息查找非常重要。

4. **.snapshot 文件**：
   
   - **描述**：这是 Kafka 的快照文件，记录了日志段的元数据快照。
   - **命名格式**：`00000000000000000016.snapshot`
   - **作用**：用于恢复日志段的元数据，保证在崩溃恢复时能够正确地重建索引和时间戳数据。

5. **leader-epoch-checkpoint 文件**：
   
   - **描述**：这是 Kafka 用于记录 leader 选举周期的检查点文件。
   - **作用**：记录了分区的 leader 副本在不同的选举周期中的偏移量信息，帮助 Kafka 在故障恢复时确定正确的 leader 和消息偏移量。

6. **partition.metadata 文件**：
   
   - **描述**：这是 Kafka 的分区元数据文件。
   - **作用**：存储分区的基本元数据信息，如分区的 leader、replica 列表等，用于分区的管理和协调。





# 4. 数据定位原理

log等文件直接打开会乱码，使用以下工具可以解析到控制台。

```bash
kafka-run-class.sh kafka.tools.DumpLogSegments --files /path/to/log-file.log --print-data-log
```

一个log文件里面有如下内容，

![78daa8f7-08cb-4619-a443-f8a695d80de8](./2024-07-20-19-59-46/78daa8f7-08cb-4619-a443-f8a695d80de8.png)

Kafka 日志文件中的内容并不是简单的按行排列的消息，而是采用了批处理（batch）的方式来存储消息。



那么.index文件中可能是如下内容：

```textile
offset: 3 position: 95
```

`.index` 文件并不会为每一条消息都记录映射关系，而是每隔一定的字节数（由配置 `log.index.interval.bytes` 决定，默认4096）记录一次。



![790a1cc5-af68-496b-a6ef-c1109a800389](./2024-07-20-19-59-46/790a1cc5-af68-496b-a6ef-c1109a800389.png)

如上图，

#### LogSegment 类

`LogSegment` 主要负责一个段的日志管理。它包括：

* **日志文件（.log）**：存储实际的消息数据。
* **偏移量索引文件（.index）**：存储消息偏移量到物理位置的映射。
* **时间戳索引文件（.timeindex）**：存储消息时间戳到物理位置的映射。

#### UnifiedLog 类

`UnifiedLog` 管理一个分区的所有日志段。它通过跳表(`ConcurrentSkipListMap`)实现多个 `LogSegment` 日志的连续存储。`UnifiedLog` 的主要职责包括：

* **消息写入**：将消息追加到当前活动的 `LogSegment` 中。如果当前日志段已满，滚动到新的日志段。
* **消息读取**：根据偏移量或时间戳查找并读取消息，可能跨越多个日志段。
* **日志截断**：根据保留策略（如日志保留时间或大小），截断过期或不需要的日志段。
* **数据恢复**：在 broker 重启或故障恢复时，从日志段中恢复数据。



如图，要查询偏移量为7的数据：

1. 通过跳表定位到对应的LogSegment

2. 通过.index，经由二分法等高效定位指定偏移量的位置（如果没记录，则使用最大的小于偏移量位置）

3. 按照指定位置快速定位到偏移量7的位置（或更前面一些）


